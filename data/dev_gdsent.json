[{"qid": "e0044a7b4d146d611e73", "term": "Albany, Georgia", "description": "City in Georgia, United States", "question": "Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?", "answer": false, "facts": ["Albany, GA has around 75,000 people", "Albany, NY has almost 100,000 people"], "decomposition": ["What is the population of Albany, Georgia?", "What is the population of Albany, New York?", "What is the difference between 100,000 and #1?", "What is the difference between 100,000 and #2?", "Is #3 smaller than #4?"], "evidence": [[[["Albany, Georgia-1"]], [["Albany, New York-2"]], ["operation"], ["operation"], ["operation"]], [[["Albany, Georgia-35"]], [["Albany, New York-2"]], ["operation"], ["operation"], ["operation"]], [[["Albany, Georgia-1"]], [["Albany, New York-2"]], ["operation"], ["operation"], ["operation"]]], "golden_sentence": [["The population was 77,434 at the 2010 U.S. Census, making it the eighth-largest city in the state."], ["As of the 2010 census, the population of Albany was 97,856."]]}, {"qid": "c69397b4341b65ed080f", "term": "Saint Vincent and the Grenadines", "description": "Country in the Caribbean", "question": "Is the language used in Saint Vincent and the Grenadines rooted in English?", "answer": true, "facts": ["The primary language spoken in Saint Vincent and the Grenadines is Vincentian Creole.", "Vincentian Creole is English-based, with elements of French, Antillean Creole, and indigenous South American and African languages."], "decomposition": ["What language is used in Saint Vincent and the Grenadines?", "Is #1 based in English?"], "evidence": [[[["Demographics of Saint Vincent and the Grenadines-9"]], [["Saint Vincent and the Grenadines-59"], "operation"]], [[["Vincentian Creole-1"]], [["Vincentian Creole-1"]]], [[["Saint Vincent and the Grenadines-59"]], [["Saint Vincent and the Grenadines-59"]]]], "golden_sentence": [["While the official language is English most Vincentians speak Vincentian Creole, an English-based creole, as their mother tongue."], ["citation needed] English is the official language."]]}, {"qid": "be5c9933987f046b476e", "term": "Greed", "description": "an inordinate or insatiable longing, especially for wealth, status, and power", "question": "Is greed the most prevalent of the Seven Deadly Sins?", "answer": false, "facts": ["Greed is a longing for wealth and power.", "White collar crime involves businesses stealing money or assets from people. ", "5-10% of arrests per 100,000 arrests were for  white collar crime according to Department of Justice statistics.", "Gluttony is the overindulgence in food or similar things.", "39.8% of US adults were classified as overweight according to the National Center for Health Statistics."], "decomposition": ["Is greed a  deadly sin?", "Is gluttonly a deadly sin?", "What percent of crimes involved greed?", "What percent of people are overweight?", "If #1 and #2 are both yes is #3 a higher percentager than #4?"], "evidence": [[[["Seven deadly sins-1"]], [["Seven deadly sins-1"]], [["Theft-52"], "no_evidence"], [["Overweight-18"]], ["no_evidence", "operation"]], [[["Greed-10"]], [["Gluttony-2"]], [["Theft-1"], "no_evidence"], [["Obesity-4"]], ["no_evidence", "operation"]], [[["Seven deadly sins-1"]], [["Seven deadly sins-1"]], [["White-collar crime-3"], "no_evidence"], [["Obesity in the United States-41"]], ["operation"]]], "golden_sentence": [["These sins are often thought to be abuses or excessive versions of one's natural faculties or passions (for example, gluttony abuses one's desire to eat, to consume)."], ["These sins are often thought to be abuses or excessive versions of one's natural faculties or passions (for example, gluttony abuses one's desire to eat, to consume)."], ["Most commonly, statutes establishing the distinction between grand theft and petty theft do so on the basis of the value of the money or property taken by the thief or lost by the victim, with the dollar threshold for grand theft varying from state to state."], ["As much as 64% of the United States' adult population is considered either overweight or obese, and this percentage has increased over the last four decades."]]}, {"qid": "1932e05f10680ece229f", "term": "Sea of Japan", "description": "Marginal sea between Japan, Russia and Korea", "question": "Would the top of Mount Fuji stick out of the Sea of Japan? ", "answer": true, "facts": ["The average depth of the Sea of Japan is  5,748 feet (1,752 metres) and its maximum depth is 12,276 feet (3,742 metres)", "Mount Fuji is 3,776.24 metres (12,389.2 ft) tall. "], "decomposition": ["How tall is Mount Fuji?", "What is the maximum depth of the Sea of Japan?", "Is #1 greater than #2?"], "evidence": [[[["Mount Fuji-18"]], [["Sea of Japan-15"]], ["operation"]], [[["Mount Fuji-1"]], [["Sea of Japan-15"]], ["operation"]], [[["Mount Fuji-1"]], [["Sea of Japan-15"]], ["operation"]]], "golden_sentence": [["It stands 3,776.24\u00a0m (12,389\u00a0ft) tall and is located near the Pacific coast of central Honshu, just south-west of Tokyo."], ["The sea has a surface area of about 978,000\u00a0km2 (378,000\u00a0sq\u00a0mi), a mean depth of 1,752\u00a0m (5,748\u00a0ft) and a maximum depth of 3,742\u00a0m (12,277\u00a0ft)."]]}, {"qid": "fb8b656051c742f5bd27", "term": "Lil Jon", "description": "American rapper, record producer and DJ from Georgia", "question": "Was Lil Jon's top ranked Billboard song a collaboration with a member of The Lox?", "answer": false, "facts": ["Lil Jon's highest ranked billboard song was Yeah.", "Yeah was a collaboration between Lil Jon, Usher, and Ludacris.", "The Lox is a rap trio consisting of: Styles P, Sheek Louch, and Jadakiss."], "decomposition": ["What is Lil Jon's top ranked Billboard song?", "What artists contributed to #1?", "Who makes up the group The Lox?", "Is any element of #3 also an element of #2?"], "evidence": [[[["Yeah! (Usher song)-1"]], [["Yeah! (Usher song)-1"]], [["The Lox-1"]], ["operation"]], [[["Lil Jon-1", "Yeah! (Usher song)-2"]], [["Yeah! (Usher song)-10"]], [["The Lox-1"]], ["operation"]], [[["Lil Jon-1"]], [["Yeah! (Usher song)-1"]], [["The Lox-1"]], ["operation"]]], "golden_sentence": [["The song was released as the lead single from Usher's fourth studio album Confessions (2004) on January 27, 2004, after Usher was told by Arista Records, his label at the time, to record more tracks for the album."], ["It also features guest vocals from Lil Jon and Ludacris, with the former also producing the song as well as incorporating crunk and R&B\u2014which he coined as crunk&B\u2014in the song's production."], ["The group is composed of East Coast rappers Sheek Louch, Styles P and Jadakiss."]]}, {"qid": "c91eafafed5a8f80bb5a", "term": "Miami", "description": "City in Florida, United States", "question": "Is Miami a city on the American West Coast?", "answer": false, "facts": ["Miami is a city in the state of Florida.", "Florida is the southernmost state on the American East Coast."], "decomposition": ["What state is Miami located in?", "Which states are part of the American West Coast?", "Is #1 included in #2?"], "evidence": [[[["Miami-1"]], [["West Coast of the United States-1"]], ["operation"]], [[["Miami-2"]], [["Pacific states-1"]], [["Pacific states-1"], "operation"]], [[["Miami-1"]], [["West Coast of the United States-1"]], ["operation"]]], "golden_sentence": [["Miami (/ma\u026a\u02c8\u00e6mi/), officially the City of Miami, is the seat of Miami-Dade County, and the cultural, economic and financial center of South Florida in the United States."], ["As a region, this term most often refers to the coastal states of California, Oregon, Washington, and Alaska."]]}, {"qid": "2047c0c34383f8014820", "term": "Swiss Guard", "description": "Military of Vatican City", "question": "Can the Swiss Guard fill the Virginia General Assembly chairs?", "answer": false, "facts": ["The Virginia General Assembly has 140 seats.", "The Swiss Guard is an honour guard of Vatican City that consists of 135 men."], "decomposition": ["What is the size of the Swiss Guard?", "What is the seating capacity of the Virginia General Assembly?", "Is #1 equal to or greater than #2?"], "evidence": [[[["Swiss Guards-18"], "no_evidence"], [["Virginia General Assembly-1"]], ["no_evidence", "operation"]], [[["Swiss Guard-31"]], [["Virginia General Assembly-1"]], ["operation"]], [[["Swiss Guard-9"]], [["Virginia General Assembly-1"]], ["operation"]]], "golden_sentence": [["A small force maintained by the Holy See, it is responsible for the safety of the Pope, including the security of the Apostolic Palace."], ["The General Assembly is a bicameral body consisting of a lower house, the Virginia House of Delegates, with 100 members, and an upper house, the Senate of Virginia, with 40 members."]]}, {"qid": "7702ee1e9f757ebffdf1", "term": "Portuguese Colonial War", "description": "1961\u20131974 armed conflicts in Africa between Portugal and independence movements", "question": "Did any country in Portuguese Colonial War share Switzerlands role in WWII?", "answer": true, "facts": ["The Portuguese Colonial War was between Portugal and several groups including People's Movement for Liberation of Angola.", "Switzerland remained neutral in World War II and did not get involved.", "Portugal stayed out of world affairs during World War II."], "decomposition": ["What was Switzerland's position in World War II?", "Which countries were involved in the Portuguese Colonial War?", "Did any of #2 maintain a #1 position through World War II?"], "evidence": [[[["Switzerland-33"]], [["Portuguese Colonial War-2"]], [["The Two Faces of War-11"]]], [[["Switzerland during the World Wars-20"]], [["Liberal Wars-1"]], [["Neutral powers during World War II-6"], "operation"]], [[["Switzerland during the World Wars-1"]], [["Portuguese Colonial War-1"]], ["operation"]]], "golden_sentence": [["Switzerland was not invaded during either of the world wars."], ["The prevalent Portuguese and international historical approach considers the Portuguese Colonial War as was perceived at the time: a single conflict fought in three separate theaters of operations: Angola, Guinea-Bissau and Mozambique (sometimes including the 1954 Indian Annexation of Dadra and Nagar Haveli and 1961 Indian Annexation of Goa) rather than a number of separate conflicts as the emergent African countries aided each other during the war."], ["In Portugal, the Estado Novo put the country into a dilemma: on the one hand, the Portuguese policy of neutrality in World War II which saved the Portuguese Armed Forces from a possible confrontation between East and West, and secondly, the responsibility for the maintenance of sovereignty over its colonies."]]}, {"qid": "11d009721f27a60f9cff", "term": "Old English", "description": "Early form of English; Anglo-Saxon", "question": "Would a Pict be confused by Old English?", "answer": true, "facts": ["Old English was spoken by the Anglo-Saxons, a Germanic tribe that inhabited England.", "The Picts were a Celtic-speaking people that lived in what is now Scotland.", "The Pictish language died out by 1100AD and was replaced by Gaelic.", "Gaelic and Old English are completely different languages from different branches of the Indo-European language family.", "Gaelic vocabulary is very different from Old English  and verbs are also conjugated differently."], "decomposition": ["What language was spoken by the Picts?", "In what language family is Old English?", "Is #2 not closely related to #1?"], "evidence": [[[["Picts-1"]], [["Old English-2"]], [["Pictish language-2"], "operation"]], [[["Pictish language-1", "Picts-1"]], [["Old English-1"]], [["English language-2", "Picts-36"], "operation"]], [[["Picts-1"]], [["Old English-3"]], [["Celtic languages-1", "West Germanic languages-2"]]]], "golden_sentence": [["The Picts were a confederation of Celtic-speaking peoples who lived in what is today eastern and northern Scotland during the Late British Iron Age and Early Medieval periods.", "Early medieval sources report the existence of a distinct Pictish language, which today is believed to have been an Insular Celtic language, closely related to the Brittonic spoken by the Britons who lived to the south."], ["Old English developed from a set of Anglo-Frisian or Ingvaeonic dialects originally spoken by Germanic tribes traditionally known as the Angles, Saxons and Jutes."], ["This is now a minority view, if not completely abandoned."]]}, {"qid": "2a90188d5b82d12c036d", "term": "Lil Wayne", "description": "American rapper, record executive and actor from Louisiana", "question": "Could Lil Wayne legally operate a vehicle on his own at the beginning of his career?", "answer": false, "facts": ["Lil Wayne's career began in 1995, at the age of 12, when he was signed by Birdman and joined Cash Money Records as the youngest member of the label.", "A driver's license is required to legally operate a vehicle by yourself in the USA.", "The eligible age to first obtain a driver's license varies substantially from state to state, from 14 years, three months, in South Dakota to 17 in New Jersey."], "decomposition": ["How old was Lil Wayne when he started his career in music?", "What is the minimum age required to obtain a valid driver's license in the US?", "Is #1 at least equal to #2?"], "evidence": [[[["Lil Wayne-1"]], [["Driver's licenses in the United States-9"]], ["operation"]], [[["Lil Wayne-7"]], [["Driver's licenses in the United States-9"]], ["operation"]], [[["Lil Wayne-1"]], [["Driver's licenses in the United States-12"]], ["operation"]]], "golden_sentence": [["Dwayne Michael Carter Jr. (born September 27, 1982), better known by his stage name Lil Wayne, is an American rapper, singer, songwriter, record executive, entrepreneur, and actor.", "His career began in 1996, at the age of 13, when he was discovered by Birdman and joined Cash Money Records as the youngest member of the label."], ["The minimum age to obtain a restricted driver license in the US varies from 14 years, three months in South Dakota to as high as 17 in New Jersey."]]}, {"qid": "1e9d59987a695898808f", "term": "Karachi", "description": "Megacity in Sindh, Pakistan", "question": "Are you likely to find a crucifix in Karachi?", "answer": false, "facts": ["The crucifix is a symbol of Christianity", "The vast majority of Pakistan's population is Muslim"], "decomposition": ["What religion does a crucifix symbolize?", "What is the main religion observed in Karachi, Pakistan?", "Is #1 the same as #2?"], "evidence": [[[["Crucifix-2"]], [["Karachi-66"]], ["operation"]], [[["Crucifix-2"]], [["Karachi-66", "Muslims-1"]], ["operation"]], [[["Christian cross-1"]], [["Religion in Karachi-6"]], ["operation"]]], "golden_sentence": [["The crucifix is a principal symbol for many groups of Christians, and one of the most common forms of the Crucifixion in the arts.", "The crucifix emphasizes Jesus' sacrifice\u2014his death by crucifixion, which Christians believe brought about the redemption of mankind."], ["Karachi is overwhelmingly Muslim, though the city is one of Pakistan's most secular cities."]]}, {"qid": "59e78fdde03974a7cf77", "term": "Creative Commons license", "description": "license allowing free use of a work", "question": "Was a person sold a Creative Commons License for Boticelli's The Birth of Venus ripped off?", "answer": true, "facts": ["A Creative Commons license allows for the free distribution of an otherwise copyrighted piece of work.", "Works that are deemed in the public domain do not require a copyright or permission to use.", "Any work created before 1923 is in the public domain.", "Sandro Boticelli's The Birth of Venus painting was from 1486."], "decomposition": ["What is the purpose of a Creative Commons license?", "Do works in the public domain need #1?", "Works created before what year are presently in the public domain?", "Was Boticelli's The Birth of Venus created before #3?", "Considering #2 and #4, is #1 unnecessary for Boticelli's The Birth of Venus?"], "evidence": [[[["Creative Commons license-1"]], [["Public domain-1"]], [["Public domain-10"], "no_evidence"], [["The Birth of Venus-1"], "operation"], ["operation"]], [[["Creative Commons license-1"]], [["Public domain-1"]], [["Public domain-2"]], [["The Birth of Venus-17"]], ["operation"]], [[["Creative Commons license-1"]], [["Public domain-1"]], [["Copyright term-2", "Public domain-6"], "no_evidence"], [["The Birth of Venus-1"]], ["operation"]]], "golden_sentence": [["Play media A Creative Commons (CC) license is one of several public copyright licenses that enable the free distribution of an otherwise copyrighted \"work\"."], ["The public domain consists of all the creative work to which no exclusive intellectual property rights apply."], ["A notable exception is the United States, where every book and tale published prior to 1925 is in the public domain; American copyrights last for 95 years for books originally published between 1925 and 1978 if the copyright was properly registered and maintained."], ["It depicts the goddess Venus arriving at the shore after her birth, when she had emerged from the sea fully-grown (called Venus Anadyomene and often depicted in art)."]]}, {"qid": "869bbd1c4e3c0bf02527", "term": "Gallon", "description": "general topic for different units of volume called gallon", "question": "Could ten gallons of seawater crush a six year old?", "answer": true, "facts": ["The average weight of a six year old is 45 pounds.", "One gallon of seawater weighs slightly over 8 pounds."], "decomposition": ["What is the average weight of a six year old?", "What is the weight of a gallon of seawater?", "Is ten times #2 more than #1?"], "evidence": [[[["Weigh station-3"], "no_evidence"], [["Seawater-1"], "no_evidence"], ["operation"]], [[["Child-7"], "no_evidence"], [["Seawater-1"], "no_evidence"], ["operation"]], [[["Early childhood-4"], "no_evidence"], [["Seawater-1"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["Portable scales allow states to set up temporary scales for situations such as seasonal check points, temporary checkpoints on isolated roads often used by trucks, or to prevent drivers from avoiding scales at fixed locations."], ["This means that every kilogram (roughly one litre by volume) of seawater has approximately 35 grams (1.2\u00a0oz) of dissolved salts (predominantly sodium (Na+ ) and chloride (Cl\u2212 ) ions)."]]}, {"qid": "4a28d99dcfc14161dc9f", "term": "Anchovy", "description": "Family of fishes", "question": "Do more anchovy live in colder temperature waters than warmer?", "answer": false, "facts": ["Anchovy are a type of small fish.", "Anchovy are concentrated in the temperate waters of the Atlantic, Indian, and Pacific Oceans.", "Anchovy are rarely found in colder waters."], "decomposition": ["Which oceans do Anchovy live in?", "Which seas do Anchovy live in?", "Are #1 and #2 cold waters?"], "evidence": [[[["Anchovy-5"]], [["Anchovy-6"]], [["Anchovy-6"], "no_evidence"]], [[["Anchovy-2"]], [["Anchovy-2"]], ["no_evidence", "operation"]], [[["Anchovy-5"]], [["Anchovy-5"]], ["operation"]]], "golden_sentence": [["Anchovies are found in scattered areas throughout the world's oceans, but are concentrated in temperate waters, and are rare or absent in very cold or very warm seas."], ["This species is regularly caught along the coasts of Crete, Greece, Sicily, Italy, France, Turkey, Northern Iran, Portugal and Spain."], ["Spawning occurs between October and March, but not in water colder than 12\u00a0\u00b0C (54\u00a0\u00b0F)."]]}, {"qid": "9635db8809b449470dd6", "term": "3D printing", "description": "Additive process used to make a three-dimensional object", "question": "Is 3D printing able to make adenovirus?", "answer": false, "facts": ["3D printers come with limitations in terms of precision. The standard nozzle output is about 0.4 mm. Therefore, if you are planning to print something that is below 0.4mm, you will not get a useful item.", "Adenoviruses are medium-sized (90\u2013100 nm), nonenveloped (without an outer lipid bilayer) viruses with an icosahedral nucleocapsid containing a double stranded DNA genome."], "decomposition": ["What is the size of a 3D printer's standard nozzle output?", "What size range do adenoviruses fall in?", "Is #2 greater than or equal to #1?"], "evidence": [[["no_evidence"], [["Adenoviridae-10"]], ["operation"]], [[["Fused filament fabrication-7"]], [["Adenoviridae-1"]], [["Nanometre-1"], "operation"]], [[["3D printing-44"], "no_evidence"], [["Adenoviridae-1", "Nanometre-1"]], ["no_evidence", "operation"]]], "golden_sentence": [["The adenovirus genome is linear, non-segmented double-stranded (ds) DNA that is between 26 and 48 Kbp."]]}, {"qid": "44f54e361e0f46ead5d4", "term": "Stoning", "description": "execution method", "question": "Would George Fox support stoning?", "answer": false, "facts": ["George Fox was the founder of the Religious Society of Friends, commonly known as the Quakers or Friends.", "The Quakers advocate for peace and nonviolence.", "Stoning is a particularly violent and brutal method of capital punishment."], "decomposition": ["What was George Fox the founder of?", "What did #1 advocate for?", "Is stoning an example of #2?"], "evidence": [[[["George Fox-1"]], [["Quakers-1"]], ["no_evidence"]], [[["George Fox-1"]], [["George Fox-23"]], ["operation"]], [[["George Fox-1"]], [["Quakers-63"]], [["Stoning-1"], "operation"]]], "golden_sentence": [["George Fox (July 1624 \u2013 23 January 1691 (O.S.13 January 1690)) was an English Dissenter, who was a founder of the Religious Society of Friends, commonly known as the Quakers or Friends."], ["Members of the various Quaker movements are all generally united by their belief in the ability of each human being to experientially access the light within, or \"that of God in every one\"."]]}, {"qid": "addf92ab71aca4e783b1", "term": "Darth Vader", "description": "fictional character in the Star Wars franchise", "question": "Is watching  Star Wars necessary to know who Darth Vader is?", "answer": false, "facts": ["Star Wars is one of the most widely parodied film series to be produced.", "Star Wars merchandise, from tees to Halloween costumes, is widely available and is plentiful. "], "decomposition": ["Has Star Wars inspired many parody films?", "Are Star Wars merchandise depicting characters from the movie available?", "Considering #1 and #2, are there no depictions of characters outside the movie?"], "evidence": [[[["Robot Chicken: Star Wars-8"]], [["Lego Star Wars-1"]], [["Lego Star Wars-1", "Robot Chicken: Star Wars-8"]]], [[["Cultural impact of Star Wars-1", "Star Wars: The Vintage Collection-1"], "no_evidence"], [["Star Wars-1"], "no_evidence"], ["operation"]], [[["Lego Star Wars-9", "Spaceballs-2"]], [["Walker (Star Wars)-33"]], ["operation"]]], "golden_sentence": [["Aubry D'Arminio of Entertainment Weekly, in reviewing the DVD, stated \"Every adult cartoon, from Family Guy to The Simpsons, has spawned a Star Wars parody, but the stop-motion maniacs at Robot Chicken top them all with 23 guffaw-filled minutes.\""], ["Lego Star Wars is a Lego theme that incorporates the Star Wars saga and franchise."], ["Lego Star Wars is a Lego theme that incorporates the Star Wars saga and franchise.", "He concluded that \"it is tough to find anything wrong with [it]\" and \"Robot Chicken went all out in creating a humorous half hour which would have us [Star Wars] nerds rolling on the floor laughing.\""]]}, {"qid": "f9686fe476e2d06e4dab", "term": "Boolean algebra", "description": "Algebra involving variables containing only \"true\" and \"false\" (or 1 and 0) as values", "question": "Can a computer be programmed entirely in Boolean algebra?", "answer": true, "facts": ["Boolean algebra is the branch of algebra in which the values of the variables are the truth values true and false, usually denoted 1 and 0 respectively. ", "Mathematics in 1 and 0 is also called binary or machine language.", "Computers are programmed in machine language."], "decomposition": ["What are values included in Boolean algebra?", "At what level are program codes read directly by computers?", "Are the values included in #2 the same as #1?"], "evidence": [[[["Boolean algebra-1"]], [["Computer programming-7"], "no_evidence"], ["operation"]], [[["Boolean algebra-1"]], [["Binary code-1"]], ["operation"]], [[["Boolean algebra-1"]], [["Binary code-1"]], ["operation"]]], "golden_sentence": [["In mathematics and mathematical logic, Boolean algebra is the branch of algebra in which the values of the variables are the truth values true and false, usually denoted 1 and 0 respectively.", "Instead of elementary algebra where the values of the variables are numbers, and the prime operations are addition and multiplication, the main operations of Boolean algebra are the conjunction (and) denoted as \u2227, the disjunction (or) denoted as \u2228, and the negation (not) denoted as \u00ac."], ["citation needed] Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation."]]}, {"qid": "5737e93c88fa5e21c2b5", "term": "Kelly Clarkson", "description": "American singer-songwriter, actress, and television personality", "question": "Did Christina Aguilera turn her chair around for Kelly Clarkson on The Voice?", "answer": false, "facts": ["Christina Aguilera is a judge on the voice.", "Kelly Clarkson is a judge on the voice.", "Judges only turn their chairs around for competitors. ", "Kelly Clarkson has not competed on the voice."], "decomposition": ["Do judges on the voice turn their chair for only contestants?", "Has Kelly Clarkson ever been a contestant on the voice?", "Are #1 and #2 the same?"], "evidence": [[[["The Voice (franchise)-2"]], [["Kelly Clarkson-33"]], ["operation"]], [[["The Voice (franchise)-6"]], [["Kelly Clarkson-1"]], ["operation"]], [[["The Voice (franchise)-6"]], [["Kelly Clarkson-34"]], ["operation"]]], "golden_sentence": [["He wanted to focus on singing quality alone, so the coaches must be top artists in the music industry."], ["In the fourteenth season of The Voice, Brynn Cartelli was crowned the winner, giving Clarkson her first victory."]]}, {"qid": "33421d4495e27f91be4d", "term": "Amy Winehouse", "description": "English singer and songwriter", "question": "Would Amy Winehouse's death have been prevented with Narcan?", "answer": false, "facts": ["Narcan is a medication that save the life of someone overdosing on opiates.", "Amy Winehouse died from alcohol poisoning.", "Narcan cannot work on alcohol overdoses."], "decomposition": ["What was the cause of Amy Winehouse's death?", "What are the indications/symptoms that can be treated with Narcan?", "Is #1 included in #2?"], "evidence": [[[["Amy Winehouse-4"]], [["Naloxone-1"]], ["operation"]], [[["Amy Winehouse-92"]], [["Naloxone-4", "Naloxone-7"]], ["operation"]], [[["Amy Winehouse-92"]], [["Naloxone-1"]], ["operation"]]], "golden_sentence": [["She died of alcohol poisoning on 23 July 2011 at the age of 27."], ["It is commonly used for decreased breathing in opioid overdose."]]}, {"qid": "99eb858b4c9624a71b40", "term": "Mongoose", "description": "family of mammals", "question": "Does a mongoose have natural camouflage for desert?", "answer": true, "facts": ["The most common fur colors of mongooses are brown and gray.", "The Desert Camouflage color is made of Caf\u00e9 Au Lait brown and Pastel Gray."], "decomposition": ["What colors are mongoose?", "What colors are desert camouflage?", "Is #1 included in #2?"], "evidence": [[[["Mongoose-5"]], [["Desert Camouflage Uniform-1"]], [["Desert Camouflage Uniform-1", "Mongoose-5"]]], [[["Egyptian mongoose-2"], "no_evidence"], [["Desert Camouflage Uniform-1"]], ["operation"]], [[["Indian brown mongoose-2"], "no_evidence"], [["Desert Camouflage Uniform-1"]], ["operation"]]], "golden_sentence": [["Most are brindled or grizzly; a few have strongly marked coats which bear a striking resemblance to mustelids."], ["In terms of pattern and textile cut, it is nearly identical to the U.S. military's Battle Dress Uniform (BDU) uniform, but features a three-color desert camouflage pattern of dark brown, pale green, and beige, as opposed to the beige, pale green, two tones of brown, and black and white rock spots of the previous Desert Battle Dress Uniform (DBDU)."], ["In terms of pattern and textile cut, it is nearly identical to the U.S. military's Battle Dress Uniform (BDU) uniform, but features a three-color desert camouflage pattern of dark brown, pale green, and beige, as opposed to the beige, pale green, two tones of brown, and black and white rock spots of the previous Desert Battle Dress Uniform (DBDU).", "Their nonretractile claws are used primarily for digging."]]}, {"qid": "b1e1256007b0a4a341a7", "term": "Capsaicin", "description": "chemical compound", "question": "If someone loves buffalo wings do they enjoy capsaicin?", "answer": true, "facts": ["Buffalo wings are fried chicken wings covered in a spicy sauce.", "Spicy foods are provided their spice from capsaicin from peppers."], "decomposition": ["What sauce is used on buffalo wings?", "What is the flavor of #1", "Is capsaicin used to create #2?"], "evidence": [[[["Buffalo wing-10"]], [["Cayenne pepper-1"]], [["Capsicum annuum-6"], "operation"]], [[["Buffalo wing-10"]], [["Hot sauce-1"]], [["Capsaicin-1"], "operation"]], [[["Buffalo wing-1"]], [["Buffalo wing-10"]], [["Capsaicin-1"]]]], "golden_sentence": [["Cayenne pepper, hot sauce and melted butter or margarine are the base of the Buffalo wing sauce, which may be made mild, medium, or hot."], ["It is usually a moderately hot chili pepper used to flavor dishes."], ["Capsinoid chemicals provide the distinctive tastes in C. annuum variants."]]}, {"qid": "12b0bb830de101c0f118", "term": "Bruce Lee", "description": "Hong Kong-American actor, martial artist", "question": "Was Bruce Lee absent from the 1964 University of Washington graduation ceremony?", "answer": true, "facts": ["Bruce Lee enrolled at the University of Washington in 1961.", "Bruce Lee dropped out of college in early 1964.", "Bruce Lee moved to Oakland to live with James Yimm Lee in 1964."], "decomposition": ["When did the University of Washington graduation ceremony for the class of 1964 take place?", "What college did Bruce Lee attend?", "When did Bruce Lee drop out of #2?", "Did #1 occur after #3?"], "evidence": [[["no_evidence"], [["Bruce Lee-30"]], [["Bruce Lee-15"]], ["operation"]], [["no_evidence"], [["Bruce Lee-2"]], [["Bruce Lee-15"]], ["operation"]], [["no_evidence"], [["Bruce Lee-14"]], [["Bruce Lee-15"]], ["no_evidence", "operation"]]], "golden_sentence": [["Lee is best known as a martial artist, but he also studied drama and Asian and Western philosophy while a student at the University of Washington and throughout his life."], ["Lee dropped out of college in early 1964 and moved to Oakland to live with James Yimm Lee."]]}, {"qid": "0f28837d8ce6901345bf", "term": "University of Pennsylvania", "description": "Private Ivy League research university in Philadelphia, Pennsylvania", "question": "Could Brooke Shields succeed at University of Pennsylvania?", "answer": true, "facts": ["Brooke Shields graduated from Princeton University.", "Princeton is ranked as the number 1 national college by US news.", "University of Pennsylvania is ranked as number 6 national college by US news.", "Princeton only admits around 6 percent of applicants as of 2018.", "University of Pennsylvania accepts around 9% of applicants as of 2018."], "decomposition": ["What college did Brooke Shields go to?", "Out of all colleges in the US, how is #1 ranked?", "Is the ranking of University of Pennsylvania similar to #2?"], "evidence": [[[["Brooke Shields-6"]], [["Princeton University-59"]], [["University of Pennsylvania-48"]]], [[["Brooke Shields-6"]], [["Princeton University-59"]], [["University of Pennsylvania-48"], "operation"]], [[["Brooke Shields-6"]], [["Princeton University-3"], "operation"], [["University of Pennsylvania-47"], "no_evidence"]]], "golden_sentence": [["At Princeton, Shields spoke openly about her sexuality and virginity.", "Noting that Shields \"got all As and Bs, and obviously paid attention to her school work\", it claimed she \"got cheated\" because Princeton did not require her to take any classical studies, medieval, modern or American history, nor any course in mathematics, philosophy, economics, political science, world literature, or science with laboratory experience."], ["From 2001 through 2019, Princeton University was ranked either first or second among national universities by U.S. News & World Report, holding the top spot for 17 of those 19 years (sole #1 twelve times, tied with Harvard for #1 five times)."], ["U.S. News & World Report's 2020 rankings place Penn 6th among national universities in the United States."]]}, {"qid": "3545982eb15f96652e1b", "term": "Rowing (sport)", "description": "Sport where individuals or teams row boats by oar", "question": "Would students at Marist have to petition to get a rowing team?", "answer": false, "facts": ["Marist is located along the Hudson River.", "Marist college has rowing teams for both men and women."], "decomposition": ["What sports teams exist at Marist?", "Does #1 exclude mention of any rowing team?"], "evidence": [[[["Marist-2"]], [["Marist Red Foxes-25"], "operation"]], [[["Marist College-89"]], [["Rowing (sport)-1"], "operation"]], [[["Marist College-89", "Marist Red Foxes-22"]], ["operation"]]], "golden_sentence": [["Marist Brothers also known as the Little Brothers of Mary and the Marist Brothers of the Schools Society of Mary (Marists) also known as the Marist Fathers Marist Sisters, a Catholic religious congregation of women Missionary Sisters of the Society of Mary also known as The Marist Missionary Sisters In New Zealand and the South Pacific Marist Brothers of the Schools began football clubs that bear the name Marist."], ["Marist routinely participates in the annual ECAC championships, the NYSCCA (New York State) rowing championships and the IRA national championships."]]}, {"qid": "a19804759885b694c56a", "term": "Lolcat", "description": "image combining a photograph of a cat with text intended to contribute humour", "question": "Could a hundred thousand lolcats fit on a first generation iPhone?", "answer": true, "facts": ["Lolcat memes are often in jpeg form", "The average size of a jpeg is 10 to 30 kb", "One gigabyte is 1000000 kb", "The first iPhone had 4GB to 16GB of storage "], "decomposition": ["What file formats are lolcats usually saved in?", "What is the typical size of #1?", "What was the storage size range of first generation iPhones?", "What is 100000 multiplied by #2 expressed in gigabytes?", "Is #4 less than or equal to the minimum value of #3?"], "evidence": [[[["Cats and the Internet-1", "Image macro-2"]], ["no_evidence"], [["IPhone (1st generation)-11", "IPhone (1st generation)-7"]], ["operation"], ["operation"]], [[["Lolcat-1"]], ["no_evidence"], [["IPhone (1st generation)-7"]], [["Gigabyte-1"], "operation"], ["operation"]], [[["Image macro-1", "Lolcat-1"]], ["no_evidence"], [["IPhone (1st generation)-10"]], ["no_evidence", "operation"], ["no_evidence", "operation"]]], "golden_sentence": [["Images and videos of domestic cats make up some of the most viewed content on the web, particularly image macros in the form of lolcats.", "LOLCats, which are images of expressive cats coupled with texts, are considered to be the first notable occurrence of image macros."], ["A 16\u00a0GB model was released on February 5, 2008 for $499, the original launch price of the 4\u00a0GB model.", "The iPhone was released in the United States on June 29, 2007 at the price of $499 for the 4\u00a0GB model and $599 for the 8\u00a0GB model, both requiring a 2-year contract."]]}, {"qid": "51678920a34b51e1e355", "term": "Human overpopulation", "description": "The condition where human numbers exceed the short or long-term carrying capacity of the environment", "question": "Does Rusev have to worry about human overpopulation in his homeland?", "answer": false, "facts": ["Human overpopulation results from the birthrate exceeding the death rate in a country.", "Rusev is a professional wrestler who was born in Bulgaria.", "The population of Bulgaria decreased by .7% in 2018."], "decomposition": ["Who is Rusev?", "What is the homeland of #1?", "Is #2 overpopulated?"], "evidence": [[[["Rusev (wrestler)-1"]], [["Rusev (wrestler)-3"]], [["Population decline-50"], "operation"]], [[["Rusev (wrestler)-2"]], [["Rusev (wrestler)-3"]], [["Plovdiv-42"]]], [[["Rusev (wrestler)-1"]], [["Rusev (wrestler)-3"]], [["Demographics of Bulgaria-4"]]]], "golden_sentence": [["Miroslav Barnyashev (Bulgarian: \u041c\u0438\u0440\u043e\u0441\u043b\u0430\u0432 \u0411\u0430\u0440\u043d\u044f\u0448\u0435\u0432, [miro\u02c8sl\u0251f b\u0251r\u02c8nj\u0251\u0283\u025bf]; born December 25, 1984) is a Bulgarian-American professional wrestler best known for his time with WWE, where he performed under the ring name Rusev (Bulgarian: \u0420\u0443\u0441\u0435\u0432)."], ["Miroslav Barnyashev was born on December 25, 1984, in Plovdiv, which was then part of the People's Republic of Bulgaria."], ["In the context of a stable or declining population, increasing workforce productivity is better than mostly short-term efforts to increase the size of the workforce."]]}, {"qid": "ebd53fd053c84d26f889", "term": "Peach", "description": "species of fruit tree (for the fruit use Q13411121)", "question": "Does Princess Peach's dress resemble a peach fruit?", "answer": false, "facts": ["Peaches have fuzzy red, orange, and yellow skin.", "Princess Peach is a character in the Nintendo Mario Universe.", "Princess Peach's dress is pink and floor length."], "decomposition": ["What color is a peach?", "What color is Princess Peach normally seen in?", "What shape is a peach?", "What shape is princess peach?", "Is #1 the same as #2 or is #3 the same as #4?"], "evidence": [[[["Peach (fruit)-5"], "no_evidence"], [["Princess Peach-3"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Peach (fruit)-3"]], [["Princess Peach-3"]], [["Peach (fruit)-3"], "no_evidence"], [["Princess Peach-3"]], ["operation"]], [[["Peach-23"]], [["Princess Peach-3"]], [["Peach-9"], "no_evidence"], [["Princess Peach-3"]], ["operation"]]], "golden_sentence": [["Peach breeding has favored cultivars with more firmness, more red color, and shorter fuzz on the fruit surface."], ["Princess Peach has long, blonde hair (except in Super Mario Bros. 2 and Super Mario Bros. 3, where she has brown hair), blue eyes, tall frame, an hourglass figure, and a rosy complexion.", "She generally wears a pink dress with a ruffled hemline, short puffy sleeves, a frilled collar, and a pannier-style overskirt."]]}, {"qid": "cbebe1a0113581f37141", "term": "United States Air Force", "description": "Air and space warfare branch of the United States Armed Forces", "question": "Are psychiatric patients welcome to join the United States Air Force?", "answer": false, "facts": ["Having a history of mental illness disqualifies most people from joining the Armed Forces.", "Psychiatric patients are being seen for management of mental illness."], "decomposition": ["What do psychiatric patients suffer from?", "Would having #1 disqualify someone from joining the United States Air Force?"], "evidence": [[[["Mental disorder-3"]], ["no_evidence", "operation"]], [[["Psychiatry-1", "Psychiatry-3"]], [["United States Air Force Fitness Assessment-1"], "no_evidence", "operation"]], [[["Mental disorder-1"]], ["no_evidence"]]], "golden_sentence": [["Services are based in psychiatric hospitals or in the community, and assessments are carried out by mental health professionals such as psychiatrists, psychologists, psychiatric nurses and clinical social workers, using various methods such as psychometric tests but often relying on observation and questioning."]]}, {"qid": "badd24672a2f951706fe", "term": "Bing (search engine)", "description": "Web search engine from Microsoft", "question": "Can I hold Bing in a basket?", "answer": false, "facts": ["Bing is a search engine, which is a digital object.", "A basket is a physical object.", "Physical objects cannot hold digital objects."], "decomposition": ["What is Bing?", "What kind of product is #1?", "What kind of object is a basket?", "Can #3 hold #2?"], "evidence": [[[["Bing (search engine)-1"]], [["Web search engine-1"]], [["Basket-1"]], ["operation"]], [[["Bing (search engine)-1"]], [["Web search engine-1"]], [["Basket-1"]], ["operation"]], [[["Bing (search engine)-1"]], [["Bing (search engine)-1"]], [["Basket-1"]], ["operation"]]], "golden_sentence": [["Bing is a web search engine owned and operated by Microsoft."], ["A web search engine or Internet search engine is a software system that is designed to carry out web search (Internet search), which means to search the World Wide Web in a systematic way for particular information specified in a textual web search query."], ["A basket is a container that is traditionally constructed from stiff fibers and can be made from a range of materials, including wood splints, runners, and cane."]]}, {"qid": "e5ffcc7b22a58df8952d", "term": "Central processing unit", "description": "Central component of any computer system which executes input/output, arithmetical, and logical operations", "question": "Does the central processing unit usually have a dedicated fan?", "answer": true, "facts": ["The CPU is the main chip on a computer's board, and generates a lot of heat.", "Computer manufacturers generally include a dedicated cooling system over the CPU in addition to the main board fans."], "decomposition": ["What do CPUs generate as they work over time?", "Do manufacturers incorporate fans specifically for removing #1 into computer systems?"], "evidence": [[[["Central processing unit-53"]], ["no_evidence", "operation"]], [[["CPU core voltage-14"]], [["Computer fan-7"]]], [[["Central processing unit-46"]], [["Computer cooling-15"]]]], "golden_sentence": [["CPUs with larger word sizes require more circuitry and consequently are physically larger, cost more and consume more power (and therefore generate more heat)."]]}, {"qid": "58f7df5e3836b24b08d0", "term": "NATO", "description": "Intergovernmental military alliance of Western states", "question": "Can Cyril Ramaphosa become Secretary General of NATO?", "answer": false, "facts": ["Cyril Ramaphosa is the President of South Africa", "The Secretary General of NATO comes from one of NATO's member countries", "South Africa is not a member of NATO"], "decomposition": ["What country is Cyril Ramaphosa from?", "What are the requirements for someone to hold office in NATO?", "What countries meet the citizenship requirements of #2?", "Is #1 included in #3?"], "evidence": [[[["Cyril Ramaphosa-1"]], [["Secretary General of NATO-13", "Secretary General of NATO-14"]], [["Enlargement of NATO-2"]], ["operation"]], [[["Cyril Ramaphosa-1"]], [["NATO-32"]], [["NATO-32"]], ["operation"]], [[["Cyril Ramaphosa-1"]], ["no_evidence"], [["NATO-2"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["Matamela Cyril Ramaphosa (born 17 November 1952) is a South African politician and the fifth and current President of South Africa.", "Ramaphosa is the former Chairman of the National Planning Commission, which is responsible for strategic planning for the future of the country, with the goal of rallying South Africa \"around a common set of objectives and priorities to drive development over the longer term\"."], ["The NATO Command Structure (NCS), consisting of two strategic commands directed by the North Atlantic Council (NAC): Liaison:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Provides advice and support to the NAC There is no formal process for selecting the secretary general.", "However, there is nothing in NATO's charter that would preclude a Canadian or American from becoming the secretary general."], ["After its formation in 1949 with twelve founding members, NATO grew by including Greece and Turkey in 1952 and West Germany in 1955, and then later Spain in 1982."]]}, {"qid": "e144fef6c590823af46a", "term": "Brooklyn", "description": "Borough in New York City and county in New York state, United States", "question": "Is Brooklyn known for its bread products?", "answer": true, "facts": ["Brooklyn and NYC bagels are known around the world for being high quality.", "Brooklyn pizza is regarded as the best in the country. "], "decomposition": ["What food items from Brooklyn are known around the world for being high quality?", "What food item from Brooklyn is known as the best in the country?", "Are any items from #1 or #2 bread products?"], "evidence": [[[["Bagel-31"]], [["Bagel-21"]], ["operation"]], [[["New York City-137"], "no_evidence"], [["Brooklyn-68"], "no_evidence"], ["no_evidence", "operation"]], [[["Neapolitan cuisine-45"], "no_evidence"], [["Pizza-1"], "no_evidence"], [["Pizza-6"], "operation"]]], "golden_sentence": [["A flat bagel, known as a 'flagel', can be found in a few locations in and around New York City, Long Island, and Toronto."], ["There is a local belief that New York bagels are the best due to the quality of the local water."]]}, {"qid": "8d95e7d922024a684ac0", "term": "Royal Air Force", "description": "Aerial warfare service branch of the British Armed Forces", "question": "Did the Royal Air Force fight in the Boxer Rebellion?", "answer": false, "facts": ["The Boxer Rebellion took place from 1899\u20131901", "The Royal Air Force was formed on 1 April 1918"], "decomposition": ["When was the Royal Air Force formed?", "In what year did the Boxer Rebellion end?", "Is #1 before #2?"], "evidence": [[[["Royal Air Force-1"]], [["Boxer Rebellion-1"]], ["operation"]], [[["Royal Air Force-1"]], [["Boxer Rebellion-1"]], ["operation"]], [[["Royal Air Force-1"]], [["Boxer Rebellion-1"]], ["operation"]]], "golden_sentence": [["It was formed towards the end of the First World War on 1 April 1918."], ["The Boxer Rebellion (\u62f3\u4e82), Boxer Uprising, or Yihetuan Movement (\u7fa9\u548c\u5718\u904b\u52d5) was an anti-imperialist, anti-foreign, and anti-Christian uprising in China between 1899 and 1901, toward the end of the Qing dynasty."]]}, {"qid": "427fdafa9e7047587d75", "term": "Fran\u00e7ois Mitterrand", "description": "21st President of the French Republic", "question": "Did Fran\u00e7ois Mitterrand serve under Napoleon Bonapart in the French army?", "answer": false, "facts": ["Fran\u00e7ois Mitterrand was born in 1916.", "Napoleon Bonapart died in 1821."], "decomposition": ["When was Fran\u00e7ois Mitterrand born?", "When did Napoleon Bonapart die?", "Is #1 before #2?"], "evidence": [[[["Fran\u00e7ois Mitterrand-1"]], [["Napoleon-1"]], ["operation"]], [[["Fran\u00e7ois Mitterrand-1"]], [["Napoleon-121"]], ["operation"]], [[["Fran\u00e7ois Mitterrand-1"]], [["Napoleon-1"]], ["operation"]]], "golden_sentence": [["Fran\u00e7ois Maurice Adrien Marie Mitterrand (26 October 1916 \u2013 8 January 1996) was a French statesman who served as President of France from 1981 to 1995, the longest time in office in the history of France."], ["Napoleon Bonaparte (born Napoleone di Buonaparte (Italian:\u00a0[napole\u02c8o\u02d0ne di \u02ccbw\u0254na\u02c8parte]; Corsican: Napulione Buonaparte; French: Napol\u00e9on Bonaparte [nap\u0254le\u0254\u0303 b\u0254napa\u0281t]; 15 August 1769 \u2013 5 May 1821) was a French statesman and military leader who rose to prominence during the French Revolution and led several successful campaigns during the French Revolutionary Wars."]]}, {"qid": "2025983d427a9d3d5bab", "term": "Cancer", "description": "group of diseases", "question": "Can amoebas get cancer?", "answer": false, "facts": ["An amoeba is a single-celled organism.", "Cancer is the improper growth of a mass of cellular tissue, made of many incorrectly formed cells."], "decomposition": ["What is cancer the growth of?", "Does an amoeba have #1?"], "evidence": [[[["Cancer-1"]], [["Amoeba-1"], "no_evidence", "operation"]], [[["Cancer-1"]], [["Amoeba-1"], "operation"]], [[["Cancer-1"]], [["Amoeba-1"], "operation"]]], "golden_sentence": [["Cancer is a group of diseases involving abnormal cell growth with the potential to invade or spread to other parts of the body."], ["An amoeba (/\u0259\u02c8mi\u02d0b\u0259/; rarely spelt am\u0153ba; plural am(o)ebas or am(o)ebae /\u0259\u02c8mi\u02d0bi/), often called an amoeboid, is a type of cell or unicellular organism which has the ability to alter its shape, primarily by extending and retracting pseudopods."]]}, {"qid": "0edac4af92465027fe27", "term": "Cholera", "description": "Bacterial infection of the small intestine", "question": "Is Cholera alive?", "answer": true, "facts": ["Cholera are a type of bacteria.", "Bacteria are considered living creatures."], "decomposition": ["Is cholera a bacteria?", "Are bacteria considered to be living?", "Are the answers to #1 and #2 the same?"], "evidence": [[[["Cholera-1"]], [["Bacteria-1"]], ["operation"]], [[["Cholera-1"]], [["Bacteria-1"]], ["operation"]], [[["Vibrio cholerae-6"]], [["Evolution of bacteria-5"]], ["operation"]]], "golden_sentence": [["Cholera is an infection of the small intestine by some strains of the bacterium Vibrio cholerae."], ["Bacteria were among the first life forms to appear on Earth, and are present in most of its habitats."]]}, {"qid": "520becb10b5c138ab300", "term": "Sweet potato", "description": "species of plant", "question": "Would someone typically confuse a sweet potato with a pineapple?", "answer": false, "facts": ["Sweet potatoes have a smooth skin and are orange in color.", "Pineapples have a short, stocky stem with tough, waxy leaves and the fruit is yellow in color."], "decomposition": ["What are the visual characteristics of a sweet potato?", "What are the visual characteristics of a pineapple?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Sweet potato-2"]], [["Pineapple-3"]], ["operation"]], [[["Sweet potato-27"]], [["Pineapple-35"]], ["operation"]], [[["Sweet potato-2"]], [["Pineapple-27"]], ["operation"]]], "golden_sentence": [["The plant is a herbaceous perennial vine, bearing alternate heart-shaped or palmately lobed leaves and medium-sized sympetalous flowers."], ["It has 30 or more long, narrow, fleshy, trough-shaped leaves with sharp spines along the margins that are 30 to 100\u00a0cm (1.0 to 3.3\u00a0ft) long, surrounding a thick stem."]]}, {"qid": "8757a53800192e066503", "term": "Miami", "description": "City in Florida, United States", "question": "Would it be common to find a penguin in Miami?", "answer": false, "facts": ["Penguins are native to the deep, very cold parts of the southern hemisphere.", "Miami is located in the northern hemisphere and has a very warm climate."], "decomposition": ["Where is a typical penguin's natural habitat?", "What conditions make #1 suitable for penguins?", "Are all of #2 present in Miami?"], "evidence": [[[["Penguin-2", "Penguin-48", "Penguin-50"]], [["Penguin-48"]], [["Miami-20"], "operation"]], [[["Chinstrap penguin-5", "Penguin-48"]], [["Penguin-48"]], [["Miami-20", "Miami-22"]]], [[["Penguin-1"]], [["Penguin-2"]], [["Miami-20"], "operation"]]], "golden_sentence": [["Although almost all penguin species are native to the Southern Hemisphere, they are not found only in cold climates, such as Antarctica.", "Although almost all penguin species are native to the Southern Hemisphere, they are not found only in cold climates, such as Antarctica.", "Major populations of penguins are found in Angola, Antarctica, Argentina, Australia, Chile, Namibia, New Zealand, and South Africa."], ["Several species live in the temperate zone; one, the Gal\u00e1pagos penguin, lives as far north as the Gal\u00e1pagos Islands, but this is only made possible by the cold, rich waters of the Antarctic Humboldt Current that flows around these islands."], ["The city's sea-level elevation, coastal location, position just above the Tropic of Cancer, and proximity to the Gulf Stream shape its climate."]]}, {"qid": "4330d46b6f594ad122a6", "term": "Lymph node", "description": "organ of the lymphatic system", "question": "Are tumors in the lymph nodes ignorable?", "answer": false, "facts": ["Lymphoma is a serious type of cancer that can begin with tumors in the lymph nodes.", "Lymphoma can kill when left untreated."], "decomposition": ["What are the threats posed by tumors in the lymph nodes?", "Is it safe for a person's health to ignore #1?"], "evidence": [[[["Lymph node-25"]], [["Lymph node-27"]]], [[["Lymph node-25"]], [["Hodgkin lymphoma-6"]]], [[["Lymph node-25", "Lymph node-3"], "no_evidence"], ["operation"]]], "golden_sentence": [["Rarely, depending on location, lymph node enlargement may cause problems such as difficulty breathing, or compression of a blood vessel (for example, superior vena cava obstruction)."], ["In addition to a medical exam by a medical practitioner, medical tests may include blood tests and scans may be needed to further examine the cause."]]}, {"qid": "a1a131e5a540d8eff3c4", "term": "Spider-Man", "description": "Fictional Marvel superhero", "question": "Did Spiderman fight against Falcon in the MCU?", "answer": true, "facts": ["In Captain America: Civil War, Iron Man and Captain America became enemies following a disagreement.", "Iron Man summoned Spiderman to fight with his team of still-loyal Avengers.", "Falcon was one of Captain America's best friends and supported the Captain in the conflict.", "Therefore, Spiderman and Falcon were on opposite teams during the inter-Avenger battle in the movie."], "decomposition": ["In the marvel movie Captain America: Civil War, which factions were the avengers divided into?", "Were Spiderman and Falcon on opposing sides of #1?"], "evidence": [[[["Captain America: Civil War-1"]], ["no_evidence"]], [[["Captain America: The Winter Soldier-1"]], [["Peter Parker (Marvel Cinematic Universe)-7", "The Falcon and the Winter Soldier-5"], "operation"]], [[["Captain America: Civil War-1"]], [["Falcon (comics)-38", "Spider-Man-27"]]]], "golden_sentence": [["In Captain America: Civil War, disagreement over international oversight of the Avengers fractures the team into opposing factions\u2014one led by Steve Rogers and the other by Tony Stark."]]}, {"qid": "f85416430e1ab2d6f96b", "term": "Shiva", "description": "One of the principal deities of Hinduism.", "question": "Is Shiva's divine dance an ancient physical fitness pose?", "answer": false, "facts": ["In yoga as exercise, the pose called Natarajasara represents Shiva's divine dance", "This pose is new, originating in the early 20th century", "Exercise is an activity that maintains physical fitness"], "decomposition": ["Which yoga pose is referred to as Shiva's divine dance?", "When did #1 originate?", "Is #2 so long ago as to be considered ancient?"], "evidence": [[[["Natarajasana-1"]], [["Nataraja-25"]], [["Ancient history-2"], "operation"]], [[["Natarajasana-1"]], [["Shri Yogendra-1"]], [["Ancient history-2"], "operation"]], [[["Natarajasana-1"]], [["Natarajasana-4"]], ["operation"]]], "golden_sentence": [["Natarajasana (Sanskrit: \u0928\u091f\u0930\u093e\u091c\u093e\u0938\u0928; IAST: Na\u1e6dar\u0101j\u0101sana), Lord of the Dance Pose or Dancer Pose is a standing, balancing, back-bending asana in modern yoga as exercise."], ["6th/7th century Nataraja in Cave 1 of Badami cave temples A damaged 6th-century Nataraja, Elephanta Caves 6th-century Nataraja in Cave 21, Ellora Caves 8th-century Nataraja in Kailasa temple (Cave 16), Ellora Caves 8th-century sandstone Nataraja from Madhya Pradesh Sukanasa with Shiva Nataraja in Pattadakal Shiva Nataraja, mid-10th Century AD, British Museum Shiva-Nataraja in the Thousand-Pillar-Hall of Meenakshi Temple in Madurai, Tamil Nadu, India In the Shiva temple of Melakadambur is a rare Pala image that shows the ten-armed Nataraja dancing on his bull."], ["Ancient history covers all continents inhabited by humans in the period 3000 BC \u2013 AD 500."]]}, {"qid": "042463e9ca7cd4c7eb5a", "term": "Hyena", "description": "family of mammal", "question": "Do hyenas appear in a Broadway musical?", "answer": true, "facts": ["Scar is the evil lion in Disney's Lion King.", "Scar's minions are a group of hyenas.", "There is a Broadway stage version of Lion King."], "decomposition": ["Who is the main antagonist in Disney's Lion King?", "Which animals were #1's minions?", "Has the Lion King been adapted into a Broadway musical and are #2 hyenas?"], "evidence": [[[["Scar (The Lion King)-1"]], [["Scar (The Lion King)-17"]], [["The Lion King (musical)-2"], "operation"]], [[["Scar (The Lion King)-1"]], [["Scar (The Lion King)-1"]], [["The Lion King (musical)-1"], "operation"]], [[["Scar (The Lion King)-1"]], [["Scar (The Lion King)-3"]], [["Scar (The Lion King)-3", "The Lion King (musical)-2"]]]], "golden_sentence": [["Scar is an animated character who appears as the main antagonist in Disney's The Lion King franchise."], ["Cleverly trapping Simba in a vast gorge, Scar signals his hyena minions, Shenzi, Banzai and Ed, to trigger a wildebeest stampede."], ["The musical debuted on July 8, 1997 in Minneapolis, Minnesota at the Orpheum Theatre and was successful before premiering on Broadway at the New Amsterdam Theatre on October 15, 1997 in previews, with the official opening on November 13, 1997."]]}, {"qid": "9fa4b205aaca877a15bf", "term": "Strawberry", "description": "edible fruit", "question": "Would an owl monkey enjoy a strawberry?", "answer": true, "facts": ["Owl monkeys are frugivores, and they prefer small, ripe fruit when available.", "Strawberries vary in size but are generally under 2 inches across and an inch in diameter.", "Strawberries are a kind of fruit."], "decomposition": ["What food group does an owl monkey's diet mainly consist of?", "Is a strawberry a #1?"], "evidence": [[[["Night monkey-8"]], [["Strawberry-1"]]], [[["Night monkey-8"]], [["Strawberry-1"]]], [[["Night monkey-1", "Night monkey-8"]], [["Strawberry-1"]]]], "golden_sentence": [["During the winter months or when food sources are reduced, night monkeys have also been observed foraging on flowers such as Tabebuia heptaphylla, however this does not represent a primary food source."], ["The garden strawberry (or simply strawberry; Fragaria \u00d7 ananassa) is a widely grown hybrid species of the genus Fragaria, collectively known as the strawberries, which are cultivated worldwide for their fruit."]]}, {"qid": "34198157c2dd7028f0a4", "term": "Snake", "description": "limbless, scaly, elongate reptile", "question": "Can a snake swallow an M60 Patton?", "answer": false, "facts": ["An M60 Patton is an army tank that weighs several tons.", "One of the largest animals a snake ate was an impala that weighed 130 pounds."], "decomposition": ["What is the largest animal that a snack has ever swallowed?", "How much does #1 weigh?", "How much does a M60 Patton weigh?", "Is #3 less than #2?"], "evidence": [[[["Reticulated python-26", "Reticulated python-27"]], [["Reticulated python-22"]], [["M60 tank-64"]], ["operation"]], [[["African rock python-2"], "no_evidence"], [["Antelope-12", "Crocodile-9"], "no_evidence"], [["M60 tank-64"]], ["operation"]], [[["Snake-1"], "no_evidence"], ["no_evidence"], [["M60 tank-64"]], ["operation"]]], "golden_sentence": [["Considering the known maximum prey size, a full-grown reticulated python can open its jaws wide enough to swallow a human, but the width of the shoulders of some adult Homo sapiens can pose a problem for even a snake with sufficient size.", "This was the first fully confirmed case of a person being eaten by a python."], ["Small specimens up to 3\u20134\u00a0m (9.8\u201313.1\u00a0ft) long eat mainly rodents such as rats, whereas larger individuals switch to prey such as small Indian civet and binturong, primates, and pigs weighing more than 60\u00a0kg (130\u00a0lb)."], ["These changes increased the vehicle weight to 62-63 tons."]]}, {"qid": "9c13ff296c299f0cd02d", "term": "DC Comics", "description": "U.S. comic book publisher", "question": "Would Avengers Comics be out of place in a DC Comics store?", "answer": true, "facts": ["The Avengers are a comic produced by Marvel.", "Marvel and DC are rival companies, each having their own line of products and merchandise. "], "decomposition": ["Who produces the Avengers Comics?", "Are #1 and DC Comics rival companies?"], "evidence": [[[["Marvel Avengers Alliance-15"]], [["DC vs. Marvel-7"]]], [[["Avengers (comics)-1"]], [["DC Comics-18", "Marvel Comics-17"], "operation"]], [[["Avengers (comics)-1"]], [["Marvel Comics-25"]]]], "golden_sentence": [["A related game to Marvel: Avengers Alliance was called Marvel: Avengers Alliance Tactics, which Playdom made for Facebook."], ["The Flash (DC) vs. Quicksilver (Marvel)."]]}, {"qid": "ed04a34363f248900c18", "term": "Persian Gulf", "description": "An arm of the Indian Ocean in western Asia", "question": "Can the Persian Gulf fit in New Jersey?", "answer": false, "facts": ["The Persian Gulf has an area of 96,912 square miles.", "New Jersey has a land area of 7,417 square miles."], "decomposition": ["How much area does the Persian Gulf cover?", "How much area does New Jersey cover?", "Is #2 greater than #1?"], "evidence": [[[["Persian Gulf-6"]], [["New Jersey-1"]], ["operation"]], [[["Persian Gulf-6"]], [["New Jersey-1"]], ["operation"]], [[["Persian Gulf-6"]], [["New Jersey-1"]], ["operation"]]], "golden_sentence": [["This inland sea of some 251,000 square kilometres (96,912\u00a0sq\u00a0mi) is connected to the Gulf of Oman in the east by the Strait of Hormuz; and its western end is marked by the major river delta of the Shatt al-Arab, which carries the waters of the Euphrates and the Tigris."], ["New Jersey is the fourth-smallest state by area but the 11th-most populous, with 8,882,190 residents as of 2019 and an area of 8,722.58 square miles, making it the most densely populated of the 50 U.S. states, with its biggest city being Newark."]]}, {"qid": "cda79ce499af9dae8ffb", "term": "Nicole Kidman", "description": "Australian-American actress and film producer", "question": "Is Nicole Kidman ideal choice to play Psylocke based on height and weight?", "answer": true, "facts": ["Psylocke is a Marvel super hero whose real name is Betsy Braddock.", "Betsy Braddock is 5'11 and 155 lbs.", "Actress Nicole Kidman is 5'11 and weighs 137 lbs.", "Actresses gain weight all the time for roles, such as Charlize Theron who gained 30 pounds for the movie Monster."], "decomposition": ["What is Psylocke's height?", "What is Psylocke's wieght?", "Does Nicole Kidman have similar attributes as #1 and #2?"], "evidence": [[[["Psylocke-2"], "no_evidence"], ["no_evidence"], [["Nicole Kidman-1"], "no_evidence", "operation"]], [[["Psylocke-2"], "no_evidence"], [["Psylocke-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Psylocke-4"], "no_evidence"], [["Psylocke-4"], "no_evidence"], [["Model (person)-19", "Model (person)-20", "Nicole Kidman-1"], "no_evidence", "operation"]]], "golden_sentence": [["Betsy Braddock was initially a supporting character in the adventures of her twin brother, Captain Britain, even briefly substituting for him in the role, before becoming the mutant superheroine and X-Men member Psylocke in 1986."], ["Nicole Mary Kidman AC (born 20 June 1967) is an Australian-American actress and producer."]]}, {"qid": "2ef10335771662b59cf8", "term": "Metropolitan Museum of Art", "description": "Art museum in New York City, New York", "question": "Could Bernie Sanders visit the Metropolitan Museum of Art twenty times for under two hundred dollars?", "answer": false, "facts": ["Bernie Sanders is a senior citizen", "Senior citizens from outside NY, NJ, or CT must pay $17 per visit"], "decomposition": ["What age group would Bernie Sanders be classifed as?", "How much must #1 pay to enter the Metropolitan Museum of Art?", "Is seventeen times #2 less than 200? "], "evidence": [[[["Bernie Sanders-1"]], [["Metropolitan Museum of Art-61"]], [["Metropolitan Museum of Art-61"]]], [[["Bernie Sanders-1", "Discounts and allowances-33"]], [["Metropolitan Museum of Art-50"], "no_evidence"], ["operation"]], [[["Bernie Sanders-5", "Old age-12"]], [["Bernie Sanders-111", "Metropolitan Museum of Art-50"]], ["operation"]]], "golden_sentence": [["Bernard Sanders (born September\u00a08, 1941) is an American politician who has served as the junior United States Senator from Vermont since 2007 and as U.S. Representative for the state's at-large congressional district from 1991 to 2007."], ["The museum admission price as of March 2018 is $25 for out-of-state and foreign visitors, while New York state residents can pay what they wish to enter."], ["Although subject to re-assessment, a 1970 agreement between the museum and the city of New York requires New York state visitors to pay at least a nominal amount; a penny is acceptable."]]}, {"qid": "983e2713b89f38cab35a", "term": "Herpes simplex virus", "description": "Species of virus", "question": "Can Planned Parenthood tell your University that you have Herpes simplex virus?", "answer": false, "facts": ["Planned Parenthood specializes in reproductive healthcare.", "Planned Parenthood practitioners are bound by HIPAA to not disclose any patient information. "], "decomposition": ["Who works at Planned Parenthood?", "Are #1 bound by any laws in regards to patient information?", "Does #2 allow for patient information to be disclosed?"], "evidence": [[[["Clinical Research Bureau-1"]], [["Confidentiality-16", "Medical privacy-52"]], ["operation"]], [[["Planned Parenthood-2"]], ["no_evidence"], [["Planned Parenthood-36"], "no_evidence", "operation"]], [[["Planned Parenthood-2"]], [["Health Insurance Portability and Accountability Act-11", "Health Insurance Portability and Accountability Act-13"]], ["operation"]]], "golden_sentence": [["Several years after a 1918 New York appeals court ruling which permitted physicians to prescribe contraceptives, Margaret Sanger decided to open a second birth control clinic, this time staffed with physicians to make it legal under the court ruling (Sanger's first clinic employed nurses, and was shut down by police soon after opening)."], ["Confidentiality is standard in the United States by HIPAA laws, specifically the Privacy Rule, and various state laws, some more rigorous than HIPAA.", "HIPAA provides a federal minimum standard for medical privacy, sets standards for uses and disclosures of protected health information (PHI), and provides civil and criminal penalties for violations."]]}, {"qid": "018cb17cb34d19be99a6", "term": "Achilles", "description": "Greek mythological hero", "question": "Would Achilles dominate Legolas in a hypothetical fight?", "answer": false, "facts": ["Achilles was a Greek hero that was killed by an arrow to the heel.", "Legolas is an elf archer from Lord of the Rings that can shoot arrows incredibly fast.", "Achilles's companions included human warriors such as Ajax and Odysseus.", "Legolas's companions include Gandalf who is a high level wizard, capable of casting many deadly spells."], "decomposition": ["What is Achilles weakspot?", "What is Legolas strength?", "Will #1 easily dominate #2"], "evidence": [[[["Achilles' heel-2"]], [["Legolas-2"]], [["Legolas-1"]]], [[["Achilles-2"]], [["Legolas-4"]], ["operation"]], [[["Achilles-2"]], [["Legolas-18"]], ["operation"]]], "golden_sentence": [["To prevent his death, his mother Thetis took Achilles to the River Styx, which was supposed to offer powers of invulnerability, and dipped his body into the water; however, as Thetis held Achilles by the heel, his heel was not washed over by the water of the magical river."], ["Commentators have noted that Legolas serves as a typical elf in the story, demonstrating more-than-human abilities such as seeing further than anyone else in Rohan and sensing the memory of a long-lost elvish civilisation in the stones of Hollin."], ["He is a Sindarin Elf of the Woodland Realm and one of the nine members of the Fellowship who set off to destroy the One Ring."]]}, {"qid": "3a76a62be2518008c701", "term": "Bucharest", "description": "Capital of Romania", "question": "Is Bucharest located south of Egypt?", "answer": false, "facts": ["Bucharest, Romania is located in Eastern Europe.", "Egypt is located in Africa.", "Most of Africa is south of Europe."], "decomposition": ["What country is Bucharest located in?", "Is #1 south of Egypt?"], "evidence": [[[["Bucharest-5"]], [["Romania-1"]]], [[["Bucharest-1"]], [["Egypt-1"], "operation"]], [[["Bucharest-1"]], ["operation"]]], "golden_sentence": [["Economically, Bucharest is the most prosperous city in Romania."], ["It borders with Bulgaria to the south, Ukraine to the north, Hungary to the west, Serbia to the southwest, and Moldova to the east and has its opening to the Black sea."]]}, {"qid": "e1f9a6b9fbba8d014643", "term": "Atmosphere of Earth", "description": "Layer of gases surrounding the planet Earth", "question": "Will a rock float in the atmosphere of Earth?", "answer": false, "facts": ["Things only float if they are less dense than the surrounding material.", "Rocks are denser than air.", "The atmosphere of Earth is made up of air."], "decomposition": ["Which substance does the earth's atmosphere contain?", "What is the average density of #1?", "What is the average density of rocks?", "Is #3 less than #2?"], "evidence": [[[["Atmosphere-14"]], [["Nitrogen-26"]], [["Sandstone-10"], "no_evidence"], ["operation"]], [[["Atmosphere of Earth-1", "Atmosphere-14"]], [["Atmosphere of Earth-9"], "no_evidence"], [["Rock (geology)-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Troposphere-5"]], [["Nitrogen-26"]], [["Granite-3"]], ["operation"]]], "golden_sentence": [["Dry air from Earth's atmosphere contains 78.08% nitrogen, 20.95% oxygen, 0.93% argon, 0.04% carbon dioxide, and traces of hydrogen, helium, and other \"noble\" gases (by volume), but generally a variable amount of water vapor is also present, on average about 1% at sea level."], ["Liquid nitrogen, a colourless fluid resembling water in appearance, but with 80.8% of the density (the density of liquid nitrogen at its boiling point is 0.808\u00a0g/mL), is a common cryogen."], ["Accessory minerals are all other mineral grains in a sandstone; commonly these minerals make up just a small percentage of the grains in a sandstone."]]}, {"qid": "49ab746264f2e50e9aee", "term": "Rhinoceros", "description": "family of mammals", "question": "Have rhinoceroses been killed to improve human sex lives?", "answer": true, "facts": ["Rhinoceros horns are used for folk treatment of sexual impotency.", "Rhinoceroses are killed to remove their horns."], "decomposition": ["Which part of the Rhinoceros do most poachers hunt and kill it for?", "What are some common traditional uses of #1?", "Is treatment of sexual impotency included in #2?"], "evidence": [[[["Rhinoceros-31"]], [["Rhinoceros-32"]], ["operation"]], [[["Rhinoceros-3"]], [["Rhinoceros-32", "Rhinoceros-34"]], ["operation"]], [[["Rhinoceros-3"]], [["Rhinoceros-32"]], [["Aphrodisiac-1"], "operation"]]], "golden_sentence": [["Domestic sale of rhinoceros horn in South Africa, home of 80% of the remaining rhino population, was banned as of 2009."], ["Rhinoceros horns are used in traditional medicines in parts of Asia, and for dagger handles in Yemen and Oman."]]}, {"qid": "a9ac24cbbb2fce862026", "term": "ABBA", "description": "Swedish pop group", "question": "Does ABBA have similar gender configuration to The Mamas & The Papas?", "answer": true, "facts": ["ABBA was a Swedish pop group composed of four members.", "The Mamas & The Papas was an American band composed of four members.", "The members of ABBA are Bj\u00f6rn Ulvaeus (male), Benny Andersson (male), Agnetha F\u00e4ltskog (female), and Anni-Frid Lyngstad (female)..", "The members of The Mamas & The Papas are John Phillips (male), Denny Doherty (male), Cass Elliot (female), and Michelle Phillips (female)."], "decomposition": ["How many men and women each make up the Mamas and the Papas?", "How many men and women each make up ABBA?", "Is #1 equal to #2?"], "evidence": [[[["The Mamas and the Papas-1"]], [["ABBA-1"]], ["operation"]], [[["The Mamas and the Papas-1"]], [["ABBA-1"]], ["operation"]], [[["The Mamas and the Papas-1"]], [["ABBA-1"]], ["operation"]]], "golden_sentence": [["The Mamas and the Papas were an American folk rock vocal group which recorded and performed from 1965 to 1968."], ["ABBA (/\u00e6\u02c8b\u0259/, Swedish pronunciation:\u00a0[\u00b2ab\u02d0a]) are a Swedish pop supergroup formed in Stockholm in 1972 by Agnetha F\u00e4ltskog, Bj\u00f6rn Ulvaeus, Benny Andersson, and Anni-Frid Lyngstad."]]}, {"qid": "e537c420c9cb2e24409c", "term": "Little Women", "description": "1860s novel by Louisa May Alcott", "question": "Would the author of Little Women have remembered the ratification of the 13th Amendment?", "answer": true, "facts": ["The 13th Amendment was ratified in 1865.", "Louisa May Alcott died in 1888."], "decomposition": ["When was the 13th Amendment ratified?", "Who wrote Little Women?", "What years was #2 alive?", "Did #1 occur sometime during #3?"], "evidence": [[[["Thirteenth Amendment to the United States Constitution-1"]], [["Little Women-1"]], [["Louisa May Alcott-1"]], ["operation"]], [[["Thirteenth Amendment to the United States Constitution-1"]], [["Little Women-1"]], [["Little Women-1"]], ["operation"]], [[["Thirteenth Amendment to the United States Constitution-1"]], [["Little Women-1"]], [["Little Women-1"]], ["operation"]]], "golden_sentence": [["The amendment was ratified by the required number of states on December 6, 1865."], ["Little Women is a novel by American author Louisa May Alcott (1832\u20131888) which was originally published in two volumes in 1868 and 1869."], ["Louisa May Alcott (/\u02c8\u0254\u02d0lk\u0259t, -k\u0252t/; November 29, 1832\u00a0\u2013 March 6, 1888) was an American novelist, short story writer and poet best known as the author of the novel Little Women (1868) and its sequels Little Men (1871) and Jo's Boys (1886)."]]}, {"qid": "c42d951f2b8339998c71", "term": "Reddit", "description": "Online news aggregator", "question": "Are the majority of Reddit users familiar with the Pledge of Allegiance?", "answer": true, "facts": ["55% of the Reddit user base comes from the United States.", "Congressional sessions open with the recital of the Pledge, as do many government meetings at local levels, and meetings held by many private organizations.", "All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools."], "decomposition": ["What country do most Reddit users come from?", "What country is the Pledge of Allegiance associated with?", "Is #1 the same as #2?"], "evidence": [[[["Reddit-2"]], [["Pledge of Allegiance-1"]], ["operation"]], [[["Reddit-2"]], [["Pledge of Allegiance-1"]], ["operation"]], [[["Reddit-2"]], [["Pledge of Allegiance-1"]], ["operation"]]], "golden_sentence": [["13 in the world, according to Alexa Internet, with 55% of its user base coming from the United States, followed by the United Kingdom at 7.4% and Canada at 5.8%."], ["The Pledge of Allegiance of the United States is an expression of allegiance to the flag of the United States and the republic of the United States of America."]]}, {"qid": "c4f5cedc6af621e44eb5", "term": "South Pole", "description": "Southern point where the Earth's axis of rotation intersects its surface", "question": "Do children send their Christmas letters to the South Pole?", "answer": false, "facts": ["Children send Christmas letters to Santa Claus.", "Santa Claus is fabled to live in the North Pole."], "decomposition": ["Who do children send their Christmas letters to?", "Does #1 supposedly live in the South Pole?"], "evidence": [[[["North Pole-61", "Santa's workshop-9"]], ["operation"]], [[["Santa Claus-55"]], [["North Pole-61"], "operation"]], [[["Santa Claus-55"]], [["Santa Claus-3"]]]], "golden_sentence": [["In some children's Western cultures, the geographic North Pole is described as the location of Santa Claus' workshop and residence, although the depictions have been inconsistent between the geographic and magnetic North Pole.", "The United States Postal Service recommends mail to Santa's workshop be sent to Santa Claus 1225 Reindeer Rd."]]}, {"qid": "6a0d8d74c097292a5d38", "term": "Maroon 5", "description": "American pop punk band", "question": "Did Maroon 5 go on tour with Nirvana?", "answer": false, "facts": ["Maroon 5 formed in 2001.", "Nirvana's final performances were in 1994."], "decomposition": ["When was Maroon 5 formed?", "What span of years was the rock band Nirvana active?", "Is #1 before or within #2?"], "evidence": [[[["Maroon 5-1"]], [["Nirvana (band)-1", "Nirvana (band)-3"]], ["operation"]], [[["Maroon 5-1"]], [["Nirvana (band)-1", "Nirvana (band)-21"]], ["operation"]], [[["Maroon 5-1"]], [["Nirvana (band)-1", "Nirvana (band)-3"]], ["operation"]]], "golden_sentence": [["In 2001, the band re-emerged as Maroon 5, pursuing a different direction and adding guitarist Valentine."], ["Nirvana was an American rock band formed in Aberdeen, Washington, in 1987.", "Nirvana disbanded following Cobain's death in April 1994."]]}, {"qid": "79535eed1af03ca748c5", "term": "Evander Holyfield", "description": "American boxer", "question": "Would an Evander Holyfield 2020 boxing return set age record?", "answer": false, "facts": ["Evander Holyfield will turn 58 years old at the end of 2020.", "Steve Ward holds the world's oldest boxer title at age 59."], "decomposition": ["How old will Evander Holyfield be at the end of 2020?", "What is the oldest age a boxer won a title bout?", "Is #1 greater than #2?"], "evidence": [[[["Evander Holyfield-1"]], [["Steve Ward (boxer)-1"]], ["operation"]], [[["Evander Holyfield-1"]], [["Bernard Hopkins-3"]], ["operation"]], [[["Evander Holyfield-7"]], [["Steve Ward (boxer)-1"]], ["operation"]]], "golden_sentence": [["Evander Holyfield (born October 19, 1962) is an American former professional boxer who competed from 1984 to 2011."], ["He lost the distinction in 2015, when an older fighter competed in a professional bout, but regained it later that year when he fought professionally at 59."]]}, {"qid": "f2a71092d2cfe16d9a64", "term": "Post Malone", "description": "American singer, rapper, songwriter, and record producer", "question": "Does Post Malone have a fear of needles?", "answer": false, "facts": ["Post Malone's body is covered with many tattoos.", "The most common method of tattooing in modern times is the electric tattoo machine, which inserts ink into the skin via a single needle or a group of needles that are soldered onto a bar, which is attached to an oscillating unit."], "decomposition": ["What is Post Malone known for having on his body and face?", "Does getting #1 not involve the use of needles?"], "evidence": [[[["Post Malone-27"]], [["Tattoo-49"]]], [[["Post Malone-27"]], [["Tattoo-51"], "operation"]], [[["Post Malone-27"]], [["Tattoo-51"]]]], "golden_sentence": [["He has tattoos on his hands and fingers of artists who have influenced him.", "The face of deceased rapper Lil Peep is tattooed on his arm."], ["In modern tattooing, an artist may use a Thermal stencil paper or Hectograph to first place the design print on the skin before working with the machine and needle on skin."]]}, {"qid": "088eb1d9e2f067cd4f36", "term": "Spanish\u2013American War", "description": "Conflict in 1898 between Spain and the United States", "question": "Did US President during Spanish-American War suffer similar demise to Abraham Lincoln?", "answer": true, "facts": ["The Spanish-American War lasted from April 21, 1898 to August 13, 1898.", "William McKinley was President of the United States from March 4, 1897 to September 14, 1901.", "William McKinley died from gun related injuries after an assassination attempt.", "Abraham Lincoln died shortly after being shot by John Wilkes Booth."], "decomposition": ["What years were the Spanish\u2013American War?", "Who was the US President during #1?", "How was #2 killed?", "How was Abraham Lincoln killed?", "Is #3 the same as #4?"], "evidence": [[[["Spanish\u2013American War-1"]], [["Spanish\u2013American War-2"]], [["William McKinley-1"]], [["Abraham Lincoln-4"]], ["operation"]], [[["Spanish\u2013American War-1"]], [["Spanish\u2013American War-2"]], [["William McKinley-1"]], [["Maryland in the American Civil War-55"]], ["operation"]], [[["Spanish\u2013American War-1"]], [["William McKinley-1"]], [["Assassination of William McKinley-1"]], [["Assassination of Abraham Lincoln-2"]], ["operation"]]], "golden_sentence": [["The Spanish\u2013American War (Spanish: Guerra Hispano-Americana; Filipino: Digmaang Espanyol-Amerikano) was an armed conflict between Spain and the United States in 1898."], ["President William McKinley ignored the exaggerated yellow press and sought a peaceful settlement."], ["William McKinley (born William McKinley Jr., January 29, 1843 \u2013 September 14, 1901) was the 25th president of the United States from 1897, until his assassination in 1901."], ["On April 14, 1865, just days after the war's end at Appomattox, he was enjoying a night at the theatre with his wife Mary when he was assassinated by Confederate sympathizer John Wilkes Booth."]]}, {"qid": "2fcd999dfde755c5c049", "term": "Eve", "description": "Biblical figure", "question": "Was Eve involved in an incestuous relationship?", "answer": true, "facts": ["God made Eve from a bone he removed from Adam.", "Since Eve was made from Adam, they would have had similar DNA and been considered twins or at least siblings.", "As the only humans at the time, they ended up starting a family together."], "decomposition": ["Who did Eve have intercourse with?", "How was Eve related to #1?", "Can it be concluded that they are family based on #2?"], "evidence": [[[["Incest-18"]], [["Incest-18"]], ["operation"]], [[["Eve-13"]], [["Eve-2"]], ["operation"]], [[["Adam and Eve-2"]], [["Adam and Eve-2"]], [["Adam and Eve-2"]]]], "golden_sentence": [["During this period, there was no other woman except Eve or there was an unnamed sister and so this meant Cain had incestuous relationship with his mother or his sister."], ["During this period, there was no other woman except Eve or there was an unnamed sister and so this meant Cain had incestuous relationship with his mother or his sister."]]}, {"qid": "9a6e08a0978b9dbc8f1d", "term": "Lil Wayne", "description": "American rapper, record executive and actor from Louisiana", "question": "Lil Wayne similar real name rapper has over quadruple Wayne's Grammy awards?", "answer": true, "facts": ["Lil Wayne was born Dwayne Michael Carter.", "Jay-Z was born Shawn Corey Carter.", "Lil Wayne has won 5 Grammy awards.", "Jay-Z has won 22 Grammy awards."], "decomposition": ["What is Lil Wayne's real name?", "What rapper has a real name that is similar to #1?", "How many Grammy awards does Lil Wayne have?", "How many Grammy awards does #2 have?", "Is #4 divided by #3 greater than 4?"], "evidence": [[[["Lil Wayne-1"]], [["Jay-Z-1"]], [["Lil Wayne-4"]], [["Jay-Z-4"]], ["operation"]], [[["Lil Wayne-1"]], [["Jay-Z-1"]], [["Lil Wayne-4"]], [["Jay-Z-4"]], ["operation"]], [[["Lil Wayne-1"]], [["Jay-Z-1"]], [["Lil Wayne-4"]], [["Jay-Z-4"]], ["operation"]]], "golden_sentence": [["Dwayne Michael Carter Jr. (born September 27, 1982), better known by his stage name Lil Wayne, is an American rapper, singer, songwriter, record executive, entrepreneur, and actor."], ["Shawn Corey Carter (born December 4, 1969), better known by his stage name Jay-Z (stylized as JAY-Z), is an American rapper, songwriter, record executive, entrepreneur, businessman, and record producer."], ["He has won five Grammy Awards, 11 BET Awards, four Billboard Music Awards, two MTV Video Music Awards and eight NAACP Image Awards."], ["He has won a total of 22 Grammy Awards, the most by a rapper, and holds the record for the most number-one albums by a solo artist on the Billboard 200, with 14."]]}, {"qid": "2e4a3ac18a5292ee1735", "term": "Nickel", "description": "Chemical element with atomic number 28", "question": "Would nickel boil in the outer core of the earth?", "answer": true, "facts": ["The boiling point of nickel is 3003 Kelvin", "The temperature of earth's outer core is 3,000\u20134,500 Kelvin"], "decomposition": ["What is the boiling point of nickel?", "What the temperature range of the earth's outer core?", "Is #1 within #2?"], "evidence": [[[["Nickel-5"], "no_evidence"], [["Nickel-4"], "no_evidence"], ["no_evidence"]], [["no_evidence"], [["Earth's outer core-3"]], ["operation"]], [["no_evidence"], [["Earth's outer core-3"]], ["operation"]]], "golden_sentence": [["Nickel is one of four elements (the others are iron, cobalt, and gadolinium) that are ferromagnetic at approximately room temperature."], ["Nickel is slowly oxidized by air at room temperature and is considered corrosion-resistant."]]}, {"qid": "4b6ca118a638ad3539c8", "term": "Porsche", "description": "automotive brand manufacturing subsidiary of Volkswagen", "question": "Was Dorothea Wendling from same place Porsche originated?", "answer": true, "facts": ["Dorothea Wendling was a singer born in Stuttgart, Germany.", "Porsche was founded in 1931 in Stuttgart, Germany."], "decomposition": ["Where was Dorothea Wendling born?", "Where was Posche founded?", "Is #1 the same as #2?"], "evidence": [[[["Dorothea Wendling-1"]], [["Porsche-2"]], ["operation"]], [[["Dorothea Wendling-1"]], [["Porsche-1"]], ["operation"]], [[["Dorothea Wendling-1"], "operation"], ["no_evidence"], ["no_evidence"]]], "golden_sentence": [["(Maria) Dorothea Wendling, n\u00e9e Spurni (21 March 1736 \u2013 20 August 1811) was a German soprano.", "Born in Stuttgart, she is remembered for being the singer for whom Mozart wrote the role of Ilia in Idomeneo, re di Creta."], ["h. c. F. Porsche GmbH\" in 1931, with main offices at Kronenstra\u00dfe 24 in the centre of Stuttgart."]]}, {"qid": "d0e463f95b1221a55a13", "term": "Surgery", "description": "Medical specialty", "question": "Can surgery prevent an existential crisis?", "answer": false, "facts": ["Surgery is used to correct medical problems or make physical alterations to the body", "An existential crisis is a metaphysical affliction"], "decomposition": ["What is an existential crisis?", "What kinds of ailments can be treated with surgery?", "Is #1 included in #2?"], "evidence": [[[["Existential crisis-1"]], [["Surgery-1"], "no_evidence"], ["operation"]], [[["Existential crisis-1"]], [["Surgery-1"]], ["operation"]], [[["Existential crisis-1"]], [["Surgery-1"]], ["operation"]]], "golden_sentence": [["Existential crises are moments when individuals question whether their lives have meaning, purpose, or value."], ["Surgery is a medical specialty that uses operative manual and instrumental techniques on a person to investigate or treat a pathological condition such as a disease or injury, to help improve bodily function or appearance or to repair unwanted ruptured areas."]]}, {"qid": "c435c8acf644ef0dde15", "term": "Al-Farabi", "description": "Philosopher in 10th century Central Asia", "question": "Was Al-Farabi a student of the Great Sheikh?", "answer": false, "facts": ["The Great Sheikh was the name for Avicenna", "Avicenna was born in 980", "Al Farabi died around 950 "], "decomposition": ["What other name was the Great Sheikh known by?", "When was #1 born?", "When did Al-Farabi die?", "Is #3 more recent than #2?"], "evidence": [[[["Zayed bin Sultan Al Nahyan-2"]], [["Zayed bin Sultan Al Nahyan-1"]], [["Al-Farabi-10"]], ["operation"]], [[["Zayed bin Khalifa Al Nahyan-1"], "no_evidence"], [["Zayed bin Khalifa Al Nahyan-1"], "no_evidence"], [["Al-Farabi-1"]], ["operation"]], [[["Zayed bin Khalifa Al Nahyan-1"]], [["Zayed bin Khalifa Al Nahyan-1"]], [["Al-Farabi-1"]], ["operation"]]], "golden_sentence": [["Zayed was the youngest of four sons of Sheikh Sultan bin Khalifa Al Nahyan.", "Sheikh Zayed was named after his grandfather, Sheikh Zayed bin Khalifa Al Nahyan (\"Zayed the Great\"), who ruled the emirate from 1855 to 1909.", "At the time of Sheikh Zayed's birth, the sheikhdom of Abu Dhabi was one of seven Trucial States along the lower coast of the Persian Gulf."], ["Sheikh Zayed bin Sultan Al Nahyan (Arabic: \u0671\u0644\u0634\u064e\u0651\u064a\u0652\u062e \u0632\u064e\u0627\u064a\u0650\u062f \u0628\u0650\u0646 \u0633\u064f\u0644\u0652\u0637\u064e\u0627\u0646 \u0622\u0644 \u0646\u064e\u0647\u0652\u064a\u064e\u0627\u0646\u200e, romanized:\u00a0Ash-Shaykh Z\u0101yed bin Sul\u1e6d\u0101n \u0100l Nahy\u0101n); 6 May 1918\u00a0\u2013 2 November 2004) was the ruler of Abu Dhabi for more than 30 years (6 August 1966\u00a0\u2013 2 November 2004)."], ["Al-Masudi, writing barely five years after the fact (955-6, the date of the composition of the Tanb\u012bh), says that Farabi died in Damascus in Rajab 339 (between 14 December 950 and 12 January 951)."]]}, {"qid": "d2ae10dfd3fa8c338d2d", "term": "Chlorine", "description": "Chemical element with atomic number 17", "question": "Is it dangerous to consume chlorine when mixed with sodium?", "answer": false, "facts": ["Chlorine mixed with sodium is sodium chloride, also known as table salt.", "Table salt is one of the most commonly consumed seasonings among all cultures."], "decomposition": ["What do you make when you mix Chlorine with sodium?", "What is another name for #1?", "Is #2 dangerous to consume?"], "evidence": [[[["Sodium chloride-13"]], [["Sodium chloride-12"]], [["Salt-5"]]], [[["Sodium chloride-22"]], [["Sodium chloride-22"]], ["operation"]], [[["Sodium chloride-1"]], [["Salt-1"]], [["Salt-2", "Salt-5"]]]], "golden_sentence": [["Sodium chloride is sometimes used as a cheap and safe desiccant because of its hygroscopic properties, making salting an effective method of food preservation historically; the salt draws water out of bacteria through osmotic pressure, keeping it from reproducing, a major source of food spoilage."], ["The salt acts to minimize the effects of shifting caused in the subsurface by changes in humidity and traffic load."], ["Excessive salt consumption may increase the risk of cardiovascular diseases, such as hypertension, in children and adults."]]}, {"qid": "b73a1bc6f2f2eb0058e8", "term": "Brazilian jiu-jitsu", "description": "martial art focusing on grappling and ground fighting, originally based on Kodokan judo newaza taught by Japanese judoka, that developed independently in Brazil from experimentation and adaptation by Carlos and H\u00e9lio Gracie, Luiz Fran\u00e7a, et al.", "question": "Did Brazilian jiu-jitsu Gracie founders have at least a baker's dozen of kids between them?", "answer": true, "facts": ["A baker's dozen refers to 13 of anything.", "Brazilian jiu-jitsu was founded by Carlos and Helio Gracie.  ", "Helio Gracie had 9 children.", "Carlos Gracie had 11 children."], "decomposition": ["Who were the founders of Brazilian jiu-jitsu?", "How many children do #1 have altogether", "What is the number represented by the baker's dozen?", "Is #2 greater than or equal to #3?"], "evidence": [[[["Brazilian jiu-jitsu-2"]], [["Carlos Gracie-12", "H\u00e9lio Gracie-25"], "operation"], [["Dozen-7"]], ["operation"]], [[["Carlos Gracie-1", "H\u00e9lio Gracie-1"]], [["Carlos Gracie-12", "H\u00e9lio Gracie-25"]], [["Dozen-7"]], ["operation"]], [[["Gracie family-1"]], [["H\u00e9lio Gracie-25"], "no_evidence"], [["Dozen-7"]], ["operation"]]], "golden_sentence": [["Brazilian Jiu-Jitsu was first developed and modified in the 1920s by Brazilian brothers Carlos, George, and H\u00e9lio Gracie after Carlos was taught traditional Kodokan Judo by a travelling Japanese judoka (Mitsuyo Maeda) in 1917, later going on to develop their own self defence system named Gracie Jiu-Jitsu."], ["At the time of his death, Gracie had twenty-one children, one hundred and six grandchildren, and one hundred and twenty-eight great-grandchildren.", "During their marriage, Gracie became the father of three sons (Rickson, Rorion, and Relson) with Isabel 'Belinha' Soares and four sons (Royler, Rolker, Royce, Robin), two daughters (Rerika and Ricci) with Vera."], ["page\u00a0needed] A baker's dozen, devil's dozen, long dozen, or long measure is 13, one more than a standard dozen."]]}, {"qid": "90c5595a6ba03e90b2c3", "term": "Dolce & Gabbana", "description": "Italian fashion house", "question": "Did Mozart ever buy anything from Dolce & Gabbana?", "answer": false, "facts": ["Dolce & Gabbana was founded in 1985.", "Wolfgang Amadeus Mozart died in 1791."], "decomposition": ["When was Dolce & Gabbana established?", "Was Mozart still alive as at #1?"], "evidence": [[[["Dolce & Gabbana-1"]], [["Wolfgang Amadeus Mozart-1"], "operation"]], [[["Dolce & Gabbana-1"]], [["Biographies of Mozart-1"]]], [[["Dolce & Gabbana-1"]], [["Wolfgang Amadeus Mozart-1"], "operation"]]], "golden_sentence": [["Dolce & Gabbana (Italian pronunciation:\u00a0[\u02c8dolt\u0283e e \u0261ab\u02c8ba\u02d0na]) is an Italian luxury fashion house founded in 1985 in Legnano by Italian designers Domenico Dolce and Stefano Gabbana."], ["Wolfgang Amadeus Mozart (27 January 1756\u00a0\u2013 5 December 1791), baptised as Johannes Chrysostomus Wolfgangus Theophilus Mozart, was a prolific and influential composer of the Classical period."]]}, {"qid": "8f9ba93cb04e4f652733", "term": "Judge", "description": "official who presides over court proceedings", "question": "Would an Orthodox Presbyterian object to 1700s judge's attire?", "answer": true, "facts": ["Judges in the 1700s wore powdered wigs and large robes during court proceedings.", "Many Orthodox Presbyterians argue that the Bible prohibits adornment such as wigs and jewelry.", "The 1 Timothy 2:8-9 Bible verse warns against adorning oneself with objects."], "decomposition": ["What attire did judges in the 1700's wear?", "What things are prohibited by Orthodox Presbyterians?", "Are some elements of #1 also found in #2?"], "evidence": [[[["Wig-16"]], ["no_evidence"], ["operation"]], [[["Court dress-110"]], ["no_evidence"], ["operation"]], [[["Wig-16"], "no_evidence"], [["Orthodox Presbyterian Church-1"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["Judges' wigs, in everyday use as court dress, are short like barristers' wigs (although in a slightly different style), but for ceremonial occasions judges and also senior barristers (QCs) wear full-bottomed wigs."]]}, {"qid": "b848db708048f54dfb6c", "term": "Haiku", "description": "very short form of Japanese poetry", "question": "Is Lines on the Antiquity of Microbes briefer than any haiku?", "answer": true, "facts": ["A haiku is a short Japanese poem that follows a 5, 7, 5 syllable structure.", "Lines on the Antiquity of Microbes, also known simply as Fleas is said to be the shortest poem written.", "Lines on the Antiquity of Microbes is made of one brief phrase: Adam. Had 'em."], "decomposition": ["How long is a haiku?", "How long is Lines on the Antiquity of Microbes?", "Is #2 shorter than #1?"], "evidence": [[[["Haiku-2"]], [["Lines on the Antiquity of Microbes-1", "Lines on the Antiquity of Microbes-3"]], ["operation"]], [[["Haiku-2"], "no_evidence"], [["Lines on the Antiquity of Microbes-1"], "operation"], ["no_evidence"]], [[["Haiku-2"]], [["Lines on the Antiquity of Microbes-3"]], ["operation"]]], "golden_sentence": [["Traditional haiku often consist of 17 on (also known as morae though often loosely translated as \"syllables\"), in three phrases of 5, 7, and 5 on, respectively."], ["Lines on the Antiquity of Microbes, also known simply as Fleas, is a couplet commonly cited as the shortest poem ever written, composed by American poet Strickland Gillilan in the early 20th century.", "\"Lines on the Antiquity of Microbes\" is frequently said to be the shortest poem in the English language, or the shortest in the world."]]}, {"qid": "a651ba82c5e39990d737", "term": "The Matrix", "description": "1999 science fiction action film directed by the Wachowskis", "question": "Do the directors of The Matrix advocate for transgender rights?", "answer": true, "facts": ["Lilly Wachowski is a trans woman who was a director of The Matrix.", "Lena Wachowski is a trans woman who was a director of The Matrix.", "The Wachowski sisters speak actively about viewing their films through a \"lens of transness\""], "decomposition": ["Who directed The Matrix?", "Are #1 transgender rights advocates?"], "evidence": [[[["The Matrix-1"]], [["The Wachowskis-1", "The Wachowskis-57"]]], [[["The Matrix-1"]], [["The Wachowskis-57"], "operation"]], [[["The Wachowskis-2"]], [["The Wachowskis-53"], "operation"]]], "golden_sentence": [["The Matrix is a 1999 science fiction action film written and directed by the Wachowskis."], ["The sisters are both trans women.", "In that article, she said, \"I am one of the lucky ones."]]}, {"qid": "117c27244c8e00112265", "term": "Northern fur seal", "description": "The largest fur seal in the northern hemisphere", "question": "Would a northern fur seal pass a driving test?", "answer": false, "facts": ["A driving test measures the ability to drive according to traffic laws.", "The northern fur seal does not have the ability to legally drive."], "decomposition": ["What does a driving test require one to do?", "Does a northern fur seal have the ability to accomplish all of #1?"], "evidence": [[[["Driving test-1"]], [["Northern fur seal-2"], "operation"]], [[["Driving test-1"]], [["Northern fur seal-2"]]], [[["Driving test-1", "Driving test-4"], "no_evidence"], [["Northern fur seal-1"], "no_evidence", "operation"]]], "golden_sentence": [["A driving test generally consists of one or two parts: the practical test, called a road test, used to assess a person's driving ability under normal operating conditions, and/or a written or oral test (theory test) to confirm a person's knowledge of driving and relevant rules and laws."], ["The hind flippers are proportionately the longest in any otariid because of extremely long, cartilaginous extensions on all of the toes."]]}, {"qid": "83a7c67c6f156f9cf4cb", "term": "Taco Bell", "description": "American fast-food chain", "question": "Will more people go in and out of Taco Bell than a Roy Rogers each year?", "answer": true, "facts": ["Taco Bell has over 7,072 restaurants as of 2018.", "Roy Rogers had over 600 restaurants at its peak.", "Roy Rogers has 48 locations as of 2019."], "decomposition": ["How many restaurants does Taco Bell have?", "How many restaurants does Roy Rogers have?", "Is #1 significantly greater than #2?"], "evidence": [[[["Taco Bell-1"]], [["Roy Rogers Restaurants-1"]], ["operation"]], [["no_evidence"], [["Roy Rogers Restaurants-1"]], ["operation"]], [["no_evidence"], [["Roy Rogers Restaurants-1"]], ["no_evidence", "operation"]]], "golden_sentence": [["Taco Bell is an American chain of fast food restaurants based in Irvine, California and a subsidiary of Yum!"], ["Currently, the chain has 48 locations."]]}, {"qid": "abb3562932923dc9286e", "term": "Red Sea", "description": "Arm of the Indian Ocean between Arabia and Africa", "question": "Would it be unusual to find a yellow perch in the Red Sea?", "answer": true, "facts": ["The Red Sea is one of the saltiest bodies of water in the world.", "The yellow perch is a freshwater perciform fish native to much of North America."], "decomposition": ["What type of water do yellow perches usually live in?", "What type of water is present in the red sea?", "IS #2 the same as #1?"], "evidence": [[[["Yellow perch-1"]], [["Red Sea-8"]], ["operation"]], [[["Yellow perch-1"]], [["Red Sea-16"]], ["operation"]], [[["Yellow perch-17"]], [["Red Sea-16"]], ["operation"]]], "golden_sentence": [["The yellow perch (Perca flavescens), commonly referred to as perch, striped perch or American perch is a freshwater perciform fish native to much of North America."], ["Although reeds do not grow in the Red Sea today (reeds do not grow in salt water), Professor Colin Humphreys explains the discrepancy on the basis that a freshwater marsh of reeds could have existed around Aqaba."]]}, {"qid": "67349fa25d548ca128ec", "term": "Samsung Galaxy S4", "description": "Android smartphone", "question": "Would General Zod prefer an iPhone over a Samsung Galaxy S4?", "answer": false, "facts": ["General Zod is a villain.", "Apple does not allow moviemakers to give villains iPhones."], "decomposition": ["What movie is General Zod from?", "What is General Zod's role in #1?", "Does Apple allow moviemakers to give #2 iPhones?"], "evidence": [[[["General Zod-11"]], [["General Zod-1"]], ["no_evidence", "operation"]], [[["General Zod-11"]], [["General Zod-2"]], ["no_evidence"]], [[["Superman II-1"]], [["General Zod-1"]], ["no_evidence", "operation"]]], "golden_sentence": [["General Zod appeared in the Superman: Last Son storyline (written by Geoff Johns and Richard Donner, the director of Superman: The Movie and most of Superman II).", "In a similar story to that of Superman II, Zod, Ursa, and Non escape from the Phantom Zone and come to Earth to try to turn it into a \"New Krypton\"."], ["General Zod is a fictional supervillain appearing in comic books published by DC Comics, commonly in association with Superman."]]}, {"qid": "e126c8162ff2b480e898", "term": "Arithmetic", "description": "Elementary branch of mathematics", "question": "Did Neanderthals use arithmetic?", "answer": false, "facts": ["The earliest written records indicate the Egyptians and Babylonians used all the elementary arithmetic operations as early as 2000 BC.", "Neanderthals are an extinct species or subspecies of archaic humans who lived in Eurasia until about 40,000 years ago."], "decomposition": ["The earliest records of arithmetic use date back to when?", "When did the Neanderthals become extinct?", "Is #1 before #2?"], "evidence": [[[["Arithmetic-2"]], [["Neanderthal-1"]], ["operation"]], [[["Arithmetic-2"]], [["Neanderthal-2"]], [["Neanderthal-2"], "operation"]], [[["History of mathematics-10"]], [["Neanderthal extinction-1"]], ["operation"]]], "golden_sentence": [["The prehistory of arithmetic is limited to a small number of artifacts which may indicate the conception of addition and subtraction, the best-known being the Ishango bone from central Africa, dating from somewhere between 20,000 and 18,000\u00a0BC, although its interpretation is disputed."], ["Neanderthals (/ni\u02c8\u00e6nd\u0259rt\u0251\u02d0l, ne\u026a-, -\u03b8\u0254\u02d0l/, also Neandertals or Neandert(h)alers, Homo neanderthalensis or Homo sapiens neanderthalensis) are an extinct species or subspecies of archaic humans who lived in Eurasia until about 40,000 years ago (40 kya [thousand years ago])."]]}, {"qid": "8238ca7e53b2eadfa5fe", "term": "Hound", "description": "dog type", "question": "Was animal in You're a Good Sport, Charlie Brown, hypothetically a hound?", "answer": true, "facts": ["A hound is a type of hunting dog used to track prey.", "Hounds include Basenjis, Dachsunds, and Beagles, among others.", "Snoopy is the dog in the Charlie Brown movies and books.", "Snoopy is a Beagle."], "decomposition": ["What animals fall under the classification of \"hound\"?", "What kind of animal was Snoopy?", "What kind of #2 was Snoopy?", "Is #3 included in #1?"], "evidence": [[[["Hound-1", "Hound-3"]], [["Beagle-1"]], [["Snoopy-1"]], ["operation"]], [[["Hound-1"]], [["Snoopy-2"]], [["Snoopy-2"]], [["Beagle-1"]]], [[["Scent hound-2"]], [["Snoopy-7"]], [["Snoopy-1"]], [["Beagle-1"], "operation"]]], "golden_sentence": [["A hound is a type of hunting dog used by hunters to track or chase prey.", "There are three types of hound, with several breeds within each type:"], ["The beagle is a scent hound, developed primarily for hunting hare (beagling)."], ["Snoopy is a fictional character, the pet beagle of Charlie Brown in the comic strip Peanuts by Charles M. Schulz."]]}, {"qid": "34aaa0304d840b427cc3", "term": "J. K. Rowling", "description": "English novelist", "question": "Are any of J.K. Rowling's books in the genre of And Then There Were None?", "answer": true, "facts": ["And Then There Were None was a mystery novel written by Agatha Christie.", "J.K. Rowling is best known for her wizard fantasy series Harry Potter.", "Robert Galbraith is the author of the Cuckoo's Calling, a mystery crime fiction novel.", "Robert Galbraith is the pseudonym that J.K. Rowling writes under."], "decomposition": ["What genre is the book And Then There Were None?", "What genre are Rowling's fiction Cormoran Strike series?", "Is #1 same as #2?"], "evidence": [[[["And Then There Were None-1"]], [["Cormoran Strike-1"]], ["operation"]], [[["And Then There Were None-1"]], [["Cormoran Strike-1"]], ["operation"]], [[["And Then There Were None-10"], "no_evidence"], [["Cormoran Strike-1"]], ["operation"]]], "golden_sentence": [["And Then There Were None is a mystery novel by English writer Agatha Christie, described by her as the most difficult of her books to write."], ["Cormoran Strike is a series of crime fiction books written by British author J. K. Rowling, published under the pseudonym Robert Galbraith."]]}, {"qid": "c649c9f1814bd72b8ccd", "term": "Jay-Z", "description": "American rapper, entrepreneur, record executive, songwriter, producer and investor from New York", "question": "Did Jay-Z ever collaborate with Louis Armstrong?", "answer": false, "facts": ["Jay-Z was born in 1969.", "Louis Armstrong died in 1971."], "decomposition": ["What year did Jay-Z make his first recording?", "When did Louis Armstrong die?", "Is #1 before #2?"], "evidence": [[[["Jay-Z-2"]], [["Louis Armstrong-87"]], ["operation"]], [[["Jay-Z albums discography-2"]], [["Louis Armstrong-1"]], ["no_evidence"]], [[["Jay-Z-11"]], [["Louis Armstrong-1"]], ["operation"]]], "golden_sentence": [["Born and raised in New York City, Jay-Z first began his musical career after founding the record label Roc-A-Fella Records in 1995, and subsequently released his debut studio album Reasonable Doubt in 1996."], ["Still hoping to get back on the road, Armstrong died of a heart attack in his sleep on July 6, 1971, a month before his 70th birthday."]]}, {"qid": "c7cb1e3fc112e8f924fe", "term": "Metre", "description": "SI unit of length", "question": "Are lengths measured in metres in the UK?", "answer": true, "facts": ["Metres are part of the metric system.", "The UK uses the metric system for measurements."], "decomposition": ["What system of measurement does the UK use?", "Are meters a unit of measure in #1?"], "evidence": [[[["System of measurement-8"]], [["Unit of length-6"], "operation"]], [[["Metric system-37"]], [["Metric units-2"]]], [[["Imperial units-1"], "no_evidence"], [["Metrication in the United Kingdom-70"], "no_evidence"]]], "golden_sentence": [["A number of other jurisdictions have laws mandating or permitting other systems of measurement in some or all contexts, such as the United Kingdom \u2013 whose road signage legislation, for instance, only allows distance signs displaying imperial units (miles or yards) \u2013 or Hong Kong."], ["The basic unit of length in the Imperial and U.S. customary systems is the yard, defined as exactly 0.9144\u00a0m by international treaty in 1959."]]}, {"qid": "8d7f7bca01ee50ec0dc7", "term": "Christopher Columbus", "description": "Italian explorer, navigator, and colonizer", "question": "Did Christopher Columbus sail representing a different country than his original home?", "answer": true, "facts": ["Columbus was originally from Genoa in what is now Italy.", "His expeditions were funded by the Spanish monarchy."], "decomposition": ["What country was Christopher Columbus born in?", "What country did Christopher Columbus sail for?", "Is #1 different than #2?"], "evidence": [[[["Christopher Columbus-5"]], [["Christopher Columbus-80"]], [["Christopher Columbus-80"]]], [[["Christopher Columbus-5"]], [["Christopher Columbus-1"]], ["operation"]], [[["Christopher Columbus-5"]], [["Christopher Columbus-30"]], ["operation"]]], "golden_sentence": [["He was born before 31 October 1451 in the territory of the Republic of Genoa (now part of modern Italy), though the exact location remains disputed."], ["The anniversary of Columbus's 1492 landing in the Americas is usually observed on 12 October in Spain and throughout the Americas, except Canada."], ["The anniversary of Columbus's 1492 landing in the Americas is usually observed on 12 October in Spain and throughout the Americas, except Canada."]]}, {"qid": "ee89128e112aca3b7efd", "term": "Blue", "description": "A primary colour between purple and green", "question": "Are blue lips normal?", "answer": false, "facts": ["Lips and skin turn blue in response to a lack of oxygen.", "When oxygen flow is inadequate, someone's health can be in danger.", "Lips can turn blue due to extreme cold."], "decomposition": ["What are the possible causes of blue lips?", "Is any of #1 a natural or normal process?"], "evidence": [[[["Cyanosis-1"]], ["operation"]], [[["Cyanosis-5", "Cyanosis-6"]], [["Cyanosis-6"]]], [[["Cyanosis-5"]], [["Oxygen saturation (medicine)-1"]]]], "golden_sentence": [["When signs of cyanosis first appear, such as on the lips or fingers, intervention should be made within 3\u20135 minutes because a severe hypoxia or severe circulatory failure may have induced the cyanosis."]]}, {"qid": "0de2785a6eaba087541a", "term": "Anorexia nervosa", "description": "Eating disorder characterized by refusal to maintain a healthy body weight, and fear of gaining weight due to a distorted self image", "question": "Did Jon Brower Minnoch suffer from anorexia nervosa?", "answer": false, "facts": ["Jon Brower Minnoch was an American man who, at his peak weight, was the heaviest human being ever recorded, weighing 1,400 lb.", "Anorexia nervosa,Anorexia nervosa is an eating disorder, characterized by low weight, food restriction, fear of gaining weight, and a strong desire to be thin. Many people with anorexia see themselves as overweight even though they are, in fact, underweight."], "decomposition": ["What are characteristics of anorexia nervosa?", "How much did Jon Brower Minnoch weigh?", "Is #2 a weight that would be considered #1?"], "evidence": [[[["Anorexia nervosa-1"]], [["Jon Brower Minnoch-1"]], [["Anorexia nervosa-2", "Jon Brower Minnoch-5"]]], [[["Anorexia nervosa-1"]], [["Jon Brower Minnoch-1"]], ["operation"]], [[["Anorexia nervosa-4"]], [["Jon Brower Minnoch-1"]], [["Jon Brower Minnoch-1"], "operation"]]], "golden_sentence": [["Anorexia nervosa, often referred to simply as anorexia, is an eating disorder, characterized by low weight, food restriction, fear of gaining weight, and a strong desire to be thin."], ["Jon Brower Minnoch (September 29, 1941 \u2013 September 10, 1983) was an American man who, at his peak weight, was the heaviest human being ever recorded, weighing 1,400\u00a0lb (635 kilograms; 100 stone)."], ["The diagnosis requires a significantly low weight.", "He weighed 476\u00a0lb (216\u00a0kg; 34\u00a0st), having lost approximately 924\u00a0lb (419\u00a0kg; 66\u00a0st), the second largest human weight loss ever documented."]]}, {"qid": "4bea34763a1e9f0d5b2b", "term": "Othello", "description": "play by Shakespeare", "question": "Would Othello be Shakespeare's play to buy Scheherazade most time with king?", "answer": false, "facts": ["Scheherazade was a character in Middle Eastern folklore that delayed her execution by telling the king long stories.", "Shakespeare's play Othello contained 26,450 words.", "Hamlet is Shakespeare's longest play consisting of 4000 lines and 30,000 words."], "decomposition": ["How long is Othello?", "Are all of Shakespeare's other plays shorter than #1?"], "evidence": [[[["Othello-41"], "no_evidence"], [["Shakespeare's plays-1"], "no_evidence", "operation"]], [[["Othello-20"], "no_evidence"], [["Hamlet-2", "The Comedy of Errors-1"], "no_evidence", "operation"]], [[["Othello-1"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["It ran for 296 performances, almost twice as long as any other Shakespearean play ever produced on Broadway."], ["The exact number of plays\u2014as well as their classifications as tragedy, history, or comedy\u2014is a matter of scholarly debate."]]}, {"qid": "51126206a7baab47253d", "term": "Baptism", "description": "Christian rite of admission and adoption, almost invariably with the use of water", "question": "Was Hillary Clinton's deputy chief of staff in 2009 baptised?", "answer": false, "facts": ["Huma Abedin was Hillary Clinton's deputy chief of staff in 2009", "Huma Abedin is an American Muslim", "Baptism is a Christian tradition"], "decomposition": ["Who was Hilary Clinton's deputy chief of staff in 2009?", "What religion does #1 practice?", "What religion practices baptism?", "Is #2 the same as #3?"], "evidence": [[[["Huma Abedin-8"]], [["Huma Abedin-10"]], [["Baptism-1"]], ["operation"]], [[["Huma Abedin-1"]], ["operation"], [["Baptism-1"]], ["operation"]], [[["Huma Abedin-1"]], [["Huma Abedin-5"]], [["Baptism-1"]], ["operation"]]], "golden_sentence": [["In 2009, Abedin was appointed deputy chief of staff to Clinton in the State Department, under a \"special government employee\" arrangement created by the department which allowed her to work for private clients as a consultant while also serving as an adviser to the Secretary of State."], ["After Republican presidential candidate Donald Trump proposed banning Muslims from entering the United States, she wrote an email to Clinton supporters calling herself \"a proud Muslim\" and criticized Trump's plan as \"literally (writing) racism into our law books\"."], ["Baptism (from the Greek noun \u03b2\u03ac\u03c0\u03c4\u03b9\u03c3\u03bc\u03b1 baptisma; see below) is a Christian rite of admission and adoption, almost invariably with the use of water, into Christianity.", "Baptism is considered a sacrament in most churches, and as an ordinance in others."]]}, {"qid": "89163b1a436926698578", "term": "Crane (bird)", "description": "family of birds", "question": "Is a Cassowary safer pet than a crane?", "answer": false, "facts": ["Crane's that are fed by humans can exhibit domestic tendencies and rarely peck at humans.", "The Cassowary, known as the world's most dangerous bird, becomes very aggressive and has even killed humans and dogs."], "decomposition": ["What behaviors do cranes have with humans?", "What behaviors do cassowaries have with humans?", "Are the behaviors of #2 less violent than #1?"], "evidence": [[[["Crane (bird)-22"], "no_evidence"], [["Cassowary-36", "Cassowary-41"]], ["operation"]], [[["Crane (bird)-24"], "no_evidence"], [["Cassowary-36"]], ["no_evidence"]], [[["Crane (bird)-5"], "no_evidence"], [["Cassowary-3"]], ["no_evidence", "operation"]]], "golden_sentence": [["Tropical species can maintain very small territories, for example sarus cranes in India can breed on territories as small as one hectare where the area is of sufficient quality and disturbance by humans is minimised."], ["Cassowaries have a reputation for being dangerous to people and domestic animals.", "Another human death due to a cassowary was recorded in Florida on April 12, 2019."]]}, {"qid": "ab2527bb6fd97508b566", "term": "Sainsbury's", "description": "chain of supermarkets in the United Kingdom", "question": "Could you drive from New England to a Sainsbury's?", "answer": false, "facts": ["New England is located in the United States of America.", "The U.K and New England are separated by a large ocean."], "decomposition": ["What country is Sainsbury located on?", "What country is New England in?", "What separates #1 and #2?", "Can a car drive over #3?"], "evidence": [[[["Sainsbury's-1"]], [["New England-1"]], [["Atlantic Ocean-2"]], ["operation"]], [[["Sainsbury's-1"]], [["Eastern United States-8"]], [["Atlantic Ocean-1"]], ["operation"]], [[["Sainsbury's-1"]], [["New England-1"]], [["Atlantic Ocean-2"]], [["Amphibious automobile-1", "Amphibious vehicle-22"]]]], "golden_sentence": [["Founded in 1869, by John James Sainsbury with a shop in Drury Lane, London, the company became the largest retailer of groceries in 1922."], ["New England is a region composed of six states in the northeastern United States: Maine, Vermont, New Hampshire, Massachusetts, Rhode Island, and Connecticut."], ["As one component of the interconnected World Ocean, it is connected in the north to the Arctic Ocean, to the Pacific Ocean in the southwest, the Indian Ocean in the southeast, and the Southern Ocean in the south (other definitions describe the Atlantic as extending southward to Antarctica)."]]}, {"qid": "7c287c8c9a4b3aef8e75", "term": "P. G. Wodehouse", "description": "English author", "question": "Would P. G. Wodehouse be taught in second grade?", "answer": false, "facts": ["Second graders are often aged seven or eight.", "The works of Wodehouse are intended for an adult audience."], "decomposition": ["How old are typical second graders?", "What age group is P. G. Wodehouse works intended for?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Second grade-1"]], [["P. G. Wodehouse-52"], "no_evidence"], ["no_evidence", "operation"]], [[["Second grade-8"]], [["P. G. Wodehouse-14"], "no_evidence"], ["operation"]], [[["Second grade-8"]], [["P. G. Wodehouse-26"], "no_evidence"], ["operation"]]], "golden_sentence": [["Second grade (also called grade two, corresponding to Year 3 in the UK) is a year of primary education in Canada and the US."], ["In his younger years, he would write around two to three thousand words a day, although he slowed as he aged, so that in his nineties he would produce a thousand."]]}, {"qid": "bbfc68abfe40adb1c618", "term": "Alice's Adventures in Wonderland", "description": "book by Lewis Carroll", "question": "Is tobacco use made to seem enjoyable in Alice's Adventures in Wonderland?", "answer": true, "facts": ["In Alice's Adventures in Wonderland, one of the characters is a caterpillar that smokes hookah.", "Hookah is a water pipe used to smoke tobacco products.", "The caterpillar speaks to Alice while making letters out of the smoke he blows."], "decomposition": ["In Alice's Adventures in Wonderland, what is a caterpillar seen smoking?", "What do you use #1 to do?", "Does it seem like the caterpillar enjoys #2?"], "evidence": [[[["Alice's Adventures in Wonderland-13"]], [["Hookah-1"]], ["no_evidence"]], [[["Alice's Adventures in Wonderland-13"]], [["Hookah-1"]], ["no_evidence", "operation"]], [[["Alice's Adventures in Wonderland-13"]], [["Hookah-1"]], ["no_evidence", "operation"]]], "golden_sentence": [["Chapter Five \u2013 Advice from a Caterpillar: Alice comes upon a mushroom and sitting on it is a blue caterpillar smoking a hookah."], ["A hookah (Hindustani: \u0939\u0941\u0915\u093c\u094d\u0915\u093c\u093e (Devanagari), \u062d\u0642\u0651\u06c1 (Nastaleeq), IPA: [\u02c8\u0266\u028aqqa\u02d0]; also see other names), also known as the qaly\u00e2n (Persian: \u0642\u0644\u06cc\u0627\u0646\u200e), is a single- or multi-stemmed instrument for vaporizing and smoking flavored cannabis, tobacco (often Mu\u2018assel), or sometimes opium, whose vapor or smoke is passed through a water basin\u2014often glass-based\u2014before inhalation."]]}, {"qid": "cbc0979b3b041cc01f32", "term": "Simon Cowell", "description": "English reality television judge, television producer and music executive", "question": "Can Simon Cowell vote for the next Supreme Court judge?", "answer": false, "facts": ["The Supreme Court is the highest court in the USA.", "Simon Cowell is a British talent competition judge.", "Members of the Supreme Court are appointed, rather than elected."], "decomposition": ["Who appoints US Supreme Court judges?", "Is Simon Cowell currently serving as #1?"], "evidence": [[[["Appointments Clause-1"]], [["Simon Cowell-27", "Simon Cowell-43"], "operation"]], [[["Appointment and confirmation to the Supreme Court of the United States-3"]], [["Simon Cowell-1"]]], [[["Supreme Court of the United States-2"]], [["Donald Trump-1"]]]], "golden_sentence": [["The Appointments Clause is part of Article II, Section 2, Clause 2 of the United States Constitution, which empowers the President of the United States to nominate and, with the advice and consent (confirmation) of the United States Senate, appoint public officials."], ["A second series is scheduled to air in 2020.", "In 2020, Cowell announced he would be writing a 7 book series titled Wishfits with his son."]]}, {"qid": "316d74f3e8ce42728fdd", "term": "Great Depression", "description": "20th-century worldwide economic depression", "question": "Could all the unemployed people due to 1933 Great Depression fit in Tiger Stadium?", "answer": false, "facts": ["There were approximately 15 million people unemployed in 1933 due to the Great Depression.", "In the 1930s Tiger Stadium had a capacity around 50,000."], "decomposition": ["How many people became unemployed due to 1933 Great Depression?", "What is the seating capacity of Tiger Stadium?", "Is #1 less than or equal to #2?"], "evidence": [[[["Recession of 1937\u201338-2", "United States-1"], "no_evidence"], [["Tiger Stadium (LSU)-18"]], ["operation"]], [[["Great Depression-65"], "no_evidence"], [["Tiger Stadium (LSU)-11"]], ["operation"]], [[["Unemployment-139"], "no_evidence"], [["Tiger Stadium (Detroit)-2"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["Unemployment remained high, but it was slightly lower than the 25% rate seen in 1933.", "The United States of America (USA), commonly known as the United States (U.S. or US) or simply America, is a country consisting of 50 states, a federal district, five major self-governing territories, and various possessions."], ["On April 27, 2012, the LSU Board of Supervisors voted unanimously in favor of an $80 million south end-zone upper deck expansion that added 70 \"Tiger Den\" suites, over 3,000 club seats and 1,500+ general public seats to bring the total capacity of Tiger Stadium to 102,321, making it the fifth-largest college football stadium in the country."]]}, {"qid": "988f73f260f65621866e", "term": "Donatello", "description": "Italian painter and sculptor", "question": "Can an adult male stand on top Donatello's bronze David and touch the Sistine Chapel ceiling?", "answer": false, "facts": ["Donatello's created a bronze David statue that stands over five feet tall.", "The average height of an adult male is five feet and nine inches.", "The tallest adult male in history was eight feet and eleven inches.", "The Sistine Chapel ceiling is sixty eight feet high."], "decomposition": ["How tall is Donatello's bronze David statue?", "How tall is the tallest person to ever live?", "How tall is the Sistine Chapel ceiling?", "Is #1 plus #2 greater than or equal to #3?"], "evidence": [[["no_evidence"], [["Robert Wadlow-1", "Robert Wadlow-2"]], [["Sistine Chapel-15"]], ["no_evidence", "operation"]], [[["David (Donatello)-5"], "no_evidence"], [["Robert Wadlow-2"]], [["Sistine Chapel-15"]], ["no_evidence", "operation"]], [[["Bronze Horseman-8"], "operation"], ["no_evidence"], ["no_evidence"], ["no_evidence"]]], "golden_sentence": [["Robert Pershing Wadlow (February 22, 1918 \u2013 July 15, 1940), also known as the Alton Giant and the Giant of Illinois, was an American man who was the tallest person in recorded history for whom there is irrefutable evidence.", "Wadlow reached 8\u00a0ft 11.1\u00a0in (2.72\u00a0m) in height and weighed 439\u00a0lb (199\u00a0kg) at his death at age 22."], ["Above is the main space, the Sistine Chapel, the vaulted ceiling rising to 20.7 metres (68\u00a0ft)."]]}, {"qid": "29574176246ede705240", "term": "Arab\u2013Israeli conflict", "description": "geopolitical conflict in the Middle East and North Africa", "question": "Was England directly involved in the Arab-Israeli conflict?", "answer": true, "facts": ["The Arab-Israeli conflict began hundreds of years ago.", "England occupied what is now Israel until 1945 when Israel became independent.", "During Israel's war for independence England allied with their Arab neighbors to fight the Israeli rebels."], "decomposition": ["Which nation did Israel gain independence from?", "Which other nation did #1 ally with to resist Israeli rebels during the war for independence?", "Is #1 England and #2 Arab?"], "evidence": [[[["Israel-5"]], [["Arab\u2013Israeli conflict-3"]], ["no_evidence"]], [[["United Nations Partition Plan for Palestine-1", "United Nations Partition Plan for Palestine-2"], "no_evidence"], [["1948 Arab\u2013Israeli War-14", "1948 Arab\u2013Israeli War-9", "Israel-30"], "no_evidence"], ["no_evidence", "operation"]], [[["Israel-32"]], ["no_evidence"], ["operation"]]], "golden_sentence": [["Upon independence in 1948, the country formally adopted the name \"State of Israel\" (Hebrew: \u05de\u05b0\u05d3\u05b4\u05d9\u05e0\u05b7\u05ea \u05d9\u05b4\u05e9\u05b0\u05c2\u05e8\u05b8\u05d0\u05b5\u05dc Med\u012bnat Yisr\u0101'el [medi\u02c8nat jis\u0281a\u02c8\u0294el]; Arabic: \u062f\u064e\u0648\u0652\u0644\u064e\u0629 \u0625\u0650\u0633\u0652\u0631\u064e\u0627\u0626\u0650\u064a\u0644\u200e Dawlat Isr\u0101\u02bc\u012bl [dawlat \u0294isra\u02d0\u02c8\u0294i\u02d0l]) after other proposed historical and religious names including Eretz Israel (\"the Land of Israel\"), Ever (from ancestor Eber), Zion, and Judea, were considered but rejected, while the name 'Israel' was suggested by Ben-Gurion and passed by a vote of 6\u20133."], ["Taking the side of the Palestinian Arabs, especially following the Israeli Declaration of Independence, the neighbouring Arab countries invaded the by-then former Mandate territory in May 1948, commencing the First Arab\u2013Israeli War."]]}, {"qid": "d7ea60bc4dd6e8986d4e", "term": "Alice's Adventures in Wonderland", "description": "book by Lewis Carroll", "question": "Did Alice's Adventures in Wonderland inspire Macbeth?", "answer": false, "facts": ["Alice's Adventures in Wonderland was published in 1865", "Macbeth was first performed in 1606"], "decomposition": ["When was Alice's Adventures in Wonderland first published?", "When was Macbeth first performed?", "Is #1 before #2?"], "evidence": [[[["Alice's Adventures in Wonderland-1"]], [["Macbeth-1"]], ["operation"]], [[["Alice's Adventures in Wonderland-3"]], [["Macbeth-32"]], ["operation"]], [[["Alice's Adventures in Wonderland-1"]], [["Macbeth-1"]], ["operation"]]], "golden_sentence": [["Alice's Adventures in Wonderland (commonly shortened to Alice in Wonderland) is an 1865 novel written by English author Charles Lutwidge Dodgson under the pseudonym Lewis Carroll."], ["Macbeth (/m\u0259k\u02c8b\u025b\u03b8/; full title The Tragedy of Macbeth) is a tragedy by William Shakespeare; it is thought to have been first performed in 1606.", "It was first published in the Folio of 1623, possibly from a prompt book, and is Shakespeare's shortest tragedy."]]}, {"qid": "6d92b708dfcdd1b904be", "term": "Asian black bear", "description": "species of mammal", "question": "Is the Asian black bear multicolored?", "answer": true, "facts": ["The Asian black bear is an animal that lives in habitats with trees.", "Multicolored refers to anything that is composed of more than one color.", "The Sian black bear has a black coat with a white V-shaped patch."], "decomposition": ["How many colors of fur does the asian black bear have?", "Is #1 greater than 1?"], "evidence": [[[["Asian black bear-2"]], ["operation"]], [[["Asian black bear-2"]], ["operation"]], [[["Asian black bear-2"]], ["operation"]]], "golden_sentence": [["The Asian black bear is black, has a light brown muzzle and a distinct white patch on the chest, which sometimes has the shape of a V. Its ears are bell shaped, proportionately longer than those of other bears, and stick out sideways from the head."]]}, {"qid": "3a9069abb5a9da1e96a3", "term": "Lieutenant", "description": "junior commissioned officer in many nations' armed forces", "question": "Are pirate lieutenants like navy lieutenants?", "answer": true, "facts": ["Lieutenant Richards was a pirate that sailed alongside Blackbeard.", "Lieutenant RIchards had many duties and was placed in charge of the ship, Bonnet's Revenge.", "In the Royal Navy and Commonwealth navies, the second-in-command of a vessel is known as the first lieutenant.", "Royal Navy lieutenants are in charge of other crew members and have many duties."], "decomposition": ["What are the duties of a pirate lieutenant?", "What are the duties of a navy lieutenant?", "Is there significant overlap between #1 and #2?"], "evidence": [[["no_evidence"], [["Lieutenant (navy)-10", "Lieutenant (navy)-11"]], ["operation"]], [[["Piracy-87"], "no_evidence"], [["Lieutenant (navy)-1", "Lieutenant (navy)-11"], "no_evidence"], ["no_evidence", "operation"]], [[["Governance in 18th-century piracy-4"], "no_evidence"], [["Lieutenant (navy)-12"], "no_evidence"], ["operation"]]], "golden_sentence": [["The first lieutenant (1st Lt or 1LT) in the Royal Navy and other Commonwealth navies, is a post or appointment, rather than a rank.", "In minor war vessels, destroyers and frigates, the first lieutenant (either a lieutenant or lieutenant commander) is second in command, executive officer (XO) and head of the executive branch; in larger ships, where a commander of the warfare specialisation is appointed as the executive officer, a first lieutenant (normally a lieutenant commander) is appointed as his deputy."]]}, {"qid": "77b1da70e82d4f165c39", "term": "Lorem ipsum", "description": "Placeholder text used in publishing and graphic design", "question": "Should a finished website have lorem ipsum paragraphs?", "answer": false, "facts": ["Lorem Ipsum paragraphs are meant to be temporary.", "Web designers always remove lorem ipsum paragraphs before launch."], "decomposition": ["What is a lorem ipsum paragraph? ", "Is #1 good to have on a website?"], "evidence": [[[["Lorem ipsum-1"]], [["Lorem ipsum-1", "Lorem ipsum-2"]]], [[["Lorem ipsum-1"]], ["operation"]], [[["Lorem ipsum-1"]], ["operation"]]], "golden_sentence": [["In publishing and graphic design, Lorem ipsum is a placeholder text commonly used to demonstrate the visual form of a document or a typeface without relying on meaningful content."], ["Lorem ipsum may be used before final copy is available, but it may also be used to temporarily replace copy in a process called greeking, which allows designers to consider form without the meaning of the text influencing the design.", "Lorem ipsum is typically a corrupted version of De finibus bonorum et malorum, a first-century BCE text by the Roman statesman and philosopher Cicero, with words altered, added, and removed to make it nonsensical, improper Latin."]]}, {"qid": "21e352756ce2d1add415", "term": "Beaver", "description": "Genus of mammals", "question": "Does the land in close proximity to beaver dams suffer?", "answer": true, "facts": ["Beaver dams often lead to flooding in the areas around them.", "Flooding can lead to loosening of the soil.", "Loosened soil can cause trees to fall over. ", "Flooding can lead to soil erosion."], "decomposition": ["What are the effects of beaver dams on surrounding lands?", "Are any of #1 significantly negative?"], "evidence": [[[["Beaver eradication in Tierra del Fuego-4", "North American beaver-9"]], ["operation"]], [[["Beaver dam-11"]], [["Beaver dam-26"]]], [[["Beaver dam-26"]], ["no_evidence"]]], "golden_sentence": [["The beavers already threaten around sixteen million hectares of indigenous forest.", "Their dams help reduce soil erosion and can help reduce flooding."]]}, {"qid": "66b3cfaa499773bdf513", "term": "Will Ferrell", "description": "American actor, comedian, producer, writer and businessman", "question": "Would it be difficult for Will Ferrell to win Empire Award for Best Newcomer?", "answer": true, "facts": ["The Empire Award for Best Newcomer was awarded for an actor in their debut role.", "Will Ferrell debuted in 1995."], "decomposition": ["When do actors get to win the Empire Award for Best Newcomer?", "When did Will Ferrell participate in #1?", "Is #2 a long time ago?"], "evidence": [[[["Empire Award for Best Newcomer-1"]], [["Will Ferrell-1"]], ["operation"]], [[["23rd Empire Awards-1", "Empire Award for Best Male Newcomer-1"]], [["Will Ferrell-1"]], ["operation"]], [[["Empire Award for Best Newcomer-1"]], [["On Our Own (1994 TV series)-2"], "no_evidence"], ["operation"]]], "golden_sentence": [["The Empire Award for Best Newcomer (formerly known as Best Debut) was an Empire Award presented annually by the British film magazine Empire to honor a director with a breakthrough film or an actor who has delivered a breakthrough performance while working within the film industry."], ["He first established himself in the mid-1990s as a cast member on the NBC sketch comedy show Saturday Night Live, and has subsequently starred in comedy films such as Anchorman: The Legend of Ron Burgundy (2004), Talladega Nights (2006), Step Brothers (2008), The Other Guys (2010) and Anchorman 2: The Legend Continues (2013), all but one of which he co-wrote with his comedy partner Adam McKay."]]}, {"qid": "5378f4b41639a2676635", "term": "John Lennon", "description": "English singer and songwriter, founding member of the Beatles", "question": "Did Cynthia Powell celebrate a silver anniversary with John Lennon?", "answer": false, "facts": ["A silver anniversary takes place during the 25th year of marriage.", "Cynthia Powell married John Lennon in 1962.", "Cynthia Powell and John Lennon got divorced in 1968."], "decomposition": ["People have to be married for how many years for them to celebrate a silver anniversary?", "When did Cynthia Powell marry John Lennon?", "When Cynthia Powell divorce John Lennon?", "What is #3 minus #2?", "Is #4 greater than or equal to #1?"], "evidence": [[[["Silver jubilee-1"]], [["Cynthia Lennon-12"]], [["Cynthia Lennon-31"]], ["no_evidence"], ["operation"]], [[["Silver jubilee-1"]], [["Cynthia Lennon-12"]], [["Cynthia Lennon-31"]], ["operation"], ["operation"]], [[["Silver jubilee-1"]], [["Cynthia Lennon-12"]], [["John Lennon-41"]], ["operation"], ["operation"]]], "golden_sentence": [["The anniversary celebrations can be of a wedding anniversary, the 25th year of a monarch's reign or anything that has completed a 25-year mark."], ["Powell and Lennon were married on 23 August 1962 at the Mount Pleasant Register office in Liverpool."], ["When the news of Ono's pregnancy broke, Cynthia started her own divorce proceedings against Lennon on 22 August 1968."]]}, {"qid": "2ebff3186955f326f556", "term": "Al Pacino", "description": "American actor", "question": "Did Al Pacino act in a movie during World War II?", "answer": false, "facts": ["Al Pacino was born in 1940.", "World War II took place from 1939-1945.", "Al Pacino's first movie role was in 1969."], "decomposition": ["When did World War II end?", "When did Al Pacino first have a movie role?", "Is #2 before #1?"], "evidence": [[[["World War II-1"]], [["Al Pacino-2"]], ["operation"]], [[["World War II-1"]], [["Al Pacino-2"]], ["operation"]], [[["The Second World War (disambiguation)-1"]], [["Al Pacino-2"]], ["operation"]]], "golden_sentence": [["World War\u00a0II (often abbreviated as WWII or WW2), also known as the Second World War, was a global war that lasted from 1939 to 1945."], ["A method actor and former student of the HB Studio and the Actors Studio, where he was taught by Charlie Laughton and Lee Strasberg, Pacino's film debut came at the age of 29 with a minor role in Me, Natalie (1969).", "He gained favorable notice for his first lead role as a heroin addict in The Panic in Needle Park (1971)."]]}, {"qid": "ba83e0960e20b69be901", "term": "Gujarati script", "description": "Indian script", "question": "Is the Gujarati script the same category of script as Kanji?", "answer": false, "facts": ["Gujarati script is an abugida script", "Kanji is an adopted logographic script "], "decomposition": ["What type of script is the Gujarati script?", "What type of script is Kanji?", "Is #1 the same as #2?"], "evidence": [[[["Gujarati script-1"]], [["Kanji-1"]], ["operation"]], [[["Gujarati script-1"]], [["Kanji-1"]], ["operation"]], [[["Gujarati script-1"]], [["Kanji-1"]], ["operation"]]], "golden_sentence": [["The Gujarati script (\u0a97\u0ac1\u0a9c\u0ab0\u0abe\u0aa4\u0ac0 \u0ab2\u0abf\u0aaa\u0abf Guj\u01cer\u0101t\u012b Lipi) is an abugida used to write the Gujarati and Kutchi languages."], ["Kanji (\u6f22\u5b57, pronounced\u00a0[ka\u0272d\u0291i] (listen)) are the adopted logographic Chinese characters that are used in the Japanese writing system."]]}, {"qid": "563a36aa0389c6f96cc7", "term": "Morris County, New Jersey", "description": "County in New Jersey", "question": "Was Morris County named after a chief justice?", "answer": true, "facts": ["The Morris County was named after Colonel Lewis Morris.", "Colonel Lewis Morris was the chief justice of New York."], "decomposition": ["Who was Morris County, New Jersey named after?", "Did #1 serve as a chief justice?"], "evidence": [[[["Morris County, New Jersey-4"]], [["Lewis Morris (governor)-1"]]], [[["Morris County, New Jersey-4"]], [["Lewis Morris (governor)-1"]]], [[["Morris County, New Jersey-4"]], [["Lewis Morris (governor)-1"]]]], "golden_sentence": [["Morris County was named after Colonel Lewis Morris, governor of New Jersey in 1738/9, the year the county was named."], ["Lewis Morris (October 15, 1671 \u2013 May 21, 1746), chief justice of New York and British governor of New Jersey, was the first lord of the manor of Morrisania in New York (in what is now the Bronx)."]]}, {"qid": "4111c4147ebc06bd1163", "term": "Very Large Telescope", "description": "telescope in the Atacama Desert, Chile", "question": "Can the Very Large Telescope observe the largest mountain on Earth?", "answer": false, "facts": ["The Very Large Telescope observes outer space.", "The largest mountain on earth is underneath the ocean."], "decomposition": ["What area does the Very Large Telescope observe?", "Is the answer to #1 the same as earth?"], "evidence": [[[["Very Large Telescope-3"]], ["operation"]], [[["Very Large Telescope-3"]], ["operation"]], [[["Very Large Telescope-1"]], ["operation"]]], "golden_sentence": [["Among the pioneering observations carried out using the VLT are the first direct image of an exoplanet, the tracking of individual stars moving around the supermassive black hole at the centre of the Milky Way, and observations of the afterglow of the furthest known gamma-ray burst."]]}, {"qid": "7e69e7d67ecf090a45be", "term": "Methane", "description": "Simplest organic molecule with one carbon atom and four hydrogen", "question": "Is cow methane safer for environment than cars?", "answer": false, "facts": ["Methane is a gas that pollutes the environment and leads to shifts in temperature.", "Cars produce 2.7 tons of methane per year.", "Cows produce 4 tons of methane gas per year."], "decomposition": ["How much methane is produced by cars annually?", "How much methane is produced by cows annually?", "Is #2 less than #1?"], "evidence": [[[["Methane-2"], "no_evidence"], [["Cattle-88"]], ["operation"]], [[["Natural gas vehicle-2"], "no_evidence"], [["Methane emissions-2"]], ["operation"]], [[["Methane-21"], "no_evidence"], ["no_evidence"], ["operation"]]], "golden_sentence": [["The Earth's atmospheric methane concentration has increased by about 150% since 1750, and it accounts for 20% of the total radiative forcing from all of the long-lived and globally mixed greenhouse gases."], ["The IPCC estimates that cattle and other livestock emit about 80 to 93 Megatonnes of methane per year, accounting for an estimated 37% of anthropogenic methane emissions, and additional methane is produced by anaerobic fermentation of manure in manure lagoons and other manure storage structures."]]}, {"qid": "9eba4476b61fc6a2dcdc", "term": "Water skiing", "description": "surface water sport", "question": "Is Morocco an ideal location for water skiing?", "answer": false, "facts": ["Water skiing is a sport that involves gliding over the surface of large bodies of water.", "Morocco is one of the leading countries plagued by drought."], "decomposition": ["What are the minimum requirements to engage in water skiing?", "Does Morocco have #1?"], "evidence": [[[["Water skiing-1"]], [["Morocco-1", "Morocco-39"], "no_evidence", "operation"]], [[["Water skiing-1"]], [["Morocco-41"], "operation"]], [[["Water skiing-5"]], [["Morocco-51"]]]], "golden_sentence": [["The sport requires sufficient area on a smooth stretch of water, one or two skis, a tow boat with tow rope, three people (depending on state boating laws), and a personal flotation device."], ["It overlooks the Mediterranean Sea to the north and the Atlantic Ocean to the west, with land border with Algeria to the east and Western Sahara to the south (status disputed).", "Morocco has a coast by the Atlantic Ocean that reaches past the Strait of Gibraltar into the Mediterranean Sea."]]}, {"qid": "f647907820a7ae1d4300", "term": "Amazon (company)", "description": "American electronic commerce and cloud computing company", "question": "Could one Amazon share ever buy twenty year Netflix subscription?", "answer": true, "facts": ["Amazon stock has reached as high as $2,500 a share as of June 2020.", "The basic Netflix subscription package costs $8.99 a month as of 2020."], "decomposition": ["What is the cost of a monthly Netflix subscription?", "How many months are there in a year?", "What is #2 multiplied by 20 and then multiplied by #1?", "What is the highest price Amazon stock has ever reached?", "Is #4 greater than #3?"], "evidence": [[[["Netflix-49"]], [["Month-38"]], ["operation"], ["no_evidence"], ["operation"]], [[["Netflix-55"]], [["Year-47"]], ["operation"], [["Amazon (company)-78"], "no_evidence"], ["no_evidence", "operation"]], [[["Netflix-49"]], [["Fiscal year-73"]], ["operation"], ["no_evidence"], ["operation"]]], "golden_sentence": [["The HD subscription plan historically cost US$7.99; in April 2014, Netflix announced that it would raise the price of this plan to $9.99 for new subscribers, but that existing customers would be grandfathered under this older price until May 2016, after which they could downgrade to the SD-only tier at the same price, or pay the higher fee for continued high definition access."], ["It has 12 months, broken down into two groups of six often termed \"winter months\" and \"summer months\"."]]}, {"qid": "1b6cc24a9abe52c6ff88", "term": "Nikola Tesla", "description": "Serbian American inventor", "question": "Is there radiation where Nikola Tesla once worked?", "answer": true, "facts": ["Nikola Tesla built a facility called the Wardenclyffe Tower in Shoreham, New York", "Shoreham was the site of a nuclear power plant in the '70s and '80s"], "decomposition": ["What facility did Nikola Tesla build?", "Where is #1 located?", "Did #2 use to be the site of a nuclear power plant?"], "evidence": [[[["Wardenclyffe Tower-12"]], [["Wardenclyffe Tower-1"]], [["Shoreham Nuclear Power Plant-1"], "operation"]], [[["Wardenclyffe Tower-1"]], [["Wardenclyffe Tower-1"]], [["Shoreham Nuclear Power Plant-4", "Shoreham, New York-9"]]], [[["Wardenclyffe Tower-1"]], [["Wardenclyffe Tower-1"]], [["Shoreham Nuclear Power Plant-1"]]]], "golden_sentence": [["Westinghouse seemed like a natural fit for the project given the large-scale AC equipment Westinghouse manufactured and Tesla's need for similar equipment."], ["Wardenclyffe Tower (1901\u20131917), also known as the Tesla Tower, was an early experimental wireless transmission station designed and built by Nikola Tesla in Shoreham, New York in 1901\u20131902."], ["The Shoreham Nuclear Power Plant was a completed General Electric nuclear boiling water reactor located adjacent to Long Island Sound in East Shoreham, New York."]]}, {"qid": "486598e9d21bb65ea56c", "term": "Harlem Renaissance", "description": "African-American cultural movement in New York City in the 1920s", "question": "Could Al Capone have read works from the Harlem Renaissance?", "answer": true, "facts": ["The Harlem Renaissance occurred during the 1920s.", "Al Capone lived through the 1920s."], "decomposition": ["When was the Harlem Renaissance?", "Was Al Capone able to read during #1?"], "evidence": [[[["Harlem Renaissance-1"]], [["Al Capone-1"], "operation"]], [[["Harlem Renaissance-1"]], [["Al Capone-1"], "operation"]], [[["Harlem Renaissance-41"], "no_evidence"], [["Al Capone-3"], "no_evidence"]]], "golden_sentence": [["The Harlem Renaissance was an intellectual, social, and artistic explosion centered in Harlem, Manhattan, New York City, spanning the 1920s."], ["Alphonse Gabriel Capone (/\u02c8k\u0259\u02c8po\u028an/, Italian:\u00a0[ka\u02c8po\u02d0ne]; January 17, 1899\u00a0\u2013 January 25, 1947), sometimes known by the nickname \"Scarface\", was an American gangster and businessman who attained notoriety during the Prohibition era as the co-founder and boss of the Chicago Outfit."]]}, {"qid": "c5e130e153c93e692833", "term": "Grand Theft Auto III", "description": "Open world action-adventure video game", "question": "Would members of Blue Lives Matter support every element of Grand Theft Auto III?", "answer": false, "facts": ["Blue Lives Matter is a countermovement in the United States that supports police officers and law enforcement personnel.", "Grand Theft Auto III allows for gratuitous violence against police officers in the game."], "decomposition": ["Which action against cops are allowed in GTA III?", "What does the Blue Lives Matter movement advocate for?", "Is all of #1 in accordance with #2?"], "evidence": [[[["Grand Theft Auto III-36"]], [["Blue Lives Matter-1"]], ["operation"]], [[["Grand Theft Auto III-36"]], [["Blue Lives Matter-1"]], ["operation"]], [[["Grand Theft Auto III-36"]], [["Blue Lives Matter-1"]], ["operation"]]], "golden_sentence": [["The game also received controversy for its depiction of crime, and allowing violence against police officers."], ["Blue Lives Matter is a countermovement in the United States advocating that those who are prosecuted and convicted of killing law enforcement officers should be sentenced under hate crime statutes."]]}, {"qid": "37673881c0036bffce3b", "term": "Wednesday", "description": "Day of the week", "question": "Does New Year's Day always occur on a Wednesday?", "answer": false, "facts": ["New Year's Day occurs on January 1st each year.", "The day of the week any given date falls on rotates by one each year.", "If Leap Year wasn't breaking up the cycle, New Year's Day would be on a Wednesday every seventh year."], "decomposition": ["What is the date of New Year's Day?", "Does #1 occur on the same day each year?"], "evidence": [[[["New Year's Day-12"]], [["New Year's Day-12"]]], [[["New Year's Day-1"]], ["operation"]], [[["New Year's Day-1"]], [["New Year's Day-4"], "no_evidence", "operation"]]], "golden_sentence": [["This day is traditionally a religious feast, but since the 1900s has also become an occasion to celebrate the night of 31 December\u2014New Year's Eve\u2014with parties, public celebrations (often involving fireworks shows) and other traditions focused on the impending arrival of midnight and the new year."], ["This day is traditionally a religious feast, but since the 1900s has also become an occasion to celebrate the night of 31 December\u2014New Year's Eve\u2014with parties, public celebrations (often involving fireworks shows) and other traditions focused on the impending arrival of midnight and the new year."]]}, {"qid": "44ec5bab0ba6b687d60e", "term": "Tick", "description": "order of arachnids", "question": "Could a nymph tick pass through a standard hole punch?", "answer": true, "facts": ["A nymph tick is the size of a poppy seed.", "A poppy seed is around 1mm in size.", "The ISO 838 standards set a hole punch size at 6 mm."], "decomposition": ["What is a nymph tick comparable in size to?", "How big around is #1?", "What is the diameter of a standard hole punch?", "Is #3 greater than or equal to #2?"], "evidence": [[[["Ixodes pacificus-11"]], [["Ixodes pacificus-11"], "no_evidence"], [["Hole punch-6"]], ["operation"]], [[["Tick-1"], "no_evidence"], [["Tick-1"]], [["Hole punch-10"]], ["operation"]], [[["Tick-1"], "no_evidence"], [["Tick-1"]], [["Hole punch-6"]], ["operation"]]], "golden_sentence": [["Due to the smaller size of the nymphal stage ticks, approximately 2 mm, they are more likely to go unnoticed when attached to a human."], ["Due to the smaller size of the nymphal stage ticks, approximately 2 mm, they are more likely to go unnoticed when attached to a human."], ["Two holes with a diameter of 6\u00b10.5\u00a0mm are punched into the paper."]]}, {"qid": "2c391bc83138f934f965", "term": "Art dealer", "description": "person that buys and sells works of art", "question": "Can an art dealer buy Boeing 737-800 with a Da Vinci painting?", "answer": true, "facts": ["The Boeing 737-800 plane costs 106 million dollars in 2019.", "Salvator Mundi, a painting attributed to Leonardo Da Vinci, is the most expensive painting ever sold.", "Salvator Mundi sold for over 450 million dollars."], "decomposition": ["How much does a  Boeing 737-800 cost?", "How much did Da Vinci's highest priced painting sell for?", "Is #2 more than #1?"], "evidence": [[[["Boeing 737 Next Generation-42"], "no_evidence"], [["Leonardo da Vinci-92"]], ["no_evidence", "operation"]], [["no_evidence"], [["Salvator Mundi (Leonardo)-13"]], ["operation"]], [[["Boeing 737 Next Generation-39"]], [["Leonardo da Vinci-92"]], ["operation"]]], "golden_sentence": [["The 737-800 seats 162 passengers in a two-class layout or 189 passengers in a one-class layout."], ["The highest known sale price for any artwork was previously US$300\u00a0million, for Willem de Kooning's Interchange, which was sold privately in September 2015."]]}, {"qid": "c0c6685bdfb09af180a1", "term": "Brewing", "description": "production of beer", "question": "Should Peter Griffin be an expert at the craft of brewing?", "answer": true, "facts": ["Peter Griffin is an employee of a brewery in Quahog. ", "Peter has worked at the brewery for many years and is expected to be familiar with how beer is made."], "decomposition": ["Where does Peter Griffin work?", "Is #1 a brewery?"], "evidence": [[[["Peter Griffin-2"]], ["operation"]], [[["Jungle Love (Family Guy)-3"]], ["operation"]], [[["Peter Griffin-2"]], ["operation"]]], "golden_sentence": [["He has worked at a toy factory and at Quahog's Brewery."]]}, {"qid": "14a1db88f1abd55a1286", "term": "2008 Summer Olympics", "description": "Games of the XXIX Olympiad, held in Beijing in 2008", "question": "Could you drive a Rowe 550 to the 2008 Summer Olympics?", "answer": true, "facts": ["The Rowe 550 was a car produced by the Chinese SAIC motor company.", "The Rowe 550 debuted at the 2007 Shanghai Auto Show.", "The 2008 Beijing Summer Olympics happened in the Capital of the People's Republic of China."], "decomposition": ["When was the Roewe 550 launched?", "Did the 2008 Summer Olympics hold before or during #1?"], "evidence": [[[["Roewe 550-1"]], [["2008 Summer Olympics-1"], "operation"]], [[["Roewe 550-1"]], [["2008 Summer Olympics-1"], "operation"]], [[["Roewe 550-2"]], ["operation"]]], "golden_sentence": [["The Roewe 550 is a compact car that is produced by Roewe in China, and was launched at the 2008 Beijing Motor Show."], ["The 2008 Summer Olympics (Chinese: \u4e8c\u96f6\u96f6\u516b\u5e74\u590f\u5b63\u5965\u8fd0\u4f1a; pinyin: \u00c8r l\u00edng l\u00edng b\u0101 Ni\u00e1n Xi\u00e0j\u00ec \u00c0oy\u00f9nhu\u00ec), officially known as the Games of the XXIX Olympiad (Chinese: \u7b2c\u4e8c\u5341\u4e5d\u5c4a\u590f\u5b63\u5965\u6797\u5339\u514b\u8fd0\u52a8\u4f1a; pinyin: D\u00ec \u00c8rsh\u00edji\u01d4 Ji\u00e8 Xi\u00e0j\u00ec \u00c0ol\u00ednp\u01d0k\u00e8 Y\u00f9nd\u00f2nghu\u00ec), and commonly known as Beijing 2008 (Chinese: \u5317\u4eac\u4e8c\u96f6\u96f6\u516b; pinyin: B\u011bij\u012bng \u00c8r l\u00edng l\u00edng b\u0101), was an international multi-sport event that was held from 8 to 24 August 2008 in Beijing, China."]]}, {"qid": "3f4f06f08f8c926c68df", "term": "Amy Winehouse", "description": "English singer and songwriter", "question": "Was Amy Winehouse a fan of Star Wars: Rogue One?", "answer": false, "facts": ["Amy Winehouse died in 2011.", "Star Wars: Rogue One was released in 2016."], "decomposition": ["When did Amy Winehouse die?", "When was Star Wars: Rogue One released?", "Is #1 after #2?"], "evidence": [[[["Amy Winehouse-1"]], [["Rogue One-2"]], [["Rogue One-2"], "operation"]], [[["Amy Winehouse-90"]], [["Rogue One-1"]], ["operation"]], [[["Amy Winehouse-1"]], [["Rogue One-3"]], ["operation"]]], "golden_sentence": [["Amy Jade Winehouse (14 September 1983 \u2013 23 July 2011) was an English singer and songwriter."], ["Principal photography on the film began at Pinewood Studios, Buckinghamshire, UK, in early August 2015 and wrapped in February 2016."], ["Based on an idea first pitched by Knoll ten years before it entered development, the film was made to be different in tone and style from the traditional Star Wars films, omitting the customary opening crawl and transitional screen wipes."]]}, {"qid": "54fbd5a53d29864cbb90", "term": "Snoopy", "description": "cartoon dog", "question": "Is Jesse W. Moore a potential recipient of a Snoopy-themed award from NASA?", "answer": false, "facts": ["Snoopy has been a mascot of safety in NASA", "The Silver Snoopy award is given by NASA astronauts to employees and contractors for outstanding achievements related to flight safety ", "Jesse W. Moore received warnings about the failure history of the O rings used on the Challenger shuttle, but did not act on them", "Jesse W. Moore was the associate administrator in charge of NASA's shuttle program at the time of the Challenger explosion", "The O rings were strongly implicated in the fatal explosion"], "decomposition": ["What NASA award is Snoopy-themed?", "What are the qualifications to receive #1?", "What were Jesse W. Moore's mission responsibilities at NASA?", "Did Moore execute #3 according to the guidelines of #2?"], "evidence": [[[["Silver Snoopy award-1"]], [["Silver Snoopy award-1"]], [["Space Shuttle Challenger disaster-76"]], [["Space Shuttle Challenger disaster-1"]]], [[["Silver Snoopy award-1"]], [["Silver Snoopy award-1"]], [["Space Shuttle Challenger disaster-76"]], [["Silver Snoopy award-1", "Space Shuttle Challenger disaster-76"]]], [[["Silver Snoopy award-1"]], [["Silver Snoopy award-8"]], ["no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["The Silver Snoopy award is a special honor awarded to NASA employees and contractors for outstanding achievements related to human flight safety or mission success."], ["The award certificate states that it is \"In Appreciation\" \"For professionalism, dedication and outstanding support that greatly enhanced space flight safety and mission success.\""], ["2 shuttle official, and Jesse W. Moore, the associate administrator in charge of the shuttle program, raising attention to the failure history of the O rings and recommending a review of the matter."], ["The Space Shuttle Challenger disaster was a fatal incident in the United States space program that occurred on Tuesday, January 28, 1986, when the Space Shuttle Challenger (OV-099) broke apart 73 seconds into its flight, killing all seven crew members aboard."]]}, {"qid": "23506d586f694c3fc8ec", "term": "Honey badger", "description": "species of mammal", "question": "Would a honey badger fit inside an oven?", "answer": true, "facts": [" Adult honey badgers measure 23 to 28 cm (9.1 to 11.0 in) in shoulder height and 55\u201377 cm (22\u201330 in) in body length, with the tail adding another 12\u201330 cm (4.7\u201311.8 in).", "Thirty-inch ovens are the standard for most homes and most kitchens. The inside dimensions of the oven are approximately 25 inches wide and 16 inches high. The oven will be approximately 16 inches deep. "], "decomposition": ["What is the average dimmension of a honey badger?", "What are the dimensions of an average oven?", "Is #1 less than #2?"], "evidence": [[[["Honey badger-12"], "no_evidence"], ["no_evidence"], ["no_evidence"]], [[["Honey badger-12"], "no_evidence"], [["Oven-6"], "no_evidence"], ["operation"]], [[["Honey badger-12"]], [["Oven-6"]], ["operation"]]], "golden_sentence": [["The mean weight of adult honey badgers from different areas has been reported at anywhere between 6.4 to 12\u00a0kg (14 to 26\u00a0lb), with a median of roughly 9\u00a0kg (20\u00a0lb), per various studies."]]}, {"qid": "486b0e16b6c36314378c", "term": "Hydropower", "description": "energy derived from falling or running water", "question": "Is chaff produced by hydropower?", "answer": true, "facts": ["Chaff is excess material from milled grain.", "Some mills use hydropower to mill grain."], "decomposition": ["Where does Chaff come from?", "Do some #1's use hydropower to do it's function?"], "evidence": [[[["Chaff-1"]], [["Winnowing (sedimentology)-1"]]], [[["Chaff-1"]], [["Hydropower-1"], "operation"]], [[["Chaff-5"]], [["Hydropower-1"], "operation"]]], "golden_sentence": [["Chaff (/t\u0283\u00e6f/; also UK: /t\u0283\u0251\u02d0f/) is the dry, scaly protective casing of the seeds of cereal grains, or similar fine, dry, scaly plant material such as scaly parts of flowers, or finely chopped straw."], ["This action can improve the sorting and increase the mean grain size of a sediment after it has been deposited."]]}, {"qid": "0ad62a523a3634a2a12a", "term": "Paulo Coelho", "description": "Brazilian lyricist and novelist", "question": "Does Paulo Coelho's wife make a living through speech?", "answer": false, "facts": ["Paulo Coelho's wife is Christina Oiticica.", "Christina Oiticica is a Brazilian artist.", "Artists make a living through drawing things, which is done by their hands.", "Speech is typically performed with one's mouth."], "decomposition": ["Who is Paulo Coelho's wife?", "What does #1 do for a living?", "What body part does she use to do #2?", "What body part do singers use to produce their craft?", "Is #3 the same as #4?"], "evidence": [[[["Paulo Coelho-6"]], [["Christina Oiticica-2"]], [["Christina Oiticica-3"]], [["Origin of speech-14"]], ["operation"]], [[["Paulo Coelho-6"]], [["Christina Oiticica-1"]], [["Painting-1"]], [["Singing-1"]], ["operation"]], [[["Paulo Coelho-6"]], [["Christina Oiticica-4"]], [["Christina Oiticica-3"]], [["Singing-4"]], ["operation"]]], "golden_sentence": [["Coelho married artist Christina Oiticica in 1980."], ["Oiticica is a \"daughter\" of the experimental art movement of the 1970s arisen in Rio de Janeiro, where she was born, and has taken her paintings all around the world."], ["Oiticica idealized the combination of land art \u2013 which uses nature as foundation matter \u2013 with a painting in the French Pyrenees, five years ago, when she decided to paint a 10-meter long canvas in the middle of nature in the open air, as she realized not to have a covered area that would enable her to create on such surface."], ["In humans, the larynx is descended, it is positioned lower than in other primates.This is because the evolution of humans to an upright position shifted the head directly above the spinal cord, forcing everything else downward."]]}, {"qid": "2a7d147c51c82ad1e13d", "term": "Lifeboat (rescue)", "description": "boat rescue craft which is used to attend a vessel in distress", "question": "Can a lifeboat rescue people in the Hooke Sea?", "answer": false, "facts": ["Lifeboats are used on bodies of liquid water", "The Hooke Sea is a geographical feature on the surface of Mars", "There are no bodies of liquid water on Mars"], "decomposition": ["What environment are lifeboats used in?", "Where is the Hooke Sea?", "Is there #1 on #2?"], "evidence": [[[["Lifeboat (rescue)-1"]], ["no_evidence"], ["no_evidence"]], [[["Lifeboat (shipboard)-3"], "no_evidence"], [["Hooke (Martian crater)-1", "Hooke (Martian crater)-2"]], ["operation"]], [[["Lifeboat (shipboard)-1"]], [["Hooke (Martian crater)-1"]], ["operation"]]], "golden_sentence": [["A rescue lifeboat is a boat rescue craft which is used to attend a vessel in distress, or its survivors, to rescue crew and passengers."]]}, {"qid": "bd9ccc3da0f6467dc411", "term": "Fiat Chrysler Automobiles", "description": "Multinational automotive manufacturing conglomerate", "question": "Is Fiat Chrysler associated with Japanese cars?", "answer": false, "facts": ["Fiat Chrysler is composed of the two merged automobile companies Fiat and Chrysler.", "Fiat is an Italian company with headquarters in Amsterdam.", "Chrysler is based in the United States of America.", "Together they own 10 car brands but none are Asian in origin."], "decomposition": ["Which companies merged to form Fiat Chrysler?", "Is any of #1 based in Japan", "Which cars have been produced by Fiat Chrysler?", "Is any of #3 Japanese in origin?", "Is #2 or #4 positive?"], "evidence": [[[["Fiat Chrysler Automobiles-1"]], [["Chrysler-1", "Fiat S.p.A.-1"], "operation"], [["Alfa Romeo 4C-12", "Fiat Chrysler Automobiles-27"], "no_evidence"], ["operation"], ["operation"]], [[["Fiat Chrysler Automobiles-1"]], ["operation"], [["Kid Brands-1"]], ["operation"], ["operation"]], [[["Fiat S.p.A.-1"]], [["Fiat Chrysler Automobiles-1"]], [["Fiat S.p.A.-3"]], ["no_evidence"], ["no_evidence"]]], "golden_sentence": [["The group was established in October 2014 by merging Fiat and Chrysler into a new holding company."], ["In addition to the Chrysler brand, FCA sells vehicles worldwide under the Dodge, Jeep, and Ram nameplates.", "The Fiat Group contained many brands such as Ferrari, Maserati, Fiat, Alfa Romeo, the Chrysler Group, and many more."], ["Delivery of the European Alfa Romeo 4C Launch Edition took place at Balocco (Vercelli, Italy) Test Centre, with vehicles delivered to Pierluigi De Silvestro (Switzerland), Philippe Walch (France), Carlos Diniz (Germany), Aldo Mariani (the Netherlands) and Stefano Zanotti (Italy).", "FCA announced a mid-cycle refresh for both the Giulia and Stelvio for production year 2021."]]}, {"qid": "6396fef048f5231560ed", "term": "Underworld", "description": "The mythic Relm of the Dead, located far underground (aka, Hades; Underworld)", "question": "Would Hades and Osiris hypothetically compete for real estate in the Underworld?", "answer": true, "facts": ["Hades was the Greek god of death and the Underworld.", "Osiris was the Egyptian god of the Underworld."], "decomposition": ["What was Hades the God of?", "What was Osiris the God of?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Hades-1"]], [["Osiris-1"]], ["operation"]], [[["Hades-1"]], [["Osiris-1"]], ["operation"]], [[["Hades-1"]], [["Osiris-1"]], ["operation"]]], "golden_sentence": [["Hades (/\u02c8he\u026adi\u02d0z/; Greek: \u1f8d\u03b4\u03b7\u03c2 H\u00e1d\u0113s; \u1f0d\u03b9\u03b4\u03b7\u03c2 H\u00e1id\u0113s), in the ancient Greek religion and myth, is the god of the dead and the king of the underworld, with which his name became synonymous."], ["Osiris (/o\u028a\u02c8sa\u026ar\u026as/, from Egyptian wsjr, Coptic \u2c9f\u2ca9\u2ca5\u2c93\u2ca3\u2c89) is the god of fertility, agriculture, the afterlife, the dead, resurrection, life, and vegetation in ancient Egyptian religion.", "Osiris was at times considered the eldest son of the god Geb and the sky goddess Nut, as well as being brother and husband of Isis, with Horus being considered his posthumously begotten son.", "Through syncretism with Iah, he is also a god of the Moon."]]}, {"qid": "a5f8af1dd0e9c46c47be", "term": "Orange County, California", "description": "County in California, United States", "question": "Does Orange County, California require airplanes to be quiet?", "answer": true, "facts": ["John Wayne Airport is in Orange County.", "John Wayne Airport is in very close proximity to residential areas.", "There is a General Aviation Noise Ordinance in Orange County, California. ", "Commercial pilots will cut the engine of the aircraft on arrival and departure from Orange County, California. "], "decomposition": ["Which ordinance must airports within or close to Orange County, California abide by?", "What actions do commercial pilots take concerning their engine noise when arriving or departing Orange County, California?", "Does #1 and #2 require that their airplanes make less noise?"], "evidence": [[[["John Wayne Airport-33"]], [["John Wayne Airport-38"]], ["no_evidence"]], [[["Orange County, California-13"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["John Wayne Airport-33"]], [["John Wayne Airport-34"]], ["operation"]]], "golden_sentence": [["The agreement in conjunction with a Phase 2 Commercial Airline Access Plan and Regulation controls the number of noisier operations (mainly commercial aircraft) allowed from the airport."], ["In order to compensate for a short runway, and to comply with local noise restrictions, pilots frequently take off at an angle of 20 to 25 degrees, compared to 10 to 15 degrees at other airports."]]}, {"qid": "f790b706fb7406d30160", "term": "Parc des Princes", "description": "football stadium in Paris, France", "question": "Was the Parc des Princes fully operational during June of 2020?", "answer": false, "facts": ["June of 2020 was marked by a global pandemic.", "During a global pandemic, large events are not permitted to proceed fully."], "decomposition": ["What kind of events are usually held in the Parc des Princes?", "In light of recent developments, are such events as #1 still holding in full capacity as of July, 2020?"], "evidence": [[[["Parc des Princes-1"]], [["Coronavirus disease 2019-1", "Social distancing-15"], "no_evidence", "operation"]], [[["Parc des Princes-1"]], [["Impact of the COVID-19 pandemic on sports-23"], "operation"]], [[["Parc des Princes-1", "Parc des Princes-2"]], ["operation"]]], "golden_sentence": [["The Parc des Princes (French pronunciation:\u00a0\u200b[pa\u0281k de p\u0281\u025b\u0303s], literally \"Princes\u2019 Park\" in English) is an all-seater football stadium in Paris, France."], ["It was first identified in December 2019 in Wuhan, China, and has since spread globally, resulting in an ongoing pandemic.", "Evidence suggesting that mass gatherings increase the potential for infectious disease transmission is inconclusive."]]}, {"qid": "bcd221573f1a6500f2eb", "term": "Retail", "description": "Sale of goods and services from individuals or businesses to the end-user", "question": "Is retail a job anybody can be suited for?", "answer": false, "facts": ["Most retail jobs require employees to be able to lift, push, and pull 25-50 lbs. ", "Retail positions require employees to interact with customers regularly.", "Various disabilities can diminish one's ability to interact with the public."], "decomposition": ["What are some basic skills that a person employed in retail should have?", "Would every person, even the disabled, possess all of #1?"], "evidence": [[[["Retail clerk-2"]], ["operation"]], [[["Retail-50"], "no_evidence"], [["Disability-3"], "no_evidence", "operation"]], [[["Retail-3"]], ["no_evidence", "operation"]]], "golden_sentence": [["They are expected to answer customers' questions concerning location, price, and use of merchandise; to total price and tax on merchandise purchased by customers to determine bill; and to accept payment, make change, and wrap or bag the merchandise for customers."]]}, {"qid": "e18f8956e3fd4e8c50b2", "term": "Gunpowder", "description": "explosive most commonly used as propellant in firearms", "question": "Would an explosion at a gunpowder storage facility result in a supersonic shock wave?", "answer": false, "facts": ["Gunpowder is classified as a low explosive", "Low explosives burn at subsonic speeds"], "decomposition": ["What kind of explosive is gunpowder classifed as?", "Does #1 burn at supersonic rates?"], "evidence": [[[["Gunpowder-3"]], [["Gunpowder-3"]]], [[["Gunpowder-3"]], ["operation"]], [[["Gunpowder-3"]], ["operation"]]], "golden_sentence": [["Gunpowder is classified as a low explosive because of its relatively slow decomposition rate and consequently low brisance."], ["Low explosives deflagrate (i.e., burn) at subsonic speeds, whereas high explosives detonate producing a supersonic shockwave."]]}, {"qid": "4f5f3dc321468c1d052d", "term": "Chlorine", "description": "Chemical element with atomic number 17", "question": "Can you buy chlorine at a dollar store?", "answer": true, "facts": ["Chlorine, when added to water, creates household bleach.", "Household bleach is available at most dollar stores."], "decomposition": ["What type of item is Chlorine?", "Would department would you find #1 in?", "Do dollar stores have #2?"], "evidence": [[[["Chlorine-62"]], [["Cleaning agent-16"], "no_evidence"], ["operation"]], [[["Chlorine-64"]], [["Department store-2"]], [["Dollar Tree-2"]]], [[["Chlorine-4"]], [["Household hardware-1"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["This was not simply modern calcium chloride, but chlorine gas dissolved in lime-water (dilute calcium hydroxide) to form calcium hypochlorite (chlorinated lime)."], ["All-purpose cleansers contain mixtures of anionic and nonionic surfactants, polymeric phosphates or other sequestering agents, solvents, hydrotropic substances, polymeric compounds, corrosion inhibitors, skin-protective agents, and sometimes perfumes and colorants."]]}, {"qid": "b4e6585cdc2765c29070", "term": "Saltwater crocodile", "description": "species of reptile", "question": "Are saltwater crocodiles related to alligators?", "answer": true, "facts": ["Crocodiles belong to the family Crocodylinae.", "Alligators belong to the family Alligatoridae.", "Crocodylinae and Alligatoridae both belong to the order Crocodilia."], "decomposition": ["What family do Crocodiles belong to?", "What family do Alligators belong to?", "What order does #1 belong to?", "What order does #2 belong to?", "Are #3 and #4 the same thing?"], "evidence": [[[["Crocodile-1"]], [["Alligator-1"]], [["Crocodile-1"]], [["Alligator-1"]], ["operation"]], [[["Crocodile-35"]], [["American alligator-5"]], [["Crocodile-35"]], [["Alligator-1"]], ["operation"]], [[["Crocodylidae-1"]], [["Alligator-1"]], [["Crocodilia-1"]], [["Crocodilia-1"]], ["operation"]]], "golden_sentence": [["The term crocodile here applies to only the species within the subfamily of Crocodylinae."], ["An alligator is a crocodilian in the genus Alligator of the family Alligatoridae."], ["The term is sometimes used even more loosely to include all extant members of the order Crocodilia, which includes the alligators and caimans (family Alligatoridae), the gharial and false gharial (family Gavialidae), and all other living and fossil Crocodylomorpha."], ["An alligator is a crocodilian in the genus Alligator of the family Alligatoridae."]]}, {"qid": "3679391b4ff09377acef", "term": "Landscape architect", "description": "person involved in the planning, design and sometimes direction of a landscape, garden, or distinct space", "question": "Would Persephone be a good consultant to a landscape architect?", "answer": true, "facts": ["Persephone is a vegetation goddess. ", "A vegetation deity is a nature deity whose disappearance and reappearance, or life, death and rebirth, embodies the growth cycle of plants.", "Landscape architects deal with planning and laying out gardens and other plant life."], "decomposition": ["Over what domains does Persephone preside?", "Do landscape architects work with any of #1?"], "evidence": [[[["Persephone-1", "Persephone-2"]], [["Landscape architect-1"], "operation"]], [[["Persephone-1"]], [["Landscaping-5"]]], [[["Persephone-1"]], ["operation"]]], "golden_sentence": [["In Greek mythology, Persephone (/p\u0259r\u02c8s\u025bf\u0259ni\u02d0/ p\u0259r-SEF-\u0259-nee; Greek: \u03a0\u03b5\u03c1\u03c3\u03b5\u03c6\u03cc\u03bd\u03b7), also called Kore (/\u02c8k\u0254\u02d0ri\u02d0/ KOR-ee; Greek: \u039a\u03cc\u03c1\u03b7; \"the maiden\"), is the daughter of Zeus and Demeter.", "In some versions, Persephone is the mother of Zeus' son Dionysus, (or Iacchus, and/or Zagreus, as a result of their identification with Dionysus)."], ["The practice of landscape architecture includes: site analysis, site inventory, site planning, land planning, planting design, grading, storm water management, sustainable design, construction specification and ensuring that all plans meet the current building codes and local and federal ordinances."]]}, {"qid": "5d85be9c8f41a21ca293", "term": "Apollo 15", "description": "Fourth crewed mission to land on the Moon", "question": "Would the crew of Apollo 15 have difficulty riding a unicycle?", "answer": true, "facts": ["There were 3 astronauts in the crew of the Apollo 15 mission.", "A unicycle only contains one saddle, and is typically only operated by a single person."], "decomposition": ["What is the maximum number of people that can ride a typical unicycle?", "How many people were on the Apollo 15 crew?", "Is #2 greater than #1?"], "evidence": [[[["Unicycle-1"]], [["Apollo 15-1"]], ["operation"]], [[["Unicycle-1"], "no_evidence"], [["Apollo 15-6"]], ["operation"]], [[["Unicycle-25"]], [["Apollo 15-6"]], ["operation"]]], "golden_sentence": [["A unicycle is a vehicle that touches the ground with only one wheel."], ["Apollo 15 was the ninth crewed mission in the United States' Apollo program, and the fourth to land on the Moon."]]}, {"qid": "4d919e6c4316cb2e1f09", "term": "Frigate", "description": "Type of warship", "question": "Are ropes required to operate a frigate?", "answer": true, "facts": ["Frigates are a kind of sailing ship.", "Many features of ships require rope to use."], "decomposition": ["What force powers frigates?", "What characteristic of frigates allows them to use #1?", "Are ropes used to manipulate #2?"], "evidence": [[[["Sailing-1"]], [["Frigate-6"]], [["Sailing ship-35"], "operation"]], [[["Frigate-11"]], [["Sail-1"]], [["Sail-3"], "no_evidence"]], [[["Full-rigged ship-5"], "no_evidence"], [["Rigging-1"]], ["operation"]]], "golden_sentence": [["Sailing craft and their rigs Sailing employs the wind\u2014acting on sails, wingsails or kites\u2014to propel a craft on the surface of the water (sailing ship, sailboat, windsurfer, or kitesurfer), on ice (iceboat) or on land (land yacht) over a chosen course, which is often part of a larger plan of navigation."], ["The term \"frigate\" (Italian: fregata; Spanish/Catalan/Portuguese/Sicilian: fragata; Dutch: fregat; French: fr\u00e9gate) originated in the Mediterranean in the late 15th century, referring to a lighter galley-type warship with oars, sails and a light armament, built for speed and maneuverability."], ["To adjust the angle of the sail to wind braces are used to adjust the fore and aft angle of a yard of a square sail, while sheets attach to the clews (bottom corners) of a sail to control the sail's angle to the wind."]]}, {"qid": "70642ac7ad94f22b612f", "term": "Jason", "description": "Greek mythological hero", "question": "Does Jason have anything in common with Dr. Disrespect?", "answer": true, "facts": ["Jason cheated on Medea with Creusa", "Dr. Disrespect cheated on his wife with another woman"], "decomposition": ["Was Jason faithful or unfaithful?", "Was Dr. Disrespect faithful or unfaithful?", "Are #1 and #2 the same?"], "evidence": [[[["Medea-10"], "no_evidence"], [["Dr DisRespect-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Jason-3"]], ["no_evidence"], ["operation"]], [[["Jason-18"]], [["Dr DisRespect-5"]], ["operation"]]], "golden_sentence": [["Various sources state that Jason and Medea had between one and fourteen children, including sons Alcimenes, Thessalus, Tisander, Mermeros and Pheres, Medus, and Argos, and a daughter, Eriopis."], ["Herschel \"Guy\" Beahm IV (born March 10, 1982), commonly known by his online alias Dr DisRespect, is an American Twitch streamer and internet personality."]]}, {"qid": "f93ca5fd96248f765ff3", "term": "Spaghetti", "description": "Type of pasta", "question": "Should a Celiac sufferer avoid spaghetti?", "answer": true, "facts": ["Celiac is a disease in which the body cannot process gluten.", "Gluten is a protein found in wheat.", "Spaghetti is made with milled wheat and water."], "decomposition": ["What food ingredients should people with celiac disease avoid?", "What ingredients make up spaghetti?", "Is #2 listed in #1?"], "evidence": [[[["Coeliac disease-2"]], [["Spaghetti-1"]], ["operation"]], [[["Coeliac disease-2"]], [["Spaghetti-1"]], ["operation"]], [[["Coeliac disease-36"]], [["Spaghetti-1"]], ["operation"]]], "golden_sentence": [["Moderate quantities of oats, free of contamination with other gluten-containing grains, are usually tolerated."], ["Like other pasta, spaghetti is made of milled wheat and water and sometimes enriched with vitamins and minerals.", "Italian spaghetti is typically made from durum wheat semolina."]]}, {"qid": "302570f3787646a587df", "term": "Koala", "description": "An arboreal herbivorous marsupial native to Australia.", "question": "Do Koalas prefer Eucalyptus over meat?", "answer": true, "facts": ["Koalas are herbivores.", "Koalas main dietary staple is eucalyptus "], "decomposition": ["What kind of diet do Koalas follow?", "Are Eucalyptus part of #1?"], "evidence": [[[["Koala-2"]], ["operation"]], [[["Koala-2"]], [["Eucalypt-5", "Koala-2"]]], [[["Koala-2"]], ["operation"]]], "golden_sentence": [["Because this eucalypt diet has limited nutritional and caloric content, koalas are largely sedentary and sleep up to 20 hours a day."]]}, {"qid": "48cf1d62fdc4ae46d79e", "term": "Elk", "description": "Large antlered species of deer from North America and east Asia", "question": "Would a body builder prefer an elk burger over a beef burger?", "answer": true, "facts": ["Bodybuilders want to build muscle and keep fat low", "Elk meat is leaner than beef", "Elk meat has higher protein than beef", "Protein helps build muscle"], "decomposition": ["Which nutrients are more important for a body builder's diet?", "How is an elk burger different from a beef burger in terms of nutrients?", "Considering #1 and #2 would an elk burger be a better source of #1?"], "evidence": [[[["Bodybuilding-31", "Bodybuilding-41"]], [["Elk-3"]], [["Bodybuilding-31", "Elk-3"]]], [[["Bodybuilding-41"]], [["Elk-3"]], ["operation"]], [[["Bodybuilding-39"]], [["Elk-3"]], [["Elk-3"], "operation"]]], "golden_sentence": [["Many clean bulk diets start off with a moderate amount of carbs, moderate amount of protein, and a decently low amount of fats.", "That effect is somewhat overcome by combining casein and whey."], ["Their meat is leaner and higher in protein than beef or chicken."], ["A common tactic for keeping fat low and muscle mass high would be to have higher calorie and lower calorie days to maintain a balance between gain and loss.", "Their meat is leaner and higher in protein than beef or chicken."]]}, {"qid": "596b615b7261cb7db9d3", "term": "Mercury (element)", "description": "Chemical element with atomic number 80", "question": "Can you transport a coin along a sea of mercury?", "answer": true, "facts": ["The density of an object determines if it will float.", "An object will float if it is less dense than the liquid it is placed in.", "Mercury is liquid at room temperature.", "The density of mercury is 13.56 g/cm3.", "The density of a penny is 7.15 g/cm3."], "decomposition": ["What is the density of mercury?", "What is the density of a typical coin?", "Is #2 less than #1?", "Considering #3 and the principle of flotation, will the coin float along mercury sea surface?"], "evidence": [[[["Mercury (element)-7"]], [["Quarter (United States coin)-3"]], ["operation"], [["Archimedes' principle-3"], "operation"]], [[["Mercury (element)-7"]], ["no_evidence"], ["no_evidence", "operation"], [["Buoyancy-1"], "operation"]], [[["Mercury (element)-7"]], [["Coin-2", "Metal-9"]], ["operation"], [["Buoyancy-2"], "operation"]]], "golden_sentence": [["Upon freezing, the volume of mercury decreases by 3.59% and its density changes from 13.69\u00a0g/cm3 when liquid to 14.184\u00a0g/cm3 when solid."], ["It weighs 0.2000 avoirdupois oz, 1/80 of a pound, 0.1823\u00a0troy oz, (5.670\u00a0grams)."], ["If this net force is positive, the object rises; if negative, the object sinks; and if zero, the object is neutrally buoyant\u2014that is, it remains in place without either rising or sinking."]]}, {"qid": "42608d4f0243d307f6de", "term": "Olive", "description": "Species of plant", "question": "Would Bugs Bunny harm an olive tree in the real world?", "answer": true, "facts": ["Bugs Bunny is an anthropomorphic gray and white rabbit.", "Rabbits eat the bark of olive trees and can do considerable damage, especially to young trees."], "decomposition": ["What kind of animal is Bugs Bunny?", "Do #1 eat and damage the bark of olive trees?"], "evidence": [[[["Bugs Bunny-2"]], [["Olive-73"]]], [[["Bugs Bunny-2"]], [["Olive-73"], "operation"]], [[["Bugs Bunny-2"]], [["Olive-73"]]]], "golden_sentence": [["Bugs is an anthropomorphic gray and white rabbit or hare who is famous for his flippant, insouciant personality."], ["Rabbits eat the bark of olive trees and can do considerable damage, especially to young trees."]]}, {"qid": "0ff6800fcdbfabb483b8", "term": "Brussels sprout", "description": "vegetable", "question": "Are Brussels sprout particularly good for adrenal fatigue?", "answer": true, "facts": ["Adenal fatigue is a disorder in which the body does not produce enough hormones and people get tired.", "Brussels sprout are foods rich in vitamin C.", "When stress levels rise, the adrenal glands require more Vitamin C and it is used very quickly."], "decomposition": ["What vitamins are found in abundance in Brussels sprouts?", "What vitamins do the adrenal glands require when a body is under stress?", "Is #2 found in #1?"], "evidence": [[[["Brussels sprout-12"]], [["Adrenaline-29"]], ["operation"]], [[["Brussels sprout-12"]], [["Adrenal gland-2"], "no_evidence"], ["no_evidence"]], [[["Brussels sprout-12"]], [["Adrenal fatigue-1", "Adrenal gland-2"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["In a 100 gram reference amount, they supply high levels (20% or more of the Daily Value, DV) of vitamin C (102% DV) and vitamin K (169% DV), with more moderate amounts of B vitamins, such as folate and vitamin B6 (USDA nutrient table, right); essential minerals and dietary fiber exist in moderate to low amounts (table)."], ["Dopamine is then converted to noradrenaline by dopamine beta-hydroxylase which utilizes ascorbic acid (Vitamin C) and copper."]]}, {"qid": "e1be1275b3c816b0b7bf", "term": "Family Guy", "description": "American animated sitcom", "question": "Does Family Guy take place on the American West Coast?", "answer": false, "facts": ["Family Guy takes place in the fictional town of Quahog, Rhode Island.", "Rhode Island is a state on the American East Coast."], "decomposition": ["Where is Family Guy set?", "Is #1 on the American West Coast?"], "evidence": [[[["Family Guy-1"]], [["Rhode Island-1"]]], [[["Rhode Island-89"]], [["West Coast of the United States-1"]]], [[["Family Guy-9"]], [["Rhode Island-34"], "operation"]]], "golden_sentence": [["The show is set in the fictional city of Quahog, Rhode Island, and exhibits much of its surreal and dark humor in the form of metafictional cutaway gags that often lampoon American culture."], ["Rhode Island is bordered by Connecticut to the west, Massachusetts to the north and east, and the Atlantic Ocean to the south via Rhode Island Sound and Block Island Sound."]]}, {"qid": "f7fa93e91293615bc50d", "term": "Mitsubishi", "description": "group of autonomous, Japanese multinational companies", "question": "Can someone in Uberlandia work for Mitsubishi?", "answer": true, "facts": ["Mitsubishi is a Japanese auto manufacturer", "Mitsubishi operates a plant in Catalao, Brazil", "Uberlandia is just under 70 miles from Catalao"], "decomposition": ["How far is Uberlandia from Catalao?", "Is #1 within reasonable distance to commute to work?", "Is there a Mitsubishi organization in Catalao?", "Are #2 and #3 positive?"], "evidence": [[[["Catal\u00e3o-1", "Uberl\u00e2ndia-1"], "no_evidence"], ["operation"], ["no_evidence"], ["operation"]], [[["Catal\u00e3o-4"]], ["operation"], [["Catal\u00e3o-1"]], ["operation"]], [[["Catal\u00e3o-1", "Uberl\u00e2ndia-1"], "no_evidence"], ["no_evidence", "operation"], [["Catal\u00e3o-1"], "operation"], ["no_evidence", "operation"]]], "golden_sentence": [["Catal\u00e3o (Portuguese pronunciation:\u00a0[k\u0250t\u0250\u02c8l\u0250\u0303w]) is a city and municipality located in the south of the state of Goi\u00e1s, in Brazil.", "The city is located on the Brazilian Highlands 2,802 feet (854\u00a0m) above sea level."]]}, {"qid": "e33a81482ffef9456bcc", "term": "Watergate scandal", "description": "Political scandal that occurred in the United States in the 1970s", "question": "Would Hannah Nixon be proud of Richard Nixon following the Watergate scandal?", "answer": false, "facts": ["Hannah Nixon was the mother of Richard Nixon.", "Richard Nixon resigned due to the unethical actions that he committed during the Watergate scandal.", "Parents are typically not proud of their children when they act immorally or unethically."], "decomposition": ["What is Hannah Nixon relation to Richard Nixon?", "What happened to Richard Nixon as a result of the Watergate scandal?", "Why did Richard Nixon have to #2?", "Are #1's usually proud if their child does #3?"], "evidence": [[[["Hannah Milhous Nixon-1"]], [["Richard Nixon-94", "Richard Nixon-95"]], [["Richard Nixon-94"], "operation"], ["operation"]], [[["Hannah Milhous Nixon-1"]], [["Richard Nixon-4"]], [["Richard Nixon-4"]], ["operation"]], [[["Hannah Milhous Nixon-1"]], [["Watergate scandal-66"]], [["Watergate scandal-65"]], ["operation"]]], "golden_sentence": [["Hannah Milhous Nixon (March 7, 1885\u00a0\u2013 September 30, 1967) was the mother of President Richard Nixon."], ["Rhodes told Nixon he faced certain impeachment in the House.", "In light of his loss of political support and the near-certainty that he would be impeached and removed from office, Nixon resigned the presidency on August 9, 1974, after addressing the nation on television the previous evening."], ["In a statement accompanying the release of what became known as the \"Smoking Gun Tape\" on August 5, 1974, Nixon accepted blame for misleading the country about when he had been told of White House involvement, stating that he had had a lapse of memory."]]}, {"qid": "d0e81c46892d0983f1e8", "term": "Eddie Murphy", "description": "American stand-up comedian and actor", "question": "Could Eddie Murphy dial 911 in a car as a young child?", "answer": false, "facts": ["Eddie Murphy was born in 1961.", "Car phones did not become commonplace in cars in America until 1984."], "decomposition": ["What year was Eddie Murphy born in?", "When did car phones become common in American cars?", "Is #1 after #2?"], "evidence": [[[["Eddie Murphy-1"]], [["Car phone-2"]], ["operation"]], [[["Eddie Murphy-1"]], [["Car phone-8"]], ["operation"]], [[["Eddie Murphy-1"]], [["Car phone-4", "Car phone-6"]], ["operation"]], [[["Eddie Murphy-1"]], [["Car phone-8"]], ["operation"]]], "golden_sentence": [["Edward Regan Murphy (born April 3, 1961) is an American actor, comedian, and singer."], ["This service originated with the Bell System, and was first used in St. Louis on June 17, 1946."]]}, {"qid": "1bdcf91a9d90ba61339a", "term": "Edmund Hillary", "description": "New Zealand mountaineer", "question": "Would Mount Wycheproof be a breeze for Edmund Hillary?", "answer": true, "facts": ["Edmund Hillary was a mountaineer that climbed Mount Everest.", "Mount Everest reaches 29,029 feet in the air.", "Mount Wycheproof is the smallest mountain in the world.", "Mount Wycheproof rises a mere 486 feet above sea level."], "decomposition": ["Which famous mountain has Edmund Hillary climbed?", "How tall is #1?", "How tall is Mount Wycheproof?", "Is #3 several thousand feet smaller than #2?"], "evidence": [[[["Edmund Hillary-1"]], [["Mount Everest-2"]], [["Mount Wycheproof-1"]], ["operation"]], [[["Edmund Hillary-1"]], [["Mount Everest-2"]], [["Mount Wycheproof-1"]], ["operation"]], [[["Edmund Hillary-1"]], [["Mount Everest-2"]], [["Mount Wycheproof-3"]], ["operation"]]], "golden_sentence": [["On 29 May 1953, Hillary and Sherpa mountaineer Tenzing Norgay became the first climbers confirmed to have reached the summit of Mount Everest."], ["The current official elevation of 8,848\u00a0m (29,029\u00a0ft), recognised by China and Nepal, was established by a 1955 Indian survey and subsequently confirmed by a Chinese survey in 1975."], ["Mount Wycheproof is a mountain in the small town of Wycheproof, Victoria, Australia, which stands at 43 metres (141\u00a0ft) above the surrounding terrain, making it the smallest mountain in the world."]]}, {"qid": "96844c5fba3f4ebacf0d", "term": "Rainbow", "description": "meteorological phenomenon", "question": "Are flag of Gabon colors found in rainbow?", "answer": true, "facts": ["Rainbows contain the following colors:  red, orange, yellow, green, blue, indigo and violet.", "The flag of Gabon is green, yellow, and blue."], "decomposition": ["What colors are found in a rainbow?", "What colors are in the flag of the country Gabon?", "Are all the colors in #2 found in #1?"], "evidence": [[[["ROYGBIV-1"]], [["Flag of Gabon-3"]], ["operation"]], [[["ROYGBIV-1"]], [["Flag of Gabon-5"]], ["operation"]], [[["ROYGBIV-1"]], [["Flag of Gabon-1"]], ["operation"]]], "golden_sentence": [["ROYGBIV or Roy G. Biv is an acronym for the sequence of hues commonly described as making up a rainbow: red, orange, yellow, green, blue, indigo and violet."], ["It featured a horizontal tricolour identical to the current flag, but with the yellow stripe at the centre narrower than the green and blue bands surrounding it."]]}, {"qid": "1cfd64486a9cabeb7c0c", "term": "Albatross", "description": "Large seabirds in the order Procellariiformes found in the Southern Ocean and the North Pacific", "question": "Do mollymawks live where albatrosses cannot?", "answer": false, "facts": ["A mollymawk is a type of albatross", "Any place inaccessible to albatrosses in general is inaccessible to specific types of albatross"], "decomposition": ["Mollymawks are a type of which animal?", "Is #1 different from an albatross?"], "evidence": [[[["Mollymawk-1"]], ["operation"]], [[["Mollymawk-4"]], [["Mollymawk-4"]]], [[["Mollymawk-1"]], ["operation"]]], "golden_sentence": [["The mollymawks are a group of medium-sized albatrosses that form the genus Thalassarche."]]}, {"qid": "fc0bbbfd4467bd868714", "term": "Curling", "description": "Team sport played on ice", "question": "Is a curling iron necessary in curling?", "answer": false, "facts": ["A curling iron is a tool used to make the hair curly using heat.", "The sport of curling requires curling brooms, stones (rocks), and curling shoes.", "Changing the structure of your hair has no practical benefit to the sport of curling."], "decomposition": ["What equipment is used in the sport of curling?", "Is a curling iron included in #1?"], "evidence": [[[["Curling-31"]], ["operation"]], [[["Curling-1"]], [["Hair iron-1"], "operation"]], [[["Curling-15", "Curling-21", "Curling-28", "Curling-32"]], ["operation"]]], "golden_sentence": [["Modern curling brush handles are usually hollow tubes made of fibreglass or carbon fibre instead of a solid length of wooden dowel."]]}, {"qid": "615aa49cbd52bbe0654b", "term": "Emu", "description": "Large flightless bird endemic to Australia", "question": "Are emus related to elks?", "answer": false, "facts": ["Emus are a type of flightless bird.", "Elks are deer, which are mammals."], "decomposition": ["What type of animal are Emus?", "What type of animals are Elks?", "Are #1 and #2 the same?"], "evidence": [[[["Emu-1"]], [["Elk-1"]], ["operation"]], [[["Emu-2"]], [["Elk-1"]], ["operation"]], [[["Emu-1"]], [["Elk-1"]], ["operation"]]], "golden_sentence": [["The emu (Dromaius novaehollandiae) is the second-largest living bird by height, after its ratite relative, the ostrich."], ["The elk (Cervus canadensis) or wapiti is one of the largest species within the deer family, Cervidae, and one of the largest terrestrial mammals in North America and Northeast Asia."]]}, {"qid": "0f172df66b358ed72ca6", "term": "Salsa (sauce)", "description": "Sauce", "question": "Would the chef at La Grenouille find salsa to be a strange request?", "answer": true, "facts": ["La Grenouille is a classic French cuisine restaurant in NYC.", "Salsa is a staple food in Mexican cuisine."], "decomposition": ["What type of cuisine does La Grenouille serve?", "Would you typically find salsa in #1?"], "evidence": [[[["La Grenouille (restaurant)-3"], "operation"], ["no_evidence"]], [[["La Grenouille (restaurant)-1"]], [["Mexican cuisine-28"]]], [[["La Grenouille (restaurant)-3"]], [["La Grenouille (restaurant)-1", "Salsa-1"]]]], "golden_sentence": [["The menu of La Grenouille is essentially entirely \"haute French cuisine,\" with customer menus presenting the French names of classic and more modern dishes, followed by the English, and an English description."]]}, {"qid": "0abc04530e898056a6c4", "term": "Globalization", "description": "process of international integration arising from the interchange of world views, products, ideas, and other aspects of culture", "question": "Are System of a Down opposed to globalization?", "answer": true, "facts": ["In Boom!, System of a Down condemns globalization.", "The lead vocalist of the band System of a Down is outspoken against globalization. "], "decomposition": ["What is globalization?", "Is the lead vocalist of the band System of a Down against #1?"], "evidence": [[[["Globalization-1"]], [["Serj Tankian-38"], "no_evidence", "operation"]], [[["Globalization-1"]], [["Serj Tankian-1", "Serj Tankian-16"], "no_evidence", "operation"]], [[["Globalization-1"]], [["System of a Down-32"]]]], "golden_sentence": [["Globalization or globalisation is the process of interaction and integration among people, companies, and governments worldwide.", "As a complex and multifaceted phenomenon, globalization is considered by some as a form of capitalist expansion which entails the integration of local and national economies into a global, unregulated market economy.", "Globalization is primarily an economic process of interaction and integration that's associated with social and cultural aspects."], ["In the 2008 Democratic Party primaries Tankian originally supported Rep. Dennis Kucinich from Ohio, and subsequently stated that Barack Obama \"presents the best possible scenario for a hopeful future, but I don't personally put my trust in any political office.\""]]}, {"qid": "fda4d970e12b123e59e6", "term": "New England", "description": "Region in the northeastern United States", "question": "Can someone from New England profit by growing coffee?", "answer": false, "facts": ["Coffee can only be grown in subtropical and equatorial climates", "New England is located in a humid continental climate"], "decomposition": ["What climates does coffee grow in?", "What kind of climate does New England have?", "Is #1 the same as #2?"], "evidence": [[[["Coffee-30"]], [["Climate of New England-2"]], ["operation"]], [[["Coffee-28"]], [["Climate of New England-4"]], ["operation"]], [[["Coffee bean-9"]], [["England-43"]], ["operation"]]], "golden_sentence": [["Additionally, Coffea canephora is less susceptible to disease than C. arabica and can be cultivated in lower altitudes and warmer climates where C. arabica will not thrive."], ["Maine, Vermont, New Hampshire, and Interior northern Massachusetts have a humid continental climate (Dfb in K\u00f6ppen climate classification)."]]}, {"qid": "ff21df087958bda81be8", "term": "Table tennis", "description": "Racket sport", "question": "Does table tennis use prime numbers?", "answer": true, "facts": ["A table tennis game is won by the player first scoring 11 points.", "11 is a prime number."], "decomposition": ["What are the scores that can be awarded in a game of table tennis?", "Is any of #1 a prime number?"], "evidence": [[[["Table tennis-9"]], [["Prime number-13"], "operation"]], [[["Table tennis-24"]], ["operation"]], [[["Table tennis-24"]], ["operation"]]], "golden_sentence": [["A few months later, the ITTF changed from a 21-point to an 11-point scoring system (and the serve rotation was reduced from five points to two), effective in September 2001."], ["No even number n {\\displaystyle n} greater than 2 is prime because any such number can be expressed as the product 2 \u00d7 n / 2 {\\displaystyle 2\\times n/2} ."]]}, {"qid": "e5dff908bcbcccd5b9a6", "term": "Church of Satan", "description": "international organization dedicated to the religion of Satanism", "question": "Is being 5 year Capital One Venture member more cost effective than being in Church of Satan?", "answer": false, "facts": ["The Capital One Venture card has an annual fee of around $95.", "The Church of Satan has a one time lifetime membership fee of $225."], "decomposition": ["What is the Church of Satan's lifetime membership fee?", "How much does being a Capital One Venture member cost per year?", "What is #2 times 5?", "Is #3 less than #1?"], "evidence": [[[["Church of Satan-23"]], ["no_evidence"], ["operation"], ["operation"]], [[["Church of Satan-23"]], [["Credit card-71"], "no_evidence"], ["operation"], ["operation"]], [[["Church of Satan-23"]], [["Capital One-6"], "no_evidence"], ["operation"], ["operation"]]], "golden_sentence": [["Timeline Membership to the Church is gained by paying $225 and filling out a registration statement, and thus initiates are bestowed with lifetime memberships and not charged annual fees."]]}, {"qid": "f2eac6cbbde0c16b8ff1", "term": "Electronic dance music", "description": "broad category of electronic music", "question": "Did Beethoven enjoy listening to EDM?", "answer": false, "facts": ["Ludwig van Beethoven died in 1827.", "EDM originated in the mid-to-late 20th century."], "decomposition": ["When did Ludwig van Beethoven die?", "When did EDM originate?", "Is #1 after #2?"], "evidence": [[[["Death of Ludwig van Beethoven-15"]], [["Trap music (EDM)-1"]], ["operation"]], [[["Ludwig van Beethoven-61"]], [["Electronic dance music-2"]], ["operation"]], [[["Ludwig van Beethoven-1"]], [["Electronic dance music-2"]], ["operation"]]], "golden_sentence": [["The funeral was held on 29 March 1827 at the parish church in Alsergrund, and he was buried in the W\u00e4hring cemetery, northwest of Vienna."], ["Trap EDM is a style of electronic dance music (EDM) that originated in the mid-2000s and early 2010s."]]}, {"qid": "d60720f31550d49b03d8", "term": "Metallica", "description": "American heavy metal band", "question": "Is Metallica protective over their music?", "answer": true, "facts": ["Napster was a P2P music sharing service.", "Metallica sued Napster in order to remove their songs from the program, as they were not getting profit from it."], "decomposition": ["What did Metallica do in response to Napster hosting their songs?", "Did #1 involve legal action?"], "evidence": [[[["Metallica v. Napster, Inc.-1"]], [["Lawsuit-1"], "operation"]], [[["Metallica-3"]], ["operation"]], [[["Metallica-3"]], [["Metallica-29"]]]], "golden_sentence": [["Metallica vs. Napster, Inc. was the first case that involved an artist suing a peer-to-peer file sharing (\"P2P\") software company."], ["The term \"lawsuit\" is used in reference to a civil action brought in a court of law in which a plaintiff, a party who claims to have incurred loss as a result of a defendant's actions, demands a legal or equitable remedy."]]}, {"qid": "6252e913d7d9401e582f", "term": "Kelly Clarkson", "description": "American singer-songwriter, actress, and television personality", "question": "Has Kelly Clarkson outsold season 4 American Idol winner?", "answer": false, "facts": ["Carrie Underwood was the winner of the fourth season of American Idol.", "Carrie Underwood has sold a little over 65 million albums.", "Kelly Clarkson has sold a little over 25 million albums."], "decomposition": ["Who was the season 4 American Idol winner?", "How many albums has Kelly Clarkson sold?", "How many albums by #1 have been sold?", "Is #2 more than #3?"], "evidence": [[[["American Idol (season 4)-20"]], [["Kelly Clarkson-3"]], [["Carrie Underwood-79"]], ["operation"]], [[["American Idol (season 4)-1"]], [["Kelly Clarkson-3"]], [["Carrie Underwood-3"]], ["operation"]], [[["American Idol (season 4)-1"]], [["Kelly Clarkson-3"]], [["Carrie Underwood-3"]], ["operation"]]], "golden_sentence": [["The winner of the competition was Carrie Underwood, who would eventually become the second \"Idol\" winner to sweep all three major music awards (American Music, Billboard, and Grammy Award) in a single season (for 2006-07)."], ["Clarkson has sold over 25 million albums and 40 million singles worldwide."], ["In the US, she has sold 20 million albums and over 40 million singles, making her the best-selling artist of the American Idol franchise, with Billboard calling her the ultimate Idol success story."]]}, {"qid": "4b66ebd989be42113847", "term": "European wildcat", "description": "Small wild cat", "question": "Do black-tailed jackrabbits fear the European wildcat?", "answer": false, "facts": ["The European wildcat is native to continental Europe, Scotland, Turkey and the Caucasus.", "The black-tailed jackrabbit is native to Mexico and the western United States."], "decomposition": ["What is the range of the black-tailed jackrabbit?", "What is the range of the European wildcat?", "Does #1 and #2 overlap?"], "evidence": [[[["Black-tailed jackrabbit-1"]], [["European wildcat-1"]], ["operation"]], [[["Black-tailed jackrabbit-1"]], [["European wildcat-1"]], ["operation"]], [[["Black-tailed jackrabbit-1"]], [["European wildcat-1"]], ["operation"]]], "golden_sentence": [["The black-tailed jackrabbit (Lepus californicus), also known as the American desert hare, is a common hare of the western United States and Mexico, where it is found at elevations from sea level up to 10,000\u00a0ft (3,000\u00a0m)."], ["The European wildcat (Felis silvestris) is a wildcat species native to continental Europe, Scotland, Turkey and the Caucasus."]]}, {"qid": "c23b892b2ce50d0582d1", "term": "Carl Friedrich Gauss", "description": "German mathematician and physicist", "question": "Could Carl Friedrich Gauss speak to someone 100 miles away?", "answer": false, "facts": ["Carl Friedrich Gauss was born in 1777.", "Speaking to someone 100 miles away requires a telephone.", "The telephone was invented in 1876."], "decomposition": ["What device allows people to speak to each other even if they are 100 miles apart?", "When was #1 invented?", "When did Carl Friedrich Gauss die?", "Is #2 before #3?"], "evidence": [[[["Telephone-1"]], [["Telephone-19"]], [["Carl Friedrich Gauss-13"]], ["operation"]], [[["Telephone-1"]], [["Telephone-22"]], [["Carl Friedrich Gauss-13"]], ["operation"]], [[["Telephone-1"]], [["Alexander Graham Bell-31"]], [["Carl Friedrich Gauss-1"]], ["operation"]]], "golden_sentence": [["A telephone (derived from the Greek: \u03c4\u1fc6\u03bb\u03b5, t\u0113le, \"far\" and \u03c6\u03c9\u03bd\u03ae, ph\u014dn\u0113, \"voice\", together meaning \"distant voice\"), or phone, is a telecommunications device that permits two or more users to conduct a conversation when they are too far apart to be heard directly."], ["Alexander Graham Bell was the first to be awarded a patent for the electric telephone by the United States Patent and Trademark Office (USPTO) in March 1876."], ["On 23 February 1855, Gauss died of a heart attack in G\u00f6ttingen (then Kingdom of Hanover and now Lower Saxony); he is interred in the Albani Cemetery there."]]}, {"qid": "d24a5b996aaa758bbc80", "term": "Lionel Richie", "description": "American singer-songwriter, musician, record producer and actor", "question": "Is Lionel Richie related to Sheila E?", "answer": false, "facts": ["Lionel Richie is an American singer and raised Nicole Richie.", "Nicole Richie was born to Sheila E's brother, Peter Michael Escovedo.", "Lionel Richie adopted Nicole Richie from Peter Michael Escovedo.", "Adoptive parents are not considered related to birth parents."], "decomposition": ["What is the relationship between Lionel Richie and Nicole Richie?", "Are #1 considered related to birth parents?"], "evidence": [[[["Lionel Richie-27"]], [["Adoption-1"], "operation"]], [[["Nicole Richie-3"]], ["operation"]], [[["Lionel Richie-27"]], [["Adoption-1"]]]], "golden_sentence": [["In 1983 the couple informally adopted Nicole Camille Escovedo, the two-year-old daughter of one of the members of Lionel's band, and niece of drummer Sheila E. They raised her as their daughter, Nicole Richie, and adopted her legally when she was nine years old."], ["Legal adoptions permanently transfer all rights and responsibilities, along with filiation, from the biological parent or parents."]]}, {"qid": "e0c10e16a23989f7a583", "term": "Roman numerals", "description": "Numbers in the Roman numeral system", "question": "Does the FDA require sell by dates using Roman Numerals?", "answer": false, "facts": ["There are no requirements for food to have sell by dates. ", "Sell by dates on most food items are written using arabic numerals."], "decomposition": ["Is there any regulation on the sell by dates of food products?"], "evidence": [[["no_evidence"]], [[["Shelf life-1", "Shelf life-31"], "operation"]], [[["Shelf life-31"]]]], "golden_sentence": []}, {"qid": "7f457f00fa010a9dd2e8", "term": "Sea shanty", "description": "work song sung to accompany labor on board large merchant sailing vessels", "question": "Did travelers sing sea shanties on the Oregon Trail?", "answer": false, "facts": ["Sea shanties are sung on seaborne vessels", "The Oregon Trail was a land-based emigration trail"], "decomposition": ["In what mode of travel are sea shanties typically sang?", "What mode of travel was mostly used on the Oregon Trail?", "Is #1 the same as #2?"], "evidence": [[[["Sea shanty-1"]], [["Oregon Trail-1"]], ["operation"]], [[["Sea Songs-3"]], [["Oregon Trail-116"]], ["operation"]], [[["Sea shanty-1"]], [["Oregon Trail-1"]], ["operation"]]], "golden_sentence": [["A sea shanty, chantey, or chanty is a type of work song that was once commonly sung to accompany labor on board large merchant sailing vessels."], ["The Oregon Trail is a 2,170-mile (3,490\u00a0km) historic east-west, large-wheeled wagon route and emigrant trail in the United States that connected the Missouri River to valleys in Oregon."]]}, {"qid": "c0e0a030b4bc54ef6d3b", "term": "Flag of the United States", "description": "National flag", "question": "Would someone with leukophobia enjoy looking at the Flag of the United States?", "answer": false, "facts": ["Leukophobia is a fear of the color white.", "The United States flag is colored red, white, and blue.", "People do not typically enjoy facing their fears."], "decomposition": ["What does someone suffering from leukophobia fear?", "What are the colors of the United States flag?", "Is #1 included in #2?"], "evidence": [[[["Chromophobia-8"]], [["Flag of the United States-1"]], ["operation"]], [[["Chromophobia-3"]], [["Flag of the United States-40"]], ["operation"]], [[["Chromophobia-3"]], [["Flag of the United States-1"]], ["operation"]]], "golden_sentence": [["In other cases, leukophobia is directed more towards the symbolic meaning of whiteness, for instance in individuals who associate the color white with chastity and are opposed to or fear chastity."], ["It consists of thirteen equal horizontal stripes of red (top and bottom) alternating with white, with a blue rectangle in the canton (referred to specifically as the \"union\") bearing fifty small, white, five-pointed stars arranged in nine offset horizontal rows, where rows of six stars (top and bottom) alternate with rows of five stars."]]}, {"qid": "fb3862c0ef8ef7e95bce", "term": "Desperate Housewives", "description": "American comedy-drama TV series", "question": "Did Teri Hatcher last twice as many episodes on Desperate Housewives as her Superman show?", "answer": true, "facts": ["Actress Teri Hatcher completed a total of 180 episodes of Desperate Housewives.", "Teri Hatcher starred in Lois & Clark: The New Adventures of Superman based on the Superman comic.", "Teri Hatcher was in 87 episodes of Lois & Clark: The New Adventures of Superman."], "decomposition": ["How many episodes of Desperate Housewives did Teri Hatcher appear in?", "What show did Teri Hatcher appear in that is based on a Superman comic?", "How many episodes of #2 did Teri Hatcher appear in?", "What is #3 multiplied by 2?", "Is #1 greater than or equal to #4?"], "evidence": [[[["Desperate Housewives-1", "Susan Mayer-1"]], [["Lois & Clark: The New Adventures of Superman-1"]], [["The Booth at the End-21"]], ["operation"], ["operation"]], [[["Teri Hatcher-1"]], [["Lois & Clark: The New Adventures of Superman-1"]], [["Teri Hatcher-1"], "no_evidence"], ["operation"], ["operation"]], [[["Desperate Housewives-1"], "no_evidence"], [["Teri Hatcher-9"]], [["Lois & Clark: The New Adventures of Superman-1"], "no_evidence"], ["operation"], ["operation"]]], "golden_sentence": [["It originally aired for eight seasons on ABC from October 3, 2004 until May 13, 2012 for a total of eight seasons and 180 episodes.", "She first appeared in the pilot episode of the series on October 3, 2004, and appeared in every episode until the series finale on May 13, 2012."], ["Lois & Clark: The New Adventures of Superman is an American superhero television series based on the DC Comics character Superman created by Jerry Siegel and Joe Shuster."], ["The fifth and final episode of Season 2 aired on September 3, 2012."]]}, {"qid": "f37c8f9e4fc20479b06c", "term": "White blood cell", "description": "type of cells of the immunological system", "question": "Do white blood cells outnumber red blood cells in the human body?", "answer": false, "facts": ["Red blood cells are about 40-50% of what makes up human blood.", "White blood cells make up about 1% of the blood in a human body."], "decomposition": ["What percent of blood by volume is made up of white blood cells?", "What percent of blood by volume is red blood cells?", "Is #1 greater than #2?"], "evidence": [[[["White blood cell-3"]], [["White blood cell-3"]], [["White blood cell-3"]]], [[["Blood-8"]], [["Blood-8"]], ["operation"]], [[["White blood cell-3"]], [["White blood cell-3"]], ["operation"]]], "golden_sentence": [["White blood cells make up approximately 1% of the total blood volume in a healthy adult, making them substantially less numerous than the red blood cells at 40% to 45%."], ["White blood cells make up approximately 1% of the total blood volume in a healthy adult, making them substantially less numerous than the red blood cells at 40% to 45%."], ["However, this 1% of the blood makes a large difference to health, because immunity depends on it."]]}, {"qid": "798529ef6d7ff2162dad", "term": "Cornwall", "description": "County of England", "question": "Was John George Bice's birthplace near Cornwall?", "answer": true, "facts": ["Politician John George Bice was born in Callington.", "Cornwall is a place located in South West England.", "Callington is a small town in South East Cornwall."], "decomposition": ["Where was John George Bice born?", "Is #1 located close to Cornwall?"], "evidence": [[[["John George Bice-2"]], ["operation"]], [[["John George Bice-2"]], [["John George Bice-2"]]], [[["John George Bice-2"]], [["Callington-1"]]], [[["John George Bice-2"]], [["John George Bice-2"]]]], "golden_sentence": [["Bice was born in Callington, Cornwall, the son of Samuel Sandoe Bice (died 1903), a mining captain who was brought out to South Australia in 1864 to work for the Wallaroo and Moonta Mining Company, and for whom he worked for more than 50 years."]]}, {"qid": "c8eac5cc49c449e28e6e", "term": "History of Europe", "description": "History of Europe from the beginnings of recorded history", "question": "Does the history of Europe include the age of dinosaurs?", "answer": false, "facts": ["Dinosaurs went extinct many millions of years ago.", "In contrast, ancient humans only started recording history several thousand years ago."], "decomposition": ["When did the dinosaurs exist?", "When did humans first colonize Europe?", "Is #2 contained within the range of #1?"], "evidence": [[[["Dinosaur-1"]], [["Europe-29"]], ["operation"]], [[["Dinosaur-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Dinosaur-1"]], [["Hominid dispersals in Europe-10"]], ["operation"]]], "golden_sentence": [["They first appeared during the Triassic period, between 243 and 233.23\u00a0million years ago, although the exact origin and timing of the evolution of dinosaurs is the subject of active research."], ["The European Bronze Age began c. 3200 BC in Greece with the Minoan civilisation on Crete, the first advanced civilisation in Europe."]]}, {"qid": "55ac71fc1cd8fdc34e8c", "term": "Urban planner", "description": "professional who works on city planning", "question": "Would Paul Bunyan hypothetically be a poor choice for an urban planner?", "answer": true, "facts": ["Paul Bunyan was a legendary giant from tall tale stories.", "Urban planners need to design buildings and ceilings in cities.", "Paul Bunyan lived in the country side with a giant blue ox.", "New York city apartment ceilings average around 8 feet in height.", "Paul Bunyan was over seven feet tall."], "decomposition": ["What environments are urban planners experts of?", "Did Paul Bunyan live or work in #1?"], "evidence": [[[["Urban planner-1", "Urban planner-2"]], [["Paul Bunyan-1"], "operation"]], [[["Urban planner-2"]], [["Paul Bunyan-1"], "operation"]], [[["Urban planner-2"], "no_evidence"], [["Lumberjack-5", "Paul Bunyan-1"], "operation"]]], "golden_sentence": [["An urban planner or an urban planning engineer is a professional who practices in the field of urban planning.", "An urban planner may focus on a specific area of practice and have a title such as city planner, town planner, regional planner, long-range planner, transportation planner, infrastructure planner, environmental planner, parks planner, physical planner, health planner, planning analyst, urban designer, community development director, economic development specialist or other similar combinations."], ["Paul Bunyan is a giant lumberjack in American and Canadian folklore."]]}, {"qid": "a68facab7157ed7e520e", "term": "Atmosphere of Mars", "description": "atmosphere", "question": "Are all the elements plants need for photosynthesis present in atmosphere of Mars?", "answer": true, "facts": ["Plants need three elements for photosynthesis: Hydrogen, Oxygen, and Carbon.", "The atmosphere of Mars is composed of carbon dioxide, nitrogen, argon, and trace levels of water vapor, oxygen, carbon monoxide, hydrogen and other noble gases."], "decomposition": ["What are the elements needed by plants need for photosynthesis?", "Which elements are found in the atmosphere?", "Are #1 included in #2?"], "evidence": [[[["Photosynthesis-11"]], [["Atmosphere of Mars-11"]], ["operation"]], [[["Photosynthesis-72"], "no_evidence", "operation"], [["Atmosphere-14"], "operation"], ["no_evidence"]], [[["Photosynthesis-10"]], [["Atmosphere-14"]], ["operation"]]], "golden_sentence": [["CO2carbon dioxide + H2O water + photonslight energy \u2192 [CH2O]carbohydrate + O2 oxygen Other processes substitute other compounds (such as arsenite) for water in the electron-supply role; for example some microbes use sunlight to oxidize arsenite to arsenate: The equation for this reaction is:"], ["The hydroxyl radicals (OH) produced from the photolysis of water vapor, together with the other odd hydrogen species (e.g."]]}, {"qid": "ec06b5fcf3cdef642f6e", "term": "Bill Nye", "description": "American science educator, comedian, television host, actor, writer, scientist and former mechanical engineer", "question": "Did Bill Nye vote for Franklin Delano Roosevelt?", "answer": false, "facts": ["Bill Nye was born in 1955", "Franklin Delano Roosevelt's last election was in 1944"], "decomposition": ["When was the last time Franklin Delano Roosevelt contested in an election?", "When was Bill Nye born?", "Is #1 at least 18 years after #2?"], "evidence": [[[["Franklin D. Roosevelt-89"]], [["Bill Nye-1"]], ["operation"]], [[["1944 United States presidential election-1"]], [["Bill Nye-1"]], ["operation"]], [[["Franklin Delano Roosevelt Jr.-15"]], [["Bill Nye-1"]], ["operation"]]], "golden_sentence": [["While some Democrats had opposed Roosevelt's nomination in 1940, the president faced little difficulty in securing his re-nomination at the 1944 Democratic National Convention."], ["William Sanford Nye (born November 27, 1955), popularly known as Bill Nye the Science Guy, is an American science communicator, television presenter, and mechanical engineer.", "He is best known as the host of the PBS and syndicated children's science show Bill Nye the Science Guy (1993\u20131998), the Netflix show Bill Nye Saves the World (2017\u20132018), and for his many subsequent appearances in popular media as a science educator."]]}, {"qid": "09734b1d720aa09e8ef2", "term": "Romani people", "description": "Ethnic group living mostly in Europe and the Americas", "question": "Is the use of the word Gypsy by non-Romani people considered okay?", "answer": false, "facts": ["'Gypsy' is considered a slur in the Americas by Romani people.", "Lady Gaga has faced online criticism regarding her use of the word 'Gypsy' as the title and lyrics of a song."], "decomposition": ["What kind of word is Gypsy considered in the Americas by Romani people?", "Would using #1 types of words be considered okay?"], "evidence": [[[["Names of the Romani people-11"], "no_evidence"], [["Antiziganism-1"]]], [[["Names of the Romani people-11"]], ["operation"]], [[["Names of the Romani people-11"]], [["Pejorative-1"], "operation"]]], "golden_sentence": [["The English term gipsy or gypsy is commonly used to indicate Romani people, Tinkers and Travellers, and use of the word gipsy in modern-day English is so pervasive (and is a legal term under English law\u2014see below) that some Romani organizations use it in their own organizational names."], ["Antiziganism (also antigypsyism, anti-Romanyism, Romaphobia, or anti-Romani sentiment) is hostility, prejudice, discrimination or racism which is specifically directed at Romani people (Roma, Sinti, Iberian Kale, Welsh Kale, Finnish Kale and Romanichal)."]]}, {"qid": "7e7ba5f2d4c84b9e2259", "term": "Land of Israel", "description": "Traditional Jewish name for an area of indefinite geographical extension in the Southern Levant.", "question": "Was Land of Israel in possession of an Islamic empire in 16th century?", "answer": true, "facts": ["Land of Israel was controlled by the Ottoman Empire in 16th century. ", "The religion of Ottoman Empire was Sunni Islam. "], "decomposition": ["Who ruled the geographic region of Israel in the 16th century?", "Was Islam the state religion of #1?"], "evidence": [[[["Israel-23", "Palestine (region)-20"]], [["Ottoman Empire-93"], "operation"]], [[["Israel-22"]], [["Ottoman Empire-96"], "no_evidence"]], [[["Israel-22"]], [["Ottoman Empire-96"], "operation"]]], "golden_sentence": [["During the 16th century, Jewish communities struck roots in the Four Holy Cities\u2014Jerusalem, Tiberias, Hebron, and Safed\u2014and in 1697, Rabbi Yehuda Hachasid led a group of 1,500 Jews to Jerusalem.", "Between the mid-16th and 17th centuries, a close-knit alliance of three local dynasties, the Ridwans of Gaza, the Turabays of al-Lajjun and the Farrukhs of Nablus, governed Palestine on behalf of the Porte (imperial Ottoman government)."], ["In the Ottoman imperial system, even though there existed a hegemonic power of Muslim control over the non-Muslim populations, non-Muslim communities had been granted state recognition and protection in the Islamic tradition."]]}, {"qid": "cc56bc3a2a756fcc8dec", "term": "Zucchini", "description": "Edible summer squash, typically green in color", "question": "Would 7 zucchini's satisfy potassium USDA daily recommendation?", "answer": true, "facts": ["The USDA recommends at least 3500 mg of potassium a day.", "One zucchini has 512 mg of potassium."], "decomposition": ["How much potassium is in a zucchini?", "How much potassium does the USDA recommend daily?", "Would seven times #1 be more than #2?"], "evidence": [[[["Zucchini-27"], "no_evidence"], [["Dietary Reference Intake-10"], "no_evidence"], ["no_evidence", "operation"]], [[["Zucchini-27"]], ["no_evidence"], ["operation"]], [["no_evidence"], [["Potassium-46"], "operation"], ["no_evidence"]]], "golden_sentence": [["Zucchini are low in food energy (approximately 71\u00a0kJ or 17\u00a0kcal (or \"food calories\") per 100\u00a0g (3.5\u00a0oz) fresh zucchini) and contain useful amounts of folate (24\u00a0\u03bcg/100\u00a0g), potassium (261\u00a0mg/100\u00a0g), and provitamin A (200\u00a0IU [10 RAE]/100 g)."], ["EARs, RDA/AIs and ULs for an average healthy 44-year-old male are shown below."]]}, {"qid": "8803ea63343c400758cf", "term": "Mini", "description": "British car model made by the British Motor Corporation (BMC) and its successors from 1959 until 2000", "question": "Was the British car, the Mini, the first car manufactured?", "answer": false, "facts": ["The first car widely manufactured was the Model T.", "The Model T was manufactured in 1908.", "The Mini was made beginning in 1959."], "decomposition": ["When was the first car manufactured?", "When was the Mini first manufactured?", "Is #2 the same as #1?"], "evidence": [[[["Nicolas-Joseph Cugnot-3"]], [["Mini-1"]], ["operation"]], [[["Car-24"]], [["Mini-1"]], ["operation"]], [[["Car-2"]], [["Mini-1"]], ["operation"]]], "golden_sentence": [["A small version of his three-wheeled fardier \u00e0 vapeur (\"steam dray\") was made and used in 1769 (a fardier was a massively built two-wheeled horse-drawn cart for transporting very heavy equipment, such as cannon barrels)."], ["The Mini is a small economy car produced by the English-based British Motor Corporation (BMC) and its successors from 1959 until 2000."]]}, {"qid": "e8d245781a7fd9e38701", "term": "Paprika", "description": "spice made from dried fruits of Capsicum annuum", "question": "Can Paprika be made without a dehydrator?", "answer": true, "facts": ["Peppers can be dehydrated in the oven in lieu of a dehydrator.", "Sunlight and heat have been used for centuries to dry peppers and other foods."], "decomposition": ["What is paprika made from?", "Can #1 be dehydrated without using a dehydrator?"], "evidence": [[[["Paprika-4"], "no_evidence"], ["no_evidence", "operation"]], [[["Paprika-1"]], [["Food dehydrator-2"], "no_evidence", "operation"]], [[["Paprika-1"]], ["no_evidence"]]], "golden_sentence": [["Sweet paprika is mostly composed of the pericarp, with more than half of the seeds removed, whereas hot paprika contains some seeds, stalks, placentas, and calyces."]]}, {"qid": "19b40f33fa199c1673fd", "term": "Bengal cat", "description": "Breed of cat", "question": "Can a Bengal cat survive eating only pancakes?", "answer": false, "facts": ["Bengal cats are carnivores.", "Pancakes contain no meat.", "Carnivores eat only meat to survive. "], "decomposition": ["What type of diet does a Bengal cats follow?", "What do #1 mainly eat?", "Do pancakes contain #2?"], "evidence": [[[["Bengal cat-1"]], [["Cat food-9"]], ["operation"]], [[["Bengal cat-1", "Cat-1"]], [["Carnivore-1"]], [["Pancake-1"], "operation"]], [[["Bengal cat-1", "Carnivore-7"]], [["Carnivore-7"]], [["Pancake-1"]]]], "golden_sentence": [["The Bengal cat is a domesticated cat breed created from hybrids of domestic cats, especially the spotted Egyptian Mau, with the Asian leopard cat (Prionailurus bengalensis)."], ["The natural diet of cats therefore does not include any vegetable matter, although cats have been known to eat certain plants and grasses occasionally, usually as an emetic."]]}, {"qid": "6fe610c55315019e87e5", "term": "Bucharest", "description": "Capital of Romania", "question": "Could a wandering albatross fly from Bucharest to New York City without a rest?", "answer": true, "facts": ["Wandering albatross can travel at least 15,000 km (just under 10,000 miles) over the sea before returning to land. ", "It's 4766 miles or 7670 km from Bucharest to New York City."], "decomposition": ["How far can a Wandering albatross travel over the sea before returning to land?", "How far is it from Bucharest to New York City", "Is #2 less than #1?"], "evidence": [[[["Wandering albatross-4"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Wandering albatross-8"], "no_evidence"], [["Bucharest-1", "New York City-1"], "no_evidence", "operation"], ["no_evidence", "operation"]], [[["Wandering albatross-5"]], ["no_evidence"], ["operation"]]], "golden_sentence": [["As a result of its wingspan, it is capable of remaining in the air without flapping its wings for several hours at a time (travelling 22\u00a0m for every metre of drop)."]]}, {"qid": "dca3c4acc079bb11689b", "term": "New York Public Library", "description": "Public library system in New York City", "question": "Does the New York Public Library sell Alpo products?", "answer": false, "facts": ["The New York Public Library is a public lending library system in New York City", "Alpo produces pet food and related products"], "decomposition": ["What does The New York Public Library offer for customers?", "What kinds of products does Alpo make?", "Is there any overlap between #1 and #2?"], "evidence": [[[["New York Public Library-30", "New York Public Library-31"]], [["Alpo (pet food)-1"]], ["operation"]], [[["New York Public Library-3"]], [["Alpo (pet food)-1"]], ["operation"]], [[["New York Public Library-19", "New York Public Library-28"]], [["Alpo (pet food)-1"]], ["operation"]]], "golden_sentence": [["The Library website provides access to the library's catalogs, online collections and subscription databases.", "The NYPL gives cardholders free access from home to thousands of current and historical magazines, newspapers, journals and reference books in subscription databases, including EBSCOhost, which contains full text of major magazines; full text of the New York Times (1995\u2013present), Gale's Ready Reference Shelf which includes the Encyclopedia of Associations and periodical indexes, Books in Print; and Ulrich's Periodicals Directory."], ["The brand is offered as a canned or packaged soft food, as well as in dry kibbles."]]}, {"qid": "9ebaee3511157e78ec7b", "term": "Tony Bennett", "description": "American singer", "question": "Is Tony Bennett's middle name shared by a former UFC champion?", "answer": true, "facts": ["Tony Bennett's full name is Anthony Dominick Benedetto.", "Dominick Cruz is a two-time UFC Bantamweight Champion."], "decomposition": ["What is Tony Bennett's middle name?", "What are the names of the former UFC champions?", "Is #1 found in #2?"], "evidence": [[[["Tony Bennett-1"]], [["Dominick Cruz-1"]], ["operation"]], [[["Tony Bennett-1"]], [["Dominick Cruz-1"]], ["operation"]], [[["Tony Bennett-1"]], [["Dominick Reyes-1"], "no_evidence"], ["operation"]]], "golden_sentence": [["Anthony Dominick Benedetto (born August 3, 1926), known professionally as Tony Bennett, is an American singer of traditional pop standards, big band, show tunes, and jazz."], ["He is a two-time UFC Bantamweight Champion and was also the final bantamweight titleholder of World Extreme Cagefighting (WEC)."]]}, {"qid": "53f2558c6a9d6c3b0a81", "term": "Peach", "description": "species of fruit tree (for the fruit use Q13411121)", "question": "Would a black widow woman have use for peaches?", "answer": true, "facts": ["A black widow woman refers to a woman who murders her husbands for money and remarries.", "Peach pits contain amygdalin, a type of cyanide.", "Cyanide is poisonous to humans."], "decomposition": ["What is a black widows main goal?", "What do peach pits contain?", "If a human ate #2, would #1 occur?"], "evidence": [[[["Stacey Castor-31"]], [["Amygdalin-5"]], [["Amygdalin-3"]]], [["no_evidence"], [["Amygdalin-2", "Peach-2", "Peach-22"], "no_evidence"], ["no_evidence", "operation"]], [[["Black Widow Murders-1"]], [["Peach (fruit)-16"]], ["operation"]]], "golden_sentence": [["He described a \"black widow\" type as a woman who kills husbands or lovers for material gain, as opposed to the typical serial killer (men who kill consecutively for sexual or sadistic motives)."], ["Amygdalin is contained in stone fruit kernels, such as almonds, apricot (14\u00a0g/kg), peach (6.8\u00a0g/kg), and plum (4\u201317.5\u00a0g/kg depending on variety), and also in the seeds of the apple (3\u00a0g/kg) ."], ["Scientific study has found them to be clinically ineffective in treating cancer, as well as potentially toxic or lethal when taken by mouth due to cyanide poisoning."]]}, {"qid": "2b73dae1804aae94e1ba", "term": "Burning Man", "description": "annual experimental festival based in Nevada, United States", "question": "Are people more likely than normal to get sunburn at Burning Man?", "answer": true, "facts": ["Burning Man often attracts lots of young people who are typically wearing minimal clothing due to the weather and for style. ", "Burning Man festivities occur in the hot summer sun and are often not in shaded areas."], "decomposition": ["What style of clothing do people wear to the burning man festival?", "Sun burning occurs easily while wearing what style of clothing?", "Is #1 and #2 the same?"], "evidence": [[[["Burning Man-37"], "no_evidence"], [["Nudity-1", "Swimsuit-2"], "no_evidence"], ["operation"]], [[["Burning Man-37"]], [["Sunburn-36"]], ["operation"]], [[["Burning Man-37"]], [["Bikini-71"]], [["Sunburn-26"], "operation"]]], "golden_sentence": [["The event is clothing-optional and public nudity is common, though not practiced by the majority."], ["In some societies, partial nudity is defined as not covering other parts of the body that are deemed to be sexual.", "A swimsuit can be worn as an undergarment in sports that require a wetsuit such as water skiing, scuba diving, surfing, and wakeboarding."]]}, {"qid": "243e3e1ef3fb7190ace3", "term": "Rahul Dravid", "description": "Indian cricketer", "question": "Did Rahul Dravid ever kick a field goal?", "answer": false, "facts": ["Rahul Dravid was a professional cricket player", "Field goal kicks are part of American football"], "decomposition": ["Which sport does Rahul Dravid play?", "Does #1 involve field goal kicks?"], "evidence": [[[["Rahul Dravid-1"]], [["Field goal-1"], "operation"]], [[["Rahul Dravid-1"]], [["Cricket-1", "Field goal-1"], "operation"]], [[["Rahul Dravid-1"]], [["Field goal-1"]]]], "golden_sentence": [["Rahul Sharad Dravid (/\u02ccr\u0259hu\u02d0l dr\u0259v\u026ad/ (listen); born 11 January 1973) is a former Indian cricketer and captain of the Indian national team."], ["To score a field goal, the team in possession of the ball must place kick, or drop kick, the ball through the goal, i.e., between the uprights and over the crossbar."]]}, {"qid": "62e8d2b87e80f78b152c", "term": "Oceanography", "description": "The study of the physical and biological aspects of the ocean", "question": "Does an individual oceanographer study many sciences?", "answer": true, "facts": ["Study of the oceans involve many fields or science.", "To properly study their specific topic of research, an oceanographer must understand how their science interacts with the other involved sciences."], "decomposition": ["What other fields of science does oceanography cover?", "Does an individual oceanographer have to understand all of #1 to properly understand oceanography?"], "evidence": [[[["Oceanography-1"]], ["operation"]], [[["Oceanography-1"]], [["Oceanography-1"]]], [[["Oceanography-1"]], ["operation"]]], "golden_sentence": [["It is an important Earth science, which covers a wide range of topics, including ecosystem dynamics; ocean currents, waves, and geophysical fluid dynamics; plate tectonics and the geology of the sea floor; and fluxes of various chemical substances and physical properties within the ocean and across its boundaries.", "These diverse topics reflect multiple disciplines that oceanographers blend to further knowledge of the world ocean and understanding of processes within: astronomy, biology, chemistry, climatology, geography, geology, hydrology, meteorology and physics.", "An oceanographer is a person who studies many matters concerned with oceans including marine geology, physics, chemistry and biology ."]]}, {"qid": "3a93c4d5d6dca707a016", "term": "Superhero fiction", "description": "Fiction genre", "question": "Was Superhero fiction invented in the digital format?", "answer": false, "facts": ["The Golden Age of comics occurred between the 1930's and the 1950's.", "Shatter was the first digitally drawn, commercially published comic."], "decomposition": ["In which format was superhero fiction first introduced?", "During which period were #1 first published and made popular?", "When was the first digitally drawn #1 published?", "Is #2 after #3?"], "evidence": [[[["Superhero fiction-21"]], [["Comic book-5"]], [["Shatter (digital comic)-2"]], ["operation"]], [[["Superhero fiction-21"]], [["Superhero fiction-21"]], [["Digital comic-4"]], ["operation"]], [[["Superhero-1"]], [["Superhero-1"]], ["no_evidence"], ["operation"]]], "golden_sentence": [["The most direct antecedents are pulp magazine crime fighters such as the masked and caped Zorro (introduced by Johnston M. McCulley in 1919 with The Curse of Capistrano) with his trademark \"Z,\" the preternaturally mesmeric The Shadow (1930), the \"peak human\" Doc Savage (1933), and The Spider (1933), and comic strip characters such as Hugo Hercules, Popeye, and the Phantom."], ["The Silver Age lasted through the late 1960s or early 1970s, during which time Marvel Comics revolutionized the medium with such naturalistic superheroes as Stan Lee and Jack Kirby's Fantastic Four and Lee and Steve Ditko's Spider-Man."], ["Until the late 1970s to early 1980s computer generated comics were done with traditional text and line-printing techniques or semigraphics, ascii art, and BBC's ceefax teletext."]]}, {"qid": "e45dd0b92d16cd22ea02", "term": "American black bear", "description": "species of bear", "question": "Could two newborn American Black Bear cubs fit on a king size bed?", "answer": true, "facts": ["The average size of an American Black Bear cub is only 8 inches at birth.", "King size beds are 76\"x80\" in size."], "decomposition": ["What is the average length of an American Black Bear cub?", "What is the size of a king bed?", "Is two times #1 smaller than #2?"], "evidence": [[[["American black bear-29"]], [["Bed size-6"]], ["operation"]], [[["American black bear-19"]], [["Bed size-17"]], [["Bed size-17"], "operation"]], [[["American black bear-29"]], [["Bed size-23"]], ["operation"]]], "golden_sentence": [["At birth, cubs weigh 280\u2013450\u00a0g (0.62\u20130.99\u00a0lb) and measure 20.5\u00a0cm (8.1\u00a0in) in length."], ["In most countries, using the International System of Units, bed dimensions most often appear in centimetres, and often only by width and length."]]}, {"qid": "8efd6e6c6c104be8f9fe", "term": "Aldi", "description": "Germany-based supermarket chain", "question": "Are Aldi's foods discounted due to being out of date?", "answer": false, "facts": ["Aldi cuts costs by charging for bags, buying in bulk, and by avoiding brand name items. ", "Aldi removes spoiled or expired foods from their shelves immediately upon identification."], "decomposition": ["How does Aldi cut cost?", "Is selling discounted food part of #1?"], "evidence": [[[["Aldi-33"]], [["Aldi-25", "Aldi-27"], "operation"]], [[["Aldi-5"]], ["operation"]], [[["Aldi-27"]], [["Aldi-27"]]]], "golden_sentence": [["It claims this is a cost saving that can be passed on to consumers."], ["On 9 August 2018, Aldi announced plans to expand its product selection by offering more organic, fresh and easy-to-prepare meals.", "Aldi stores are noted as examples of so-called no-frills stores that often display a variety of items at discount prices, specializing in staple items, such as food, beverages, toilet paper, sanitary articles, and other inexpensive household items."]]}, {"qid": "896b0fa12e06b67a1b91", "term": "Black pepper", "description": "species of plant", "question": "Are ground bell peppers the main ingredient of black pepper?", "answer": false, "facts": ["Black pepper is made from black peppercorns.", "Black peppercorns grow on the Piper Nigrum plant.", "Bell peppers are from the capsicum annuum plant."], "decomposition": ["What is used to make black pepper?", "Is #1 the same thing as bell pepper?"], "evidence": [[[["Black pepper-1"]], [["Bell pepper-1"], "operation"]], [[["Black pepper-1"]], [["Bell pepper-1"], "operation"]], [[["Black pepper-1"]], [["Bell pepper-1"]]]], "golden_sentence": [["Black pepper (Piper nigrum) is a flowering vine in the family Piperaceae, cultivated for its fruit, known as a peppercorn, which is usually dried and used as a spice and seasoning.", "Peppercorns and the ground pepper derived from them may be described simply as pepper, or more precisely as black pepper (cooked and dried unripe fruit), green pepper (dried unripe fruit), or white pepper (ripe fruit seeds)."], ["The bell pepper (also known as sweet pepper, pepper or capsicum /\u02c8k\u00e6ps\u026ak\u0259m/) is the fruit of plants in the Grossum cultivar group of the species Capsicum annuum."]]}, {"qid": "0dc86ca8b9eb2c1f99dd", "term": "Kinetic energy", "description": "Energy in motion Or Object In Motion", "question": "Does taking ukemi halt kinetic energy?", "answer": false, "facts": ["\"Taking ukemi\" refers to the art of falling or receiving in martial arts", "Taking ukemi usually requires the person doing it to move their body in a way that minimizes injury, and so it uses kinetic energy"], "decomposition": ["What does the term 'taking ukemi' refer to?", "What state of an object indicates exertion of kinetic energy?", "Can #1 be executed while avoiding #2?"], "evidence": [[[["Uke (martial arts)-3"]], [["Kinetic energy-1"]], ["operation"]], [[["Uke (martial arts)-3"]], [["Kinetic energy-1"]], ["no_evidence"]], [[["Uke (martial arts)-3"]], [["Kinetic energy-1"]], [["Uke (martial arts)-4"], "operation"]]], "golden_sentence": [["Literally translated as \"receiving body\", it is the art of knowing how to respond correctly to an attack and often incorporates skills to allow one to do so safely."], ["In physics, the kinetic energy (KE) of an object is the energy that it possesses due to its motion."]]}, {"qid": "ba2a5930ff574802a3da", "term": "Casablanca", "description": "City / State in Casablanca-Settat, Morocco", "question": "Is it hard to get a BLT in Casablanca?", "answer": true, "facts": ["A BLT is a sandwich consisting of bacon, lettuce and tomato", "Casablanca is predominantly Muslim", "Islam forbids the consumption of pork and pork products"], "decomposition": ["What is the predominant religion of Casablanca?", "What dietary restrictions does #1 impose?", "What all goes on a BLT?", "Are there items common to both #2 and #3?"], "evidence": [[[["Casablanca-43"]], [["Islamic culture-45"]], [["BLT-1"]], ["operation"]], [[["Casablanca-43"]], [["Haram-13"]], [["BLT-7"]], ["operation"]], [[["Casablanca-43"]], [["Islamic culture-45"]], [["BLT-1"]], [["Bacon-1"]]]], "golden_sentence": [["99.9% of the population of Morocco are Arab and Berber Muslims."], ["Muslims are restricted in their diet."], ["A BLT is a type of sandwich, named for the initials of its primary ingredients, bacon, lettuce and tomato."]]}, {"qid": "4d52dbeb76f228b14998", "term": "Snowdon", "description": "highest mountain in Wales", "question": "Would the yearly precipitation on Snowdon submerge an upright bowling pin?", "answer": true, "facts": ["Snowdown gets about 200 inches of precipitation a year ", "A standard bowling pin is one foot, three inches tall"], "decomposition": ["How much precipitation does Snowdown get yearly?", "How tall is a standard bowling pin?", "Is #1 more than #2?"], "evidence": [[[["Snowdon-9"]], [["Bowling pin-2"]], [["Bowling pin-2", "Snowdon-9"]]], [[["Snowdon-9"]], [["Bowling pin-2"]], ["operation"]], [[["Snowdon-9"]], [["Bowling pin-2"]], ["operation"]]], "golden_sentence": [["The slopes of Snowdon have one of the wettest climates in Great Britain, receiving an annual average of more than 200 inches (5,100\u00a0mm) of precipitation."], ["Pins are 4.75 inches (121\u00a0mm) wide at their widest point and 15 inches (380\u00a0mm) tall."], ["The weight of the pin was originally based on the idea that a single pin should be around 24 percent the weight of the heaviest bowling ball within regulation, 16\u00a0lb 0\u00a0oz (7.", "The English name \"Snowdon\" comes from the Old English snaw dun, meaning \"snow hill\", as Snowdon often has a covering of snow."]]}, {"qid": "1eb877fa5b2962f5e5a9", "term": "Stanley Baldwin", "description": "Former Prime Minister of the United Kingdom", "question": "Was a woman Prime Minister directly before or after Stanley Baldwin?", "answer": false, "facts": ["Stanley Baldwin was preceded by Ramsay MacDonald as Prime Minister.", "Stanley Baldwin was succeeded as Prime Minister by Neville Chamberlain."], "decomposition": ["Who was the Prime Minister before Stanley Baldwin?", "Who was the Prime Minister after Stanley Baldwin?", "Was #1 a woman?", "Was #2 a woman?", "Is the answer to either #3 or #4 yes?"], "evidence": [[[["Ramsay MacDonald-1"]], [["Neville Chamberlain-1"]], ["operation"], ["operation"], ["operation"]], [[["Ramsay MacDonald-1", "Ramsay MacDonald-1", "Stanley Baldwin-5"]], [["Neville Chamberlain-3"]], [["Ramsay MacDonald-1"]], [["Neville Chamberlain-8"]], ["operation"]], [[["Stanley Baldwin-14"]], [["Sir Roger Conant, 1st Baronet-3"]], ["operation"], ["operation"], ["operation"]]], "golden_sentence": [["James Ramsay MacDonald FRS (n\u00e9 James McDonald Ramsay; 12 October 1866\u00a0\u2013 9 November 1937) was a British statesman who was the first Labour Party politician to become Prime Minister of the United Kingdom, leading minority Labour governments for nine months in 1924 and then in 1929\u201331."], ["Arthur Neville Chamberlain FRS (/\u02c8t\u0283e\u026amb\u0259rl\u026an/; 18 March 1869\u00a0\u2013 9 November 1940) was a British Conservative politician who served as Prime Minister of the United Kingdom from May 1937 to May 1940."]]}, {"qid": "6208234549bac8cc46da", "term": "Eagle", "description": "large carnivore bird", "question": "Would  bald eagle deliver an urgent message before B-52?", "answer": false, "facts": ["A bald eagle can travel up to 99 MPH.", "The B-52 is a US air bomber that can travel up to 650 MPH."], "decomposition": ["How fast can an eagle travel?", "How fast can a B-52 travel?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Eagle Flight-6"], "no_evidence"], [["B-52 (cocktail)-10"], "no_evidence"], ["no_evidence"]], [["no_evidence"], [["Boeing B-52 Stratofortress-6"]], ["operation"]]], "golden_sentence": []}, {"qid": "a9d22dce3199e77dd271", "term": "Professional boxing", "description": "sport", "question": "Can professional boxers expect to have low dental bills?", "answer": false, "facts": ["Professional boxers often receive punches to their face.", "Even with a mouth guard, dental injuries occur often in boxing.", "The average cost for one dental crown is between $500-$3000"], "decomposition": ["What types of injuries are professional boxers likely to sustain?", "Are #1 inexpensive to treat?"], "evidence": [[[["Boxing-63"]], [["History of dental treatments-6"]]], [[["Boxing-82"]], ["operation"]], [[["Boxing-63"]], [["Dental insurance-1"]]]], "golden_sentence": [["Both fighters must wear soft soled shoes to reduce the damage from accidental (or intentional) stepping on feet."], ["Br\u00e5nemark observed that bone had grown into such close proximity with the titanium that it effectively adhered to the metal."]]}, {"qid": "14bfe3d51a876549fc0a", "term": "Dr. Seuss", "description": "American children's writer and illustrator", "question": "Did Dr. Seuss live a tragedy free life?", "answer": false, "facts": ["Dr. Seuss's wife committed suicide.", "In his later years, Dr. Seuss was diagnosed with cancer."], "decomposition": ["Was Dr. Seuss' life free of tragic occurrences?"], "evidence": [[[["Dr. Seuss-20"]]], [[["Dr. Seuss-20"]]], [[["Dr. Seuss-22"], "no_evidence"]]], "golden_sentence": [["Dimond added that Geisel \"lived his whole life without children and he was very happy without children.\""]]}, {"qid": "157b095bcd5d48c694f5", "term": "Jackson Pollock", "description": "American painter", "question": "Were Jackson Pollock's parents not required to say The Pledge of Allegiance as children?", "answer": true, "facts": ["Jackson Pollock's parents were both born and grew up in Tingley, Iowa.", "All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools."], "decomposition": ["What state did Jackson Pollock's parents grow up in?", "What states do not require the pledge to be recited in school?", "Is #1 in the list in #2?"], "evidence": [[[["Jackson Pollock-4"]], [["Pledge of Allegiance-2"]], ["operation"]], [[["Jackson Pollock-4"]], [["Pledge of Allegiance-2"]], ["operation"]], [[["Jackson Pollock-4"]], [["Pledge of Allegiance-2"]], ["operation"]]], "golden_sentence": [["His parents, Stella May (n\u00e9e McClure) and LeRoy Pollock, were born and grew up in Tingley, Iowa, and were educated at Tingley High School.", "He subsequently grew up in Arizona and Chico, California."], ["All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools."]]}, {"qid": "5787a201b7da5929cb75", "term": "San Diego County, California", "description": "County in California, United States", "question": "Is San Diego County the home of a Shamu?", "answer": true, "facts": ["Shamu is the name of Sea World's mascot orca.", "Every Sea World has a Shamu.", "There is a Sea World location in San Diego."], "decomposition": ["What is Shamu the name of?", "Where can you find #1?", "Is there a #2 in San Diego?"], "evidence": [[[["Shamu-1"]], [["SeaWorld San Diego-1", "SeaWorld-1"]], ["operation"]], [[["Shamu-1"]], [["Captive killer whales-19"]], [["SeaWorld San Diego-1"]]], [[["Shamu-1"]], [["SeaWorld San Diego-27"]], [["SeaWorld San Diego-27"], "operation"]]], "golden_sentence": [["Shamu /\u0283\u00e6mu\u02d0/ was a killer whale (orca) that appeared in shows at SeaWorld San Diego in the mid/late 1960s."], ["SeaWorld San Diego is an animal theme park, oceanarium, outside aquarium and marine mammal park, in San Diego, California, United States, inside Mission Bay Park.", "There are operations located within the United States in Orlando, Florida; San Diego, California; San Antonio, Texas; later outside the United States such as Abu Dhabi, United Arab Emirates; and previously Aurora, Ohio."]]}, {"qid": "81f2c649b9f61e019fcf", "term": "Flying Spaghetti Monster", "description": "Chief deity of Pastafarianism", "question": "Is the Flying Spaghetti Monster part of an ancient pantheon?", "answer": false, "facts": ["Ancient polytheistic religions are generally no longer popular in Western culture.", "The Church of the Flying Spaghetti Monster was established in 2006 after the creation of the FSM itself in 2005."], "decomposition": ["What time period is considered ancient?", "What religion is the Flying Spaghetti Monster part of?", "Was #2 established during #1?"], "evidence": [[[["Ancient history-2"]], [["Flying Spaghetti Monster-1"]], [["Flying Spaghetti Monster-3"], "operation"]], [[["Ancient history-2"]], [["Flying Spaghetti Monster-1"]], [["Ancient history-2", "Flying Spaghetti Monster-2"], "operation"]], [[["Ancient history-2"]], [["Flying Spaghetti Monster-5"]], ["operation"]]], "golden_sentence": [["Ancient history covers all continents inhabited by humans in the period 3000 BC \u2013 AD 500."], ["The Flying Spaghetti Monster (FSM) is the deity of the Church of the Flying Spaghetti Monster, or Pastafarianism.", "According to adherents, Pastafarianism is a \"real, legitimate religion, as much as any other\".", "In August 2018 the Dutch Council of State also ruled that Pastafarianism is not a religion."], ["Pastafarian tenets (generally satires of creationism) are presented on Henderson's Church of the Flying Spaghetti Monster website, where he is described as \"prophet\", in The Gospel of the Flying Spaghetti Monster, written by Henderson in 2006, and in The Loose Canon, the Holy Book of the Church of the Flying Spaghetti Monster."]]}, {"qid": "1d07c9eb265c6cdc3947", "term": "Elizabeth II", "description": "Queen of the United Kingdom and the other Commonwealth realms", "question": "Does Elizabeth II reign over the Balearic Islands?", "answer": false, "facts": ["Queen Elizabeth II is the monarch of the United Kingdom and its commonwealth", "The Balearic Islands are part of the country of Spain"], "decomposition": ["What are all the areas Queen Elizabeth II rules over?", "What country owns the Balearic Islands?", "Is #2 included in #1?"], "evidence": [[[["Monarchy of the United Kingdom-1"]], [["Balearic Islands-1"]], ["operation"]], [[["Commonwealth realm-1"]], [["Balearic Islands-3"]], ["operation"]], [[["Commonwealth realm-1"]], [["Balearic Islands-1"]], ["operation"]]], "golden_sentence": [["The monarchy of the United Kingdom, commonly referred to as the British monarchy, is the constitutional monarchy of the United Kingdom, its dependencies (the Bailiwick of Guernsey, the Bailiwick of Jersey and the Isle of Man) and its overseas territories."], ["The Balearic Islands (/\u02ccb\u00e6li\u02c8\u00e6r\u026ak/ BAL-ee-ARR-ik, also US: /\u02ccb\u0251\u02d0l-/ BAHL-, UK: /b\u0259\u02c8l\u026a\u0259r\u026ak/ b\u0259-LEER-ik; Catalan: Illes Balears [\u02c8i\u028e\u0259z b\u0259l\u0259\u02c8as]; Spanish: Islas Baleares [\u02c8izlaz \u03b2ale\u02c8a\u027ees]) are an archipelago of Spain in the western Mediterranean Sea, near the eastern coast of the Iberian Peninsula."]]}, {"qid": "8c115e85cf8c30135bf4", "term": "Football War", "description": "1969 War between Honduras and El Salvador", "question": "Did the Football War last at least a month?", "answer": false, "facts": ["The Football War began on July 14 1969.", "It ended on July 20 1969.", "Therefore, it did not even last a whole week."], "decomposition": ["How long did the Football War last?", "Is #1 greater than or equal to a month?"], "evidence": [[[["Football War-1"]], ["operation"]], [[["Football War-1"]], ["operation"]], [[["Football War-1"]], ["operation"]]], "golden_sentence": [["The Football War (Spanish: La guerra del f\u00fatbol; colloquial: Soccer War or the Hundred Hours' War also known as 100 Hour War) was a brief war fought between El Salvador and Honduras in 1969."]]}, {"qid": "2b98270f27a5263b991f", "term": "Patronage", "description": "support that one organization or individual bestows to another", "question": "Was Lorenzo de Medici's patronage of Da Vinci exclusive?", "answer": false, "facts": ["Lorenzo de Medici was a great patron of the arts in Florence and served as a patron for Leonardo Da Vinci.", "Lorenzo de Medici was also a patron of the artist Sandro Boticelli.", "Leonardo Da Vinci had many patrons including Ludovico Sforza and Cesare Borgia."], "decomposition": ["What artists did Lorenzo de Medici support?", "How many people are listed in #1?", "Is #2 equal to one?"], "evidence": [[[["Lorenzo de' Medici-1"]], [["Lorenzo de' Medici-1"]], ["operation"]], [[["Lorenzo de' Medici-13"]], ["operation"], ["operation"]], [[["Lorenzo de' Medici-1"]], ["operation"], ["operation"]]], "golden_sentence": [["Also known as Lorenzo the Magnificent (Lorenzo il Magnifico [lo\u02c8r\u025bntso il ma\u0272\u02c8\u0272i\u02d0fiko]) by contemporary Florentines, he was a magnate, diplomat, politician and patron of scholars, artists, and poets.", "As a patron, he is best known for his sponsorship of artists such as Botticelli and Michelangelo."], ["Lorenzo de' Medici (Italian pronunciation:\u00a0[lo\u02c8r\u025bntso de \u02c8m\u025b\u02d0dit\u0283i], 1 January 1449 \u2013 8 April 1492) was an Italian statesman, de facto ruler of the Florentine Republic and the most powerful and enthusiastic patron of Renaissance culture in Italy."]]}, {"qid": "9f141949c05a47064fa9", "term": "Last Supper", "description": "Final meal that, in the Gospel accounts, Jesus shared with his apostles in Jerusalem before his crucifixion", "question": "Is anyone at the Last Supper celebrated in Islam?", "answer": true, "facts": ["The Last Supper was a meal between Jesus and his twelve disciples in Christianity.", "In Islam, Jesus is one of many revered prophets.", "In Islam, Jesus returns in a Second Coming to fight the \"False Messiah\" and establish peace on earth."], "decomposition": ["Who was present at the Last Supper?", "Are any of #1 celebrated in Islam?"], "evidence": [[[["Last Supper-1"]], [["Jesus-4"], "operation"]], [[["Last Supper-1"]], [["Jesus in Islam-2"]]], [[["Apostles-1", "Last Supper-1"]], [["Disciples of Jesus in Islam-1"], "no_evidence", "operation"]]], "golden_sentence": [["The Last Supper is the final meal that, in the Gospel accounts, Jesus shared with his apostles in Jerusalem before his crucifixion."], ["Most Muslims do not believe that he was crucified, but that he was physically raised into Heaven by God."]]}, {"qid": "b37207ee5c3ebd455355", "term": "Bengal cat", "description": "Breed of cat", "question": "Would a Bengal cat be afraid of catching a fish?", "answer": false, "facts": ["Fish live in water. ", "Many Bengal owners say that their Bengal naturally retrieves items.", "Bengal cats often enjoy playing in water."], "decomposition": ["Where do fish live?", "What do bengal cats naturally do when they see something?", "Would a bengal cat be able to #2 from #1?"], "evidence": [[[["Fish-1"]], [["Bengal cat-20"], "no_evidence"], ["no_evidence", "operation"]], [[["Fish-1"]], [["Bengal cat-20"]], [["Bengal cat-20"], "operation"]], [[["Fish-5"]], [["Bengal cat-20", "Bengal cat-21"]], ["operation"]]], "golden_sentence": [["Fish are gill-bearing aquatic craniate animals that lack limbs with digits."], ["Many Bengal owners say that their Bengal naturally retrieves items, and they often enjoy playing in water."]]}, {"qid": "71e6d5a927e7241c8f59", "term": "Benito Mussolini", "description": "Fascist leader of Italy", "question": "Did Benito Mussolini wear bigger shoes than Haf\u00fe\u00f3r Bj\u00f6rnsson?", "answer": false, "facts": ["Benito Mussolini was 5' 6\u200b1\u20442\" tall.", "Haf\u00fe\u00f3r Bj\u00f6rnsson is 6 feet 9 inches tall.", "Shoe size increases proportionally as height increases."], "decomposition": ["How tall was Benito Mussolini?", "How tall is Haf\u00fe\u00f3r Bj\u00f6rnsson?", "Is #2 smaller than #1?"], "evidence": [[[["Benito Mussolini-8"], "no_evidence"], [["Haf\u00fe\u00f3r J\u00fal\u00edus Bj\u00f6rnsson-5"]], ["operation"]], [[["Benito Mussolini-1"], "no_evidence"], [["Haf\u00fe\u00f3r J\u00fal\u00edus Bj\u00f6rnsson-19"]], ["no_evidence", "operation"]], [["no_evidence"], [["Haf\u00fe\u00f3r J\u00fal\u00edus Bj\u00f6rnsson-5"]], ["no_evidence", "operation"]]], "golden_sentence": [["Benito Mussolini's father, Alessandro Mussolini, was a blacksmith and a socialist, while his mother, Rosa (n\u00e9e Maltoni), was a devout Catholic schoolteacher."], ["At 2.06\u00a0m (6\u00a0ft 9\u00a0in), he started his senior team career with Division I club Brei\u00f0ablik in 2004, playing as a center."]]}, {"qid": "bdaf032b5e375aeb9bfa", "term": "Bobby Jindal", "description": "American politician", "question": "Would Bobby Jindal's high school mascot eat kibble?", "answer": true, "facts": ["Bobby Jindal attended Baton Rouge Magnet High School.", "Baton Rouge Magnet High School's mascot is the bulldog.", "Kibble is another name for the dry form of dog/pet food."], "decomposition": ["Which school did Bobby Jindal attend?", "What is #1's mascot?", "What does kibble refer to?", "Would a #2 eat #3?"], "evidence": [[[["Bobby Jindal-7"]], ["no_evidence"], [["Kibbles 'n Bits-1"]], ["operation"]], [[["Bobby Jindal-7"]], [["Baton Rouge Magnet High School-1"], "no_evidence"], [["Dog food-1"], "no_evidence"], ["operation"]], [[["Bobby Jindal-7"]], ["no_evidence"], [["Dog food-16"]], [["Dog food-16"], "no_evidence"]]], "golden_sentence": [["Jindal attended Baton Rouge Magnet High School, graduating in 1988."], ["Kibbles 'n Bits is a brand name of dog food manufactured and marketed by Big Heart Pet Brands."]]}, {"qid": "c39d1e6ffbca58600a38", "term": "United States Capitol", "description": "seat of the United States Congress", "question": "Is the United States Capitol located near the White House?", "answer": true, "facts": ["The Capitol building is located at one end of the National Mall in downtown Washington DC.", "The White House is located next to the Washington Monument a short way down from the Mall."], "decomposition": ["What city is the United States Capitol located in?", "What city is the White House located in?", "Is #1 the same as #2?"], "evidence": [[[["United States Capitol-1"]], [["White House-1"]], ["operation"]], [[["United States-1"]], [["White House-1"]], ["operation"]], [[["United States Capitol-1"]], [["White House-1"]], ["operation"]]], "golden_sentence": [["It is located on Capitol Hill at the eastern end of the National Mall in Washington, D.C.."], ["It is located at 1600 Pennsylvania Avenue NW in Washington, D.C., and has been the residence of every U.S. president since John Adams in 1800."]]}, {"qid": "5b45ccb915731a9e5f05", "term": "Logging", "description": "the cutting, skidding, on-site processing, and loading of trees or logs onto transport vehicles", "question": "Would it be hard to get toilet paper if there were no loggers?", "answer": true, "facts": ["Logging produces products such as pulp.", "Pulp is used to make paper products such as toilet paper."], "decomposition": ["What material is used to make paper products such as toilet paper?", "Is logging an important step in  producing #1?"], "evidence": [[[["Pulp (paper)-1"]], [["Logging-1"]]], [[["Paper-1"]], [["Logging-1"]]], [[["Toilet paper-37"]], [["Logging-11"], "operation"]]], "golden_sentence": [["Mixed with water and other chemical or plant-based additives, pulp is the major raw material used in papermaking and the industrial production of other paper products."], ["Logging is the cutting, skidding, on-site processing, and loading of trees or logs onto trucks or skeleton cars."]]}, {"qid": "c44aebb62354b76e5f68", "term": "Iggy Pop", "description": "American rock singer-songwriter, musician, and actor", "question": "Was Iggy Pop named after his father?", "answer": true, "facts": ["Iggy Pop's birth name was James Newell Osterberg Jr.", "The father of Iggy Pop was James Newell Osterberg Sr."], "decomposition": ["What is Iggy Pop's real name?", "What is Iggy Pop's father's name?", "Is #1 the same as #2?"], "evidence": [[[["Iggy Pop-1"]], [["Iggy Pop-5"]], ["operation"]], [[["Iggy Pop-1"]], [["Iggy Pop-5"]], ["operation"]], [[["Iggy Pop-1"]], [["Iggy Pop-5"]], ["operation"]]], "golden_sentence": [["James Newell Osterberg Jr. (born April 21, 1947), better known as Iggy Pop, is an American singer, songwriter, musician, record producer, and actor."], ["Pop was born James Newell Osterberg Jr. in Muskegon, Michigan, on April 21, 1947, the son of Louella (n\u00e9e Christensen; 1917\u20131996) and James Newell Osterberg Sr. (1921\u20132007), a former high school English teacher and baseball coach at Fordson High School in Dearborn, Michigan.", "He is of English and Irish descent on his father's side, and Danish and Norwegian ancestry on his mother's side."]]}, {"qid": "3eb805c6e6cce883416c", "term": "Preventive healthcare", "description": "Prevent and minimize the occurrence of diseases", "question": "Can preventive healthcare reduce STI transmission?", "answer": true, "facts": ["Preventive healthcare includes screenings for STI/STD's. ", "Increases in testing for STI's allow for citizens to protect themselves from infection and contain outbreaks."], "decomposition": ["What are the effects of preventive measures on STI transmission?", "Does #1 involve a reduction in their spread?"], "evidence": [[[["Sexually transmitted infection-22"], "no_evidence"], ["no_evidence", "operation"]], [[["Preventive healthcare-18"]], [["Pre-exposure prophylaxis-8"], "operation"]], [[["Condom-85"]], [["Condom-85"]]]], "golden_sentence": [["Vaccines are available that protect against some viral STIs, such as Hepatitis A, Hepatitis B, and some types of HPV."]]}, {"qid": "b81db0d01318a28e877c", "term": "Beauty and the Beast (1991 film)", "description": "1991 American animated musical fantasy romance film", "question": "Do inanimate objects come alive in Beauty and the Beast?", "answer": true, "facts": ["Beauty and the Beast features a castle full of items that move and speak on their own. ", "An inanimate object is one that is not alive in any way.", "Main characters of Beauty and the Beast include a talking teacup and a sassy duster."], "decomposition": ["Who are the main characters in Beauty and the Beast?", "What type of entities are the characters listed in #1?", "Are any of the types listed in #2 usually inanimate objects?"], "evidence": [[[["Beauty and the Beast (2017 film)-6"]], [["Beauty and the Beast (2017 film)-6"]], [["Beauty and the Beast (2017 film)-6"]]], [[["Beauty and the Beast (1991 film)-6", "Beauty and the Beast (1991 film)-7"], "no_evidence"], [["Beauty and the Beast (1991 film)-7"], "no_evidence"], ["operation"]], [[["Beauty and the Beast (1991 film)-7"]], [["Beauty and the Beast (1991 film)-10"]], ["operation"]]], "golden_sentence": [["Belle uses the book to visit her childhood home in Paris, where she discovers a plague doctor mask and realizes that she and her father were forced to leave when her mother succumbed to the plague."], ["Belle uses the book to visit her childhood home in Paris, where she discovers a plague doctor mask and realizes that she and her father were forced to leave when her mother succumbed to the plague."], ["When she wanders into the forbidden west wing and finds the rose, the Beast scares her into the woods."]]}, {"qid": "ed247b0929da4a53aa85", "term": "Bandy", "description": "ballgame on ice played using skates and sticks", "question": "Would Bandy be likely to become popular in Texas?", "answer": false, "facts": ["The American Bandy Association governs major Bandy play in the United States.", "There are no teams from Texas registered with the American Bandy Association.", "Sports involving ice and snow tend to be more popular in cold climates.", "Texas has an extremely hot climate."], "decomposition": ["What kind of climate favors long term playing of Bandy?", "Which US States have Bandy teams?", "Is Texas included in #2 or have #1 climate?"], "evidence": [[[["Sport in Russia-15"]], [["Bandy in the United States-1"], "no_evidence"], ["operation"]], [[["Bandy-1"]], [["Bandy-101"]], [["Texas-30"], "operation"]], [[["Bandy-1"]], [["Bandy in the United States-1"]], ["operation"]]], "golden_sentence": [["Bandy is a team winter sport played on ice, in which skaters use sticks to direct a ball into the opposing team's goal."], ["Bandy in the United States is played mostly in Minnesota."]]}, {"qid": "9bf48fb011c640f0de4b", "term": "Spinach", "description": "species of plant", "question": "For bone growth, is kale more beneficial than spinach?", "answer": true, "facts": ["Calcium is an important nutrient for bone health.", "Kale has more calcium per serving than spinach."], "decomposition": ["What nutrient is critical for bone growth?", "How much #1 does kale contain?", "How much #1 does spinach contain?", "Is #2 greater than #3?"], "evidence": [[[["Bone growth factor-3"]], [["Kale-11"]], [["Spinach-7"]], ["operation"]], [[["Calcium-36"]], [["Kale-11"]], [["Spinach-7"]], ["operation"]], [[["Calcium-3"]], [["Kale-11"], "no_evidence"], [["Spinach-7"], "no_evidence"], ["no_evidence", "operation"]]], "golden_sentence": [["Other hormones implicated in control of bone growth include thyroid hormone, parathyroid hormone, calcitonin, glucocorticoids such as cortisol, and vitamin D (calcitriol)."], ["Raw kale is composed of 84% water, 9% carbohydrates, 4% protein, and 1% fat (table).", "It is a rich source (20% or more of the DV) of vitamin A, vitamin C, vitamin B6, folate, and manganese (see table \"Kale, raw\")."], ["Raw spinach is 91% water, 4% carbohydrates, 3% protein, and contains negligible fat."]]}, {"qid": "5a7265daf4314e5b9283", "term": "Amazonas (Brazilian state)", "description": "State of Brazil", "question": "Does walking across Amazonas put a person's life at risk?", "answer": true, "facts": ["Amazonas is mostly tropical jungle.", "Tropical jungles contain dangerous creatures.", "Dangerous creatures put people's lives at risk."], "decomposition": ["What is the Amazons made up of?", "Does #1 contain anything dangerous?", "Does #2 put people's life at risk?"], "evidence": [[[["Amazon River-1"]], [["Amazon River-75"], "no_evidence"], [["Piranha-16"], "operation"]], [[["Amazon River-19"]], [["Amazon River-76"]], [["Shark attack-1"]]], [[["Amazon basin-2"]], [["Amazon basin-10"]], ["operation"]]], "golden_sentence": [["The Amazon River (UK: /\u02c8\u00e6m\u0259z\u0259n/, US: /\u02c8\u00e6m\u0259z\u0252n/; Spanish: R\u00edo Amazonas, Portuguese: Rio Amazonas) in South America is the largest river by discharge volume of water in the world, and by most accepted definitions it is the second longest river in the world, after the Nile River."], ["However, only a few of its species are known to attack humans, most notably Pygocentrus nattereri, the red-bellied piranha."], ["Most piranha attacks on humans only result in minor injuries, typically to the feet or hands, but they are occasionally more serious and very rarely can be fatal."]]}, {"qid": "31d0f85e4da977a2ada5", "term": "Nintendo", "description": "Japanese multinational consumer electronics company", "question": "Did original Nintendo have games in same format as Playstation 3?", "answer": false, "facts": ["Nintendo was originally released in 1983 and used games that were in a cartridge format.", "Sony Playstation 3 was released in 2006 and had games in a CD format."], "decomposition": ["What format were Nintendo games originally released in?", "What format were PlayStation 3 games released in?", "Is #1 the same as #2?"], "evidence": [[[["Video game console-11"]], [["PlayStation 3-23"]], ["operation"]], [[["Nintendo Entertainment System-3"]], [["PlayStation 3-2"]], ["operation"]], [[["Nintendo Entertainment System-27"]], [["PlayStation 3-2"]], ["operation"]]], "golden_sentence": [["To distinguish its product from older game consoles, Nintendo released their Famicom as the Nintendo Entertainment System (NES) which used a front-loading cartridge port similar to a VCR, included a plastic \"robot\" (R.O.B."], ["PlayStation 3 features a slot-loading 2x speed Blu-ray Disc drive for games, Blu-ray movies, DVDs, and CDs."]]}, {"qid": "0ec75be0266c3bc29a85", "term": "Fibonacci number", "description": "integer in the infinite Fibonacci sequence", "question": "Is the Fibonacci number sequence longer than every number discovered in Pi?", "answer": true, "facts": ["The Fibonaacci number is a sequence of numbers that adds a number to the one before it and goes on forever.", "Pi is a sequence of numbers and 2.7 trillion digits were discovered in 2010."], "decomposition": ["How many numbers are in Pi?", "How many numbers are in the Fibonacci number sequence?", "Is #2 larger than #1?"], "evidence": [[[["Pi-2"], "no_evidence"], [["Fibonacci prime-3"], "no_evidence"], ["no_evidence", "operation"]], [[["Piphilology-65"]], [["Fibonacci-12"], "no_evidence"], ["operation"]], [[["Pi-2"]], [["Random Fibonacci sequence-4"], "no_evidence"], ["operation"]]], "golden_sentence": [["The digits appear to be randomly distributed."], ["It is not known whether there are infinitely many Fibonacci primes."]]}, {"qid": "ec0463f1bd3c28fe300a", "term": "Judo", "description": "modern martial art, combat and Olympic sport", "question": "Would a Germaphobia be able to participate in Judo?", "answer": false, "facts": ["Germaphobia is a term used by psychologists to describe a pathological fear of germs, bacteria, microbes, contamination and infection.", "If you\u2019re training Judo, you will also find yourself getting into close proximity to the people you are training with, and rolling around on matted floors too. ", "Additionally, you will sweat and roll around on a shared mat when practicing judo."], "decomposition": ["What are some common symptoms of Germaphobia?", "What kind of contact and actions does judo training involve?", "Is avoidance of #2 not included in #1?"], "evidence": [[[["Mysophobia-1"]], [["Judo-1"]], [["Mysophobia-4"], "operation"]], [[["Mysophobia-1"]], [["Judo-1"]], ["operation"]], [[["Mysophobia-1", "Mysophobia-4"]], [["Judo-1"]], ["operation"]]], "golden_sentence": [["Mysophobia, also known as verminophobia, germophobia, germaphobia, bacillophobia and bacteriophobia, is a pathological fear of contamination and germs."], ["Strikes and thrusts by hands and feet as well as weapons defences are a part of judo, but only in pre-arranged forms (kata, \u5f62) and are not allowed in judo competition or free practice (randori, \u4e71\u53d6\u308a)."], ["excessive hand washing an avoidance of locations that might contain a high presence of germs a fear of physical contact, especially with strangers excessive effort dedicated to cleaning and sanitizing one's environment a refusal to share personal items a fear of becoming ill Mysophobia greatly affects the everyday life of individuals and can range in severity of symptoms from difficult breathing, excessive perspiration, increased heart rate, and states of panic when exposed to germ-enhanced conditions."]]}, {"qid": "72478c2c5ce262b5cef4", "term": "Autumn", "description": "one of the Earth's four temperate seasons, occurring between summer and winter", "question": "Is Autumn a good time to collect bear pelts in US?", "answer": false, "facts": ["Autumn runs from September to the end of December in the US.", "Bears go into hibernation from September through April and are scarcely seen."], "decomposition": ["What months does Autumn occur in the US?", "Where do bear pelts come from?", "What months can #2 be easily seen in the US?", "Do #1 and #3 overlap?"], "evidence": [[[["Autumn-3"]], [["Bear hunting-17"]], [["Brown bear-27"]], [["Autumn-1", "Brown bear-27"]]], [[["Autumn-3"]], [["Bear hunting-23"]], ["no_evidence"], ["operation"]], [[["Autumn-1"]], [["American black bear-1", "Grizzly bear-1"]], [["Bear-39"], "no_evidence"], ["operation"]]], "golden_sentence": [["However, according to the Irish Calendar, which is based on ancient Gaelic traditions, autumn lasts throughout the months of August, September and October, or possibly a few days later, depending on tradition."], ["The underfur, which is soft and dense, serves primarily as an insulator."], ["Although they are not full hibernators and can be woken easily, both sexes like to den in a protected spot during the winter months."], ["Autumn marks the transition from summer to winter, in September (Northern Hemisphere) or March (Southern Hemisphere), when the duration of daylight becomes noticeably shorter and the temperature cools considerably.", "However, it frequently seems to peak in activity in the morning and early evening hours."]]}, {"qid": "7e6f36cc5ad38b425b53", "term": "Pink (singer)", "description": "American singer, songwriter, and actress", "question": "Are there Pink music videos that are triggering for eating disorder patients?", "answer": true, "facts": ["The video for 'Stupid Girls' features a scene where Pink and a woman share a toothbrush to induce vomiting in the bathroom.", "Images or discussion of purging activity can be triggering for people with Eating Disorders."], "decomposition": ["What are the depictions in Pink's music video 'Stupid Girls'?", "What are some situations that can be triggering for people with eating disorders?", "Are any of #2 included in #1?"], "evidence": [[[["Stupid Girls-12"]], [["Eating disorder-7"], "no_evidence"], ["operation"]], [[["Stupid Girls-12", "Stupid Girls-13"]], [["Eating disorder-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Stupid Girls-13"]], [["Eating disorder-9"]], [["Stupid Girls-13"]]]], "golden_sentence": [["The angel shows her a series of images demonstrating the stupidity of current trends in female celebrities, and the images feature Pink in various roles, including a dancer in a 50 Cent video, a girl attempting to attract the attention of an instructor at the gym but her tracksuit pants get caught in the treadmill, causing them to be ripped off and exposing her bright pink panties, a girl who uses her emergency inflatable breasts at a bowling alley, a girl at a tanning salon, a girl with purging disorder who considers calories \"so not sexy\", an old woman in a pink tracksuit who looks as if she is trying too hard to look young, a girl getting plastic surgery, a girl making a sex tape, a girl washing her car and rubbing a facecloth and soap all over herself, and a girl who goes into what looks like a pet shop, buys an \"itsy bitsy doggy\" with the advertisement that it \"stays younger longer\", and drives her car so carelessly while putting on makeup that she runs over two people.", "Pink also plays characters meant to represent the opposite of \"stupid girls\", such as a female president and a girl winning a game of football."], ["Those who have the restricting type of anorexia nervosa restrict food intake and do not engage in binge eating, whereas those with the binge/purge type lose control over their eating at least occasionally and may compensate for these binge episodes."]]}, {"qid": "5f290c4202a54bf6aa71", "term": "Space Race", "description": "Competition between the USSR and the USA to explore space", "question": "Did Al Unser Jr. win the Space Race?", "answer": false, "facts": ["Al Unser Jr. is a race car driver", "The Space Race was the competition between the Soviet Union and United States over space exploration"], "decomposition": ["What two entities were part of the Space Race?", "Is Al Unser Jr. either of #1?"], "evidence": [[[["Space Race-1"]], [["Al Unser Jr.-1"], "operation"]], [[["Space Race-1"]], [["Al Unser Jr.-1"], "operation"]], [[["Space Race-1"]], ["operation"]]], "golden_sentence": [["The Space Race was a 20th-century competition between two Cold War rivals, the Soviet Union (USSR) and the United States (US), to achieve firsts in spaceflight capability."], ["Alfred Unser Jr. (born April 19, 1962), nicknamed \"Little Al\", \"Al Junior\", or simply \"Junior\", is a retired American race car driver and two-time Indianapolis 500 winner."]]}, {"qid": "534cebe828195c3a8f31", "term": "World of Warcraft", "description": "video game by Blizzard Entertainment", "question": "Is World of Warcraft heavier than a loaf of bread?", "answer": false, "facts": ["World of Warcraft is a piece of software.", "Software is digital.", "Digital items do not have weight. "], "decomposition": ["What does World of Warcraft refer to?", "Is #1 a tangible item that has weight?"], "evidence": [[[["World of Warcraft-2"]], ["no_evidence", "operation"]], [[["World of Warcraft-2"]], [["Software-1"]]], [[["World of Warcraft-1"]], ["operation"]]], "golden_sentence": [["At BlizzCon 2017, a vanilla version of the game titled World of Warcraft Classic was announced, which planned to provide a way to experience the base game before any of its expansions launched."]]}, {"qid": "f640e31952dea1040e3c", "term": "Metroid", "description": "Video game series", "question": "Did Electronic Arts profit from Metroid sales?", "answer": false, "facts": ["Metroid was created and published by Nintendo.", "Electronic Arts is a video game company that is a competitor to Nintendo.", "Companies cannot profit of the work owned by another company typically.", "Companies do not typically share profits with their competitors."], "decomposition": ["What company created and published Metroid?", "What is the relationship between #1 and Electronic Arts?", "Do two entities engaged in #2 directly benefit each other?"], "evidence": [[[["Metroid-10"]], [["Electronic Arts-15"]], ["operation"]], [[["Metroid-1"]], [["Electronic Arts-15"], "no_evidence"], ["operation"]], [[["Metroid (video game)-8"]], [["Electronic Arts-15"]], ["operation"]]], "golden_sentence": [["Developers from Retro Studios gave a full but cryptic denial of any connection with the rumored game, and Nintendo denied they were making another 2D Metroid game."], ["Electronic Arts was The 3DO Company's primary partner in sponsoring their console, showcasing on it their latest games."]]}, {"qid": "2800bf5c809ed1224b42", "term": "New Testament", "description": "Second division of the Christian biblical canon", "question": "Would a kindergarten teacher make a lesson of the New Testament?", "answer": false, "facts": ["The majority of Kindergarten teachers work in public schools.", "Public schools abide by a separation of church and state, and do not have any overall religion.", "Students of all religions are welcome to attend public school."], "decomposition": ["Where do the majority of kindergarten teachers work?", "Do students in #1 follow a paritcular religion?"], "evidence": [[[["Kindergarten-1"]], [["Kindergarten Playway-3"]]], [[["Kindergarten-89"]], [["Education in the United States-2"], "no_evidence"]], [[["Education in the United States-47"]], [["School prayer in the United States-1"], "operation"]]], "golden_sentence": [["Such institutions were originally made in the late 18th century in Bavaria and Alsace to serve children whose parents both worked outside home."], ["A kindergarten (from German, German pronunciation: [\u02c8k\u026and\u0250\u02cc\u0261a\u02d0\u0250\u032ftn\u0329] which means literally \"garden for the children\", the term was coined in the metaphorical sense of \"place where children can grow in a natural way\", not in the literal sense of having a \"garden\") is a preschool educational approach traditionally based on playing, singing, practical activities such as drawing, and social interaction as part of the transition from home to school."]]}, {"qid": "6e95d89ccd3256bde343", "term": "Amy Winehouse", "description": "English singer and songwriter", "question": "Did Amy Winehouse always perform live perfectly?", "answer": false, "facts": ["Amy Winehouse was known for getting intoxicated before an during sets.", "Amy Winehouse forgot the lyrics to her songs during her last performance."], "decomposition": ["Is Amy Winehouse known for always being sober and coordinated on stage?"], "evidence": [[[["Amy Winehouse-16"]]], [[["Amy Winehouse-16"]]], [[["Amy Winehouse-16"]]]], "golden_sentence": [["Mitch Winehouse wrote about her nervousness before public performances in his 2012 book, Amy, My Daughter."]]}, {"qid": "7d1f1c2a9d554a017a22", "term": "Anchovy", "description": "Family of fishes", "question": "Are there bones in an anchovy pizza?", "answer": true, "facts": ["Anchovies used on pizza are typically packed whole in oil or water. ", "Anchovies on pizza are not usually cut or filleted in any way."], "decomposition": ["Which fishes are used in anchovy pizza?", "Are #1 usually packed whole into the pizza?"], "evidence": [[[["Anchovies as food-3"]], [["Anchovies as food-2"]]], [[["Anchovies as food-2"]], [["Anchovies as food-2"], "no_evidence", "operation"]], [[["Anchovy-3"]], [["Anchovy-3"]]]], "golden_sentence": [["Anchovies are a popular pizza topping in some places."], ["A traditional method of processing and preserving anchovies is to gut and salt them in brine, allow them to mature, and then pack them in oil or salt."]]}, {"qid": "4070e4485b1bcc9e04d8", "term": "Sand cat", "description": "Small wild cat", "question": "Can you hide a basketball in a sand cat's ear?", "answer": false, "facts": ["The diameter of a standard NBA basketball is around 9.5 inches", "A sand cat's ear grows to 2.8 inches tall"], "decomposition": ["On average, how large is a sand cat's ear?", "What is the size of a standard NBA basketball?", "Is #1 greater than #2?"], "evidence": [[[["Sand cat-1"]], [["Basketball-1"]], ["operation"]], [[["Sand cat-1"], "no_evidence"], [["Basketball-1"]], ["no_evidence", "operation"]], [[["Sand cat-19"], "no_evidence"], [["Basketball (ball)-1"], "no_evidence"], ["operation"]]], "golden_sentence": [["Its 5\u20137\u00a0cm (2.0\u20132.8\u00a0in) long ears are set low on the sides of the head, aiding detection of prey moving underground."], ["Basketball is a team sport in which two teams, most commonly of five players each, opposing one another on a rectangular court, compete with the primary objective of shooting a basketball (approximately 9.4 inches (24\u00a0cm) in diameter) through the defender's hoop (a basket 18 inches (46\u00a0cm) in diameter mounted 10 feet (3.048\u00a0m) high to a backboard at each end of the court) while preventing the opposing team from shooting through their own hoop."]]}, {"qid": "6ef94676fb10c0e34de2", "term": "Ivan the Terrible", "description": "Grand Prince of Moscow and 1st Tsar of Russia", "question": "Did Ivan the Terrible's father and grandfather have nicer nicknames?", "answer": true, "facts": ["Ivan the Terrible was nicknamed terrible because of his harsh rule.", "Ivan the Terrible's father, Vasili III Ivanovich, was nicknamed Vasili the Adequate.", "Ivan the Terrible's grandfather, Ivan III Vasilyevich, was nicknamed Ivan the Great."], "decomposition": ["Who was Ivan the Terrible's father?", "Who was the father of #1?", "Do #1 and #2 have nicer nicknames than \"the Terrible\"?"], "evidence": [[[["Vasili III of Russia-1"]], [["Ivan III of Russia-1", "Vasili III of Russia-1"]], ["operation"]], [[["Vasili III of Russia-1"]], [["Vasili III of Russia-1"]], [["Vasili III of Russia-1"], "operation"]], [[["Vasili III of Russia-1"]], [["Ivan III of Russia-1"]], ["operation"]]], "golden_sentence": [["He was the son of Ivan III Vasiliyevich and Sophia Paleologue and was christened with the name Gavriil (\u0413\u0430\u0432\u0440\u0438\u0438\u043b).", "He is sometimes mockingly referred to as Vasili the Adequate due to his rule taking place between those of Ivan the Great and his son Ivan the Terrible, as well as the relative uneventfulness of his reign."], ["Ivan served as the co-ruler and regent for his blind father Vasily II from the mid-1450s before he officially ascended the throne in 1462.", "He was the son of Ivan III Vasiliyevich and Sophia Paleologue and was christened with the name Gavriil (\u0413\u0430\u0432\u0440\u0438\u0438\u043b)."]]}, {"qid": "42852587e89ab6ade6b9", "term": "Breast cancer", "description": "cancer that originates in the mammary gland", "question": "Are amoebas safe from breast cancer?", "answer": true, "facts": ["Breast cancer is a disease that occurs in the mammary tissues of mammals.", "Amoebas are single cell organisms that lack mammary tissue."], "decomposition": ["What tissue does breast cancer affect?", "Is having #1 a necessary condition for breast cancer?", "By #2, is it the case that if an organism lacks #1 they cannot get breast cancer?"], "evidence": [[[["Breast cancer-1"]], [["Breast cancer-2"]], [["Breast cancer-2"]]], [[["Breast cancer-1"]], ["operation"], ["operation"]], [[["Breast cancer-2"]], [["Breast cancer-8"]], ["operation"]]], "golden_sentence": [["Signs of breast cancer may include a lump in the breast, a change in breast shape, dimpling of the skin, fluid coming from the nipple, a newly-inverted nipple, or a red or scaly patch of skin."], ["Risk factors for developing breast cancer include being female, obesity, a lack of physical exercise, alcoholism, hormone replacement therapy during menopause, ionizing radiation, an early age at first menstruation, having children late in life or not at all, older age, having a prior history of breast cancer, and a family history of breast cancer."], ["Risk factors for developing breast cancer include being female, obesity, a lack of physical exercise, alcoholism, hormone replacement therapy during menopause, ionizing radiation, an early age at first menstruation, having children late in life or not at all, older age, having a prior history of breast cancer, and a family history of breast cancer."]]}, {"qid": "bac108d947b7b26035cc", "term": "Pi", "description": "Ratio of the circumference of a circle to its diameter", "question": "Was Pi an acceptable number of children in 1980s China?", "answer": false, "facts": ["Pi, the ratio of a circle's circumference to diameter, is equal to 3.14.", "In the 1980's China instituted a one-child policy.", "People that violated China's one child policy were fined heavily and some were sterilized."], "decomposition": ["How many children were Chinese parents limited to by the One-child policy in the 1980s?", "What is the value of the number pi?", "Is #2 less than or equal to #1?"], "evidence": [[[["One-child policy-1"]], [["Pi-1"]], ["operation"]], [[["One-child policy-1"]], [["Pi-1"]], ["operation"]], [[["One-child policy-1"]], [["Pi-1"]], ["operation"]]], "golden_sentence": [["It was introduced in 1979 (after a decade-long two-child policy), modified beginning in the mid 1980s to allow rural parents a second child if the first was a daughter, and then lasted three more decades before the government announced in late 2015 a reversion to a two-child limit."], ["It is approximately equal to 3.14159."]]}]